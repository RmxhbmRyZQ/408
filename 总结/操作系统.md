# 操作系统

- [第一章 操作系统的基本概念](#作系统的基本概念)
- [第二章 进程管理](#进程管理)
- [第三章 内存管理](#内存管理)
- [第四章 文件管理](#文件管理)
- [第五章 输入输出管理](#输入输出管理)

# 操作系统的基本概念

## 操作系统的基本概念

### 操作系统的概念

计算机系统自下而上可大致分为：**硬件、操作系统、应用程序、用户**（与计组的分层不同）

操作系统管理各种计算机硬件，为应用程序提供基础，是**计算机硬件与用户之间的中介**

- 硬件**提供基本的计算资源**
- 应用程序规定按何种方式使用这些资源来**解决用户的计算问题**
- 操作系统控制和协调各用户的应用程序**对硬件的分配与使用**

操作系统 Operating System 是指**控制和管理整个计算机系统的硬件与软件资源，合理地组织、调度计算机的工作与资源的分配**，进而为用户和其他软件**提供方便接口与环境的程序集合**，操作系统是计算机系统中**最基本的系统软件**

### 操作系统的特征

操作系统是一种**系统软件**，但与其他系统软件和应用软件有很大的不同，它**有自己的特殊性即基本特征**，基本特征有：

#### 并发 Concurrence

并发是指**两个或多个事件在同一时间间隔内发生**；在操作系统中，引入进程的目的是**使程序能并发执行**

操作系统的并发性是指**同时存在多个运行的程序**，具有**处理和调度多个程序同时执行的能力**

并发和并行的区别：

- 并发：同一时间间隔，**即一段时间内**，宏观上有**多道程序在同时执行**，而微观上这些程序**仍是分时交替执行的**
- 并行：**同一时刻**能完成两种或两种以上的工作；**并行性**是指系统可以进行并发，并行性**需要有相关硬件的支持**

#### 共享 Sharing

资源共享即共享，是指**系统中的资源可供内存中多个并发执行的进程共同使用**，共享可分为以下两种资源共享方式

##### 互斥共享方式

系统中的某些资源，如打印机，虽然可供多个进程使用，但为使得所打印或记录的结果不致造成混淆，应规定**在一段时间内只允许一个进程访问该资源**，不能出现打印机第一行打印 A 文档的内容、第二行打印 B 文档的内容

进程 A 使用某资源时，其他人想要使用就必须等 A 使用完了才可以使用，即使 A 被分时系统暂停了

这种资源共享方式称为**互斥式共享**，而把在**一段时间内只允许一个进程访问的资源**称为**临界资源或独占资源**

计算机系统中的**大多数物理设备**及**某些软件中所用的栈、变量和表格**，都属于临界资源，它们都要求被互斥地共享

##### 同时访问方式

系统中还有另一类资源，这类资源**允许在一段时间内由多个进程同时访问**

这里所说的同时通常是宏观上的，而在微观上，这些进程可能是**交替地对该资源进行访问**即分时共享的

进程 A 被分时系统暂停后，进程 B 就可以使用，但从微观来看资源被交替的使用

可供多个进程“同时”访问的典型资源是**磁盘设备**，即允许若干个用户“同时”访问该文件

思考：互斥共享要等别人用完了才能用（即使某时间段没有使用），同时访问是只要别人不用就可以用

------

**并发和共享是操作系统两个最基本的特征**，两者之间互为存在的条件：

1. 资源共享是以程序的并发为条件的，<u>若系统不允许程序并发执行，则自然不存在资源共享问题</u>
2. <u>若系统不能对资源共享实施有效的管理，则必将影响到程序的并发执行</u>，甚至根本无法并发执行

#### 虚拟 Virtual

虚拟是指**把一个物理上的实体变为若干逻辑上的对应物**。物理实体（前者）是实的，即实际存在的；而后者是虚的，是用户感觉上的事物。用于实现虚拟的技术，称为虚拟技术

操作系统中利用了多种虚拟技术来实现虚拟处理器、虚拟内存和虚拟外部设备等

- 虚拟处理器技术：

  采用让多道程序并发执行的方法，来分时使用一个处理器，让<u>每个终端用户都感觉有一个中央处理器在专门为它服务</u>

  利用多道程序设计技术**把一个物理上的 CPU 虚拟为多个逻辑上的 CPU**，称为虚拟处理器

- 虚拟存储器技术：

  将一台机器的物理存储器变为虚拟存储器，**从逻辑上扩充存储器的容量**

  这时用户所感觉到的内存容量是虚的，我们把**用户感觉到的存储器称为虚拟存储器**

- 虚拟设备技术：

  **将一台物理 I/O 设备虚拟为多台逻辑上的 I/O 设备**，并允许每个用户占用一台逻辑上的 I/O 设备

  使原来仅允许在一段时间内由一个用户访问的设备变为在一段时间内允许多个用户同时访问的共享设备

操作系统的虚拟技术可归纳为：**时分复用技术**，如处理器的分时共享；**空分复用技术**，如虚拟存储器

#### 异步 Asynchronism

一个程序想要使用一个临界资源，若没有其他程序就可以直接使用，否则要等其他程序释放了才可以使用

多道程序环境允许多个程序并发执行，但由于**资源有限**，进程的执行并**不是一贯到底的**，而是走走停停的，它以**不可预知**的速度向前推进（有人抢资源慢一点，没人抢资源快一点），这就是**进程的异步性**

异步性使得操作系统运行在一种随机的环境下，可能**导致进程产生与时间有关的错误**

只要**运行的环境相同**（如同样是有人抢资源的情况下），操作系统就须<u>保证多次运行进程后都能获得相同的结果</u>

### 操作系统的目标和功能

用户是雇主，计算机是机器，操作系统是有熟练技能的工人，能够控制和协调各个部件的工作，即操作系统对资源的管理

同时，工人必须接收雇主的命令，这就是“接口”，有了工人，机器就能发挥更大的作用，因此工人就成了“扩充机器”

操作系统有以下功能：

#### 系统资源的管理者

##### 处理机管理

在多道程序环境下，处理机的分配和运行都以进程（或线程）为基本单位，因而**对处理机的管理可归结为对进程的管理**

并发是指在计算机内**同时运行多个进程**，**主要管理**进程<u>何时创建、何时撤销、如何管理、如何避免冲突、合理共享</u>

进程管理的**主要功能**包括<u>进程控制、进程同步、进程通信、死锁处理、处理机调度</u>等

##### 存储器管理

存储器管理是为了**给多道程序的运行提供良好的环境**，方便用户使用及提高内存的利用率

**主要包括**内存分配与回收、地址映射、内存保护与共享和内存扩充等功能

##### 文件管理

计算机中的**信息都是以文件的形式存在**的，操作系统中负责文件管理的部分称为**文件系统**

文件管理包括文件存储空间的管理、目录管理及文件读写管理和保护等

##### 设备管理

设备管理的**主要任务**是<u>完成用户的 I/O 请求，方便用户使用各种设备，并提高设备的利用率</u>

**主要包括**缓冲管理、设备分配、设备处理和虚拟设备等功能

#### 用户与硬件之间的接口

为了让用户方便、快捷、可靠地操纵计算机硬件并运行自己的程序，操作系统还提供了用户接口

操作系统提供的接口主要分为两类：

- 命令接口：用户利用这些操作命令来组织和控制作业的执行
- 程序接口：**编程人员**可以使用它们来**请求操作系统服务**

##### 命令接口

按作业控制方式的不同，可将命令接口分为联机命令接口和脱机命令接口，分别对应联机控制方式和脱机控制方式

- 联机命令接口，交互式命令接口：适用于分时或实时系统的接口，它**由一组键盘操作命令组成**

  用户**通过控制台或终端输入操作命令，向系统提出各种服务要求**，如 Windows 里面使用 `cmd` 调用命令

- 脱机命令接口，批处理命令接口：适用于批处理系统，它**由一组作业控制命令组成**，用户**不能直接干预作业的运行**

  事先用相应的作业控制命令**写成一份作业操作说明书，连同作业一起提交给系统**，如 Windows 的 .bat 文件

##### 程序接口

程序接口由**一组系统调用（也称广义指令）组成**，用户**只能通过用户程序间接使用**系统调用来请求操作系统为其提供服务

图形接口 GUI **最终通过调用程序接口实现的**，用户通过在图形界面上单击或使用快捷键，就能很方便地使用操作系统

严格来说，图形接口不是操作系统的一部分，但图形接口所调用的系统调用命令是操作系统的一部分

#### 操作系统用作扩充机器*

**没有任何软件支持的计算机称为裸机**，它仅构成计算机系统的物质基础，在用户面前的是经过若干层软件改造的计算机

裸机在最里层，其外面是操作系统，操作系统所提供的资源管理功能和方便用户的各种服务功能，将裸机改造成功能更强、使用更方便的机器；因此，我们通常**把覆盖了软件的机器称为扩充机器或虚拟机**

## 操作系统的发展与分类

通用操作系统：具有通用性，如 Android 等；专用操作系统：只能在某一特定的硬件上使用，如控制火箭

### 手工操作阶段

用户在计算机上的所有工作都要人工干预，如程序的装入、运行、结果的输出等

手工操作阶段（此阶段无操作系统）有两个突出的缺点：

1. 用户独占全机，虽然不会出现因资源已被其他用户占用而等待的现象，但**资源利用率低**
2. CPU 等待手工操作，**CPU 的利用不充分**

唯一的解决办法就是<u>用高速的机器代替相对较慢的手工操作</u>来对作业进行控制

### 批处理阶段

为了解决人机矛盾及 CPU 和 I/O 设备之间速度不匹配的矛盾，出现了批处理系统，操作系统开始出现

#### 单道批处理系统

单道批处理系统是在解决<u>人机矛盾及 CPU 和 I/O 设备速率不匹配</u>的矛盾中形成的

单道批处理系统的主要特征如下：

1. 自动性：在顺利的情况下，磁带上的一批作业能**自动地逐个运行，无须人工干预**
2. 顺序性：磁带上的各道作业顺序地进入内存，**先调入内存的作业先完成**
3. 单道性：**内存中仅有一道程序运行**，当该程序**完成或发生异常**情况时，**才换入其后继程序进入内存运行**

问题：每次主机内存中仅存放一道作业，每当它在**运行期间**发出输入/输出请求后，高速的 CPU 便处于**等待低速的 I/O 完成**的状态，为了进一步**提高资源的利用率和系统的吞吐量**，引入了多道程序技术

#### 多道批处理系统

多道程序设计技术允许**多个程序同时进入内存并允许它们在 CPU 中交替地运行**，这些程序**共享系统中的各种硬/软件资源**

当一道程序**因 I/O 请求而暂停运行时**，CPU 便立即转去运行另一道程序，**让系统的各个组成部分都尽量去“忙”**，使其整体在单位时间内的**效率翻倍**（CPU 和 I/O 设备**并行**），CPU 利用率：CPU 时间 / 整个程序时间

多道批处理系统的设计和实现要**比单道系统复杂很多**，因为要充分利用各种资源，就要涉及**各种资源的调度问题**

多道程序设计的特点：

1. 多道：计算机**内存中同时存放多道相互独立的程序**
2. 宏观上并行：内存中的多道程序**都处于运行过程中**
3. 微观上串行：内存中的多道程序**轮流占有 CPU**，交替执行

多道程序设计技术的实现需要解决下列问题：

1. 如何**分配处理器**
2. 多道程序的**内存分配**问题
3. **I/O 设备如何分配**
4. 如何**组织和存放大量的程序和数据**，以方便用户使用并保证其安全性与一致性

在批处理系统中采用多道程序设计技术就形成了**多道批处理操作系统**

优点：

- **资源利用率高**，多道程序共享计算机资源，从而使各种资源得到充分利用
- **系统吞吐量大**，CPU 和其他资源保持“忙碌”状态

缺点：用户**响应的时间较长**；**不提供人机交互能力**，用户既不能了解自己的程序的运行情况，又不能控制计算机

注意：引入多道程序设计后，程序的执行就**失去了封闭性和顺序性**，程序也由于资源、协同等原因相互制约

### 分时操作系统

所谓分时技术，是指**把处理器的运行时间分成很短的时间片，按时间片轮流把处理器分配给各联机作业使用**

若某个作业**不能在分配给它的时间片内完成计算，则暂停该作业**，把处理器**让给其他作业使用**，等待**下一轮再继续运行**

由于计算机速度很快，作业运行轮转得也很快，因此给每个用户的感觉就像是自己独占一台计算机

分时操作系统是指**多用户共享一台主机**，这些终端连接在主机上，用户**可以同时与主机进行交互操作而互不干扰**

实现分时系统最关键的问题是**如何使用户能与自己的作业进行交互**，即**系统应能及时接收并及时处理命令并返回结果**

分时系统操作系统是在**多道批处理系统加上人机交互**，具有与批处理系统不同的特征

分时系统的主要特征如下：

1. 同时性，多路性：允许**一台计算机与若干台终端相连接**，终端上的这些用户**可以同时或基本同时使用计算机**
2. 交互性：用户通过终端采用人机对话的方式直接控制程序运行，**与同程序进行交互**
3. 独立性：系统中**多个用户可以彼此独立地进行操作**，互不干扰，感觉不到别人也在使用这台计算机
4. 及时性：分时系统**采用时间片轮转方式使一台计算机同时为多个终端服务**，使用户请求能在**很短时间内获得响应**

虽然分时操作系统较好地解决了人机交互问题，但在一些应用场合，**需要系统能对外部的信息在规定的时间（比时间片的时间还短）内做出处理**（比如飞机订票系统或导弹制导系统），实时操作系统应运而生

### 实时操作系统

为了**能在某个时间限制内完成某些紧急任务而不需要时间片排队**，诞生了实时操作系统

这里的时间限制可以分为两种情况：

1. 硬实时系统：某个动作**必须绝对地在规定的时刻或规定的时间范围发生**，如飞行器的飞行自动控制系统
2. 软实时系统：能够接受**偶尔违反时间规定且不会引起任何永久性的损害**，如飞机订票系统、银行管理系统

在实时操作系统的控制下，计算机系统接收到外部信号后**及时进行处理**，并**在严格的时限内处理完接收的事件**

实时操作系统的主要特点是**及时性和可靠性**

### 网络操作系统*

网络操作系统<u>把计算机网络中的各台计算机有机地结合起来</u>，提供一种统一、经济而有效的使用各台计算机的方法，<u>实现各台计算机之间数据的互相传送</u>

网络操作系统最主要的特点是**网络中各种资源的共享及各台计算机之间的通信**

### 分布式计算机系统*

分布式计算机系统是由多台计算机组成并满足下列条件的系统：

1. 系统中<u>任意两台计算机通过通信方式交换信息</u>
2. 系统中的<u>每台计算机都具有同等的地位</u>，即没有主机也没有从机
3. 每台计算机上的<u>资源为所有用户共享</u>
4. 系统中的<u>任意台计算机都可以构成一个子系统，并且还能重构</u>
5. <u>任何工作都可以分布在几台计算机上</u>，由它们并行工作、协同完成

用于管理分布式计算机系统的操作系统称为分布式计算机系统，该系统的主要特点是：<u>分布性和并行性</u>

分布式操作系统与网络操作系统的本质不同是，**分布式操作系统中的若干计算机相互协同完成同一任务**

### 个人计算机操作系统*

个人计算机操作系统是目前<u>使用最广泛的操作系统</u>，它广泛应用于文字处理、电子表格、游戏中，常见的有 Windows、Linux 和 Macintosh 等

操作系统的发展历程如图所示：

![image-20211101214657019](..\images\image-20211101214657019.png)

此外，还有<u>嵌入式操作系统、服务器操作系统、智能手机操作系统</u>等

额外：这里的脱机处理指把穿孔卡输入进磁带，CPU 直接从磁带提取数据，以提高 I/O 速度，可能仅提高 I/O 没使用批处理

## 操作系统的运行环境

### 操作系统的运行机制

计算机系统中有两种指令：**特权指令和非特权指令**，特权指令是指**计算机中不允许用户直接使用的指令**

相应的有两种处理器状态，核心态和用户态：

1. 核心态：可以运行**特权指令和非特权指令**，这里面的程序叫做**管理程序（系统内核程序）**，用来**管理用户态的程序**

   如 I/O 指令、置中断指令，存取用于内存保护的寄存器等，为了**安全**起见代替用户态执行这些指令

2. 用户态：只能运行**非特权指令**，里面的程序是**用户自编程序（应用程序）**，不能直接访问系统中的软硬件资源

现代计算机几乎都是**层次式的结构**，**与硬件关联较紧密的模块处于最低层**，其次是**运行频率较高的程序**

这两部分内容构成了操作系统的内核，这部分内容的指令操作工作在核心态

![image-20211102183613575](..\images\image-20211102183613575.png)

**内核是计算机上配置的底层软件，是计算机功能的延伸**，大多数操作系统的内核包括 4 方面的内容：

#### 时钟管理

在计算机的各种部件中，时钟是**最关键的设备**

时钟的第一功能是计时，操作系统需要通过时钟管理，**提供标准的系统时间**；通过时钟中断的管理，可以**实现进程的切换**

1. 在分时操作系统中采用时间片轮转调度
2. 在实时系统中按截止时间控制运行
3. 在批处理系统中通过时钟管理来衡量一个作业的运行程度

因此，**系统管理的方方面面无不依赖于时钟**

#### 中断机制

中断机制是操作系统各项操作的**基础**，现代操作系统是靠中断驱动的软件，操作系统必须提供

键盘或鼠标信息的输入、进程的管理和调度、系统功能的调用、设备驱动、文件访问等，无不依赖于中断机制

//中断机制中，只有一小部分功能属于内核，它们负责保护和恢复中断现场的信息，转移控制权到相关的处理程序

//这样可以减少中断的处理时间，提高系统的并行处理能力

其中 **PC 和 PSW 由硬件保存，通用寄存器和屏蔽字由操作系统保存**

#### 原语

原语 Atomic Operation 是具有以下特点的程序（原语**各自完成一个规定的操作**）：

1. 处于操作系统的最低层，是**最接近硬件的部分**，通常可由硬件实现
2. 这些程序的运行**具有原子性**，其**操作只能一气呵成**（主要从系统安全性和便于管理考虑）
3. 这些程序的运行时间都较短，而且**调用频繁**

定义原语的直接方法是<u>关闭中断，让其所有动作不可分割地完成后再打开中断</u>

系统中的设备驱动、CPU 切换、进程通信等功能中的部分操作都可定义为原语，使它们成为**内核的组成部分**

#### 系统控制的数据结构及处理

为了实现有效的管理，系统需要一些基本的操作，常见的操作有以下 3 种：

1. **进程管理**：进程状态管理、进程调度和分派、创建与撤销进程控制块等

   选择题：进程调度不需要硬件支持，它仅需要软件来进行调度

2. **存储器管理**：存储器的空间分配和回收、内存信息保护程序、代码对换程序等

3. **设备管理**：缓冲区管理、设备分配和回收等

核心态指令实际上包括**系统调用类指令和一些针对时钟、中断和原语的操作指令**

### 中断和异常的概念

在操作系统中引入核心态和用户态后，就要考虑它们如何切换，操作系统内核工作在核心态，而用户程序工作在用户态

在实际操作系统中，CPU 运行上层程序时**唯一的进入核心态的途径**就是通过**中断或异常**

**使用状态寄存器的一位记录是核心态或用户态**，发生中断时，由**<u>硬件</u>改为核心态**，中断程序执行完后由**特权指令改回用户态**

中断是操作系统中非常重要的一个概念，对一个运行在计算机上的实用操作系统而言，<u>缺少了中断机制，将是不可想象的</u>

<u>操作系统的发展过程大体上就是一个想方设法不断提高资源利用率的过程</u>，而中断在程序并未使用某种资源时，把它对那种资源的占有权释放，从而提高资源利用率

思考：中断进入内核态，保存断点、现场、屏蔽字，然后在内核态下运行中断服务程序

#### 中断和异常的定义

- 中断 Interruption，外中断：来自 CPU 执行**指令以外的事件的发生**，如设备发出的 I/O 结束中断

  时钟中断，表示**一个固定的时间片已到**，让处理机处理计时、启动定时运行的任务等

- 异常 Exception，内中断：**源自 CPU 执行指令内部的事件**，如程序的非法操作码、缺页、陷入指令等

  对异常的处理一般要依赖于当前程序的运行现场，而且**异常不能被屏蔽，一旦出现应立即处理**

![image-20211102192950500](..\images\image-20211102192950500.png)

#### 中断和异常的分类

外中断可分为可屏蔽中断和不可屏蔽中断：

- 可屏蔽中断：通过 INTR 线发出的中断请求，通过改变屏蔽字可以实现多重中断
- 不可屏蔽中断：通过 NMI 线发出的中断请求，通常是紧急的硬件故障，如电源掉电等（异常也不可屏蔽）

异常可分为故障、自陷、终止：

- 故障 Fault：由**指令执行引起**的异常，如非法操作码、 缺页故障、除数为 0、运算溢出等
- 自陷 Trap：事先安排的异常事件，用于在用户态下调用操作系统内核程序，如条件陷阱指令
- 终止 Abort：指出现了使得 CPU 无法继续执行的硬件故障，如控制器岀错、存储器校验错等

故障异常和自陷异常属于软件中断（程序性异常），终止异常和外部中断属于硬件中断

#### 中断和异常处理的过程

中断和异常处理过程的大致描述如下：

1. 若 CPU 在执行用户程序的第 i 条指令时检测到一个异常事件，或在执行第 i 条指令后发现一个中断请求信号
2. 打断当前的用户程序，然后转到相应的中断或异常处理程序去执行
3. 若能够解决相应的问题，则最后执行中断或异常返回指令，回到被打断的用户程序的第 i 条指令或第 i + 1 条指令继续执行
4. 若发现是不可恢复的致命错误，则终止用户程序

通常情况下，对中断和异常的具体处理过程由操作系统（和驱动程序）完成

选择题：中断处理一定会保存而子程序调用不需要保存其内容的**程序状态字寄存器 PSW**

### 系统调用

所谓系统调用，是指**用户在程序中调用操作系统所提供的一些子功能**，系统调用可视为**特殊的公共子程序**

操作系统掌管所有共享资源，为了让资源**并发和安全**的执行，用户程序必须**通过系统调用让操作系统代为完成**

这些系统调用按功能大致可分为如下几类：

- **设备管理**：完成设备的请求或释放，以及设备启动等功能
- **文件管理**：完成文件的读、写、创建及删除等功能
- **进程控制**：完成进程的创建、撤销、阻塞及唤醒等功能
- **进程通信**：完成进程之间的消息传递或信号传递等功能
- **内存管理**：完成内存的分配、回收以及获取作业占用内存区大小及始址等功能

系统调用涉及**资源管理**，所以理应由操作系统内核完成，**运行在核心态**，用户通过**陷入指令来调用系统调用**

这么设计的目的是：**用户程序不能直接执行对系统影响非常大的操作**，必须通过系统调用的方式请求操作系统代为执行，以便保证系统的稳定性和安全性，**防止用户程序随意更改或访问重要的系统资源**，影响其他进程的运行

操作系统的运行环境就可以理解为：用户程序**需要管理程序服务时**，通过**陷入指令进入核心态**，运行管理程序；或运行**出现异常，被迫进入核心态**；管理程序运行结束时，就退出中断处理程序或异常处理程序，**返回断点处继续执行**

![image-20211102195155388](..\images\image-20211102195155388.png)

在操作系统这一层面上，我们关心的是系统**核心态和用户态的软件实现与切换**

下面列举一些由**用户态转向核心态的例子**：

1. 用户程序要求操作系统的服务，即系统调用
2. 发生一次中断
3. 用户程序中产生了一个错误状态
4. 用户程序中企图执行一条特权指令

从**核心态转向用户态由一条指令实现**，这条指令也是特权命令，一般是**中断返回指令**

注意：由用户态进入核心态，所用的堆栈也**可能需要由用户堆栈切换为系统堆栈**，但这个系统堆栈也是属于该进程的

若程序的运行由用户态转到核心态，则会用到访管指令，**访管指令<u>只能</u>是在用户态使用的**，它**不是特权指令**

注意：系统调用不是操作系统必须提供的功能，有些专业的操作系统，特权指令也会直接提供给用户

## 操作系统结构

### 分层法

分层法是将操作系统分为若干层，最底层为硬件，最高层为用户接口，每层**只能调用紧邻它的低层的功能和服务**

![image-20220702173444013](..\images\image-20220702173444013.png)

分层法的优点：

1. **便于系统的调试和验证，简化了系统的设计和实现**

   可以逐层调试，如果在调试某层时发现错误，那么错误应在这一层上，因为它的低层都调试好了

2. **易扩充和易维护**：改变层内的内容时，只要不改变相应层间的接口，就不会影响其他层

分层法的问题：

1. 合理定义各层比较困难：依赖关系固定后，往往就显得不够灵活
2. **效率较差**：操作系统执行一个功能，要自上而下多次传递，导致系统效率降低

### 模块化

模块化：**将内核划分为多个模块，各模块之间相互协作**

**内核 由 主模块内核 和 可加载内核模块 组成**：

- **主模块：只负责核心功能，如进程调度、内存管理**
- **可加载内核模块：可以动态加载新模块到内核，而无需重新编译整个内核**

模块-接口法：

每个模块具有某方面的管理功能，并规定好各模块间的接口，使各模块之间能够通过接口进行通信

还可以进一步将各模块细分为若干具有一定功能的子模块，同样也规定好各子模块之间的接口

![image-20220702174024346](..\images\image-20220702174024346.png)

在划分模块时：

- 分得太小，能降低复杂性，但会增加模块间的联系，造成系统比较混乱
- 分得过大，会增加复杂性，显然应在两者间进行权衡

划分模块还要考虑模块的独立性问题，独立性越高，各模块间的交互就越少，系统的结构也就越清晰

衡量模块的独立性主要有两个标准：

- 内聚性：模块内部各部分间联系的紧密程度，越高越好
- 耦合度：模块间相互联系和相互影响的程度，越低越好

模块化的优点：

1. 模块间逻辑清晰易于维护，确定模块间接口后即可多模块同时开发
2. **支持动态加载新的内核模块（安装设备驱动程序、安装新的文件系统模块到内核)，增强 OS 适应性**
3. **任何模块都可以直接调用其他模块，无需采用消息传递进行通信，效率高**

模块化的缺点：

1. 模块间的接口定义未必合理、实用
2. 模块间相互依赖，更难调试和验证（不能像分层那样，先确定一部分没问题，再确定另一部分）

### 宏内核

从操作系统的内核架构来划分，可分为宏内核和微内核

![image-20220702175837392](..\images\image-20220702175837392.png)

宏内核、单内核、大内核：将系统的主要功能模块作为一个整体运行在核心态

优点：**高性能**，管理模块间共享信息，能有效利用相互之间的有效特性

缺点：**内核代码庞大，结构混乱，难以维护**，随着体系结构和应用需求的发展，规模急剧增长

目前主流的操作系统，如 Windows 都是基于宏内核的构架，是广泛吸取微内核构架的优点而后揉合而成的混合内核

宏内核构架遇到了越来越多的困难和挑战，而微内核的优势似乎越发明显，如谷歌的 Fuchsia 和华为的鸿蒙 OS

微内核在实时、工业、航空及军事应用中特别流行，这些领域都是关键任务，需要有高度的可靠性

### 微内核

#### 微内核的基本概念

微内核构架：**将内核中最基本的功能保留在内核，非核心的功能移到用户空间**，从而降低内核的设计复杂性，所有新服务都可以在用户空间增加，内核基本不用去做改动

微内核结构的操作系统由微内核和多个服务器组成：

- 微内核：精心设计的、能实现操作系统最基本核心功能的小型内核，通常包含：

  1. 与硬件处理紧密相关的部分
  2. 一些较基本的功能
  3. 客户和服务器之间的通信

- 服务器（进程）：运行在用户态，实现操作系统中的绝大部分功能，如管理进程的进程服务器

  客户与服务器之间是借助微内核提供的消息传递机制来实现交互的

![image-20220702181526561](..\images\image-20220702181526561.png)

在微内核结构中，只有微内核运行在内核态，**一个模块中的错误只会使这个模块崩溃**，而不会使整个系统崩溃

如文件服务代码运行时出了问题，宏内核的系统会直接崩溃，而微内核就把文件服务功能强行停止后重启，继续使用

#### 微内核的基本功能

微内核结构使用“机制与策略分离”的原理来构造 OS 结构，通常具有如下功能：

1. 进程管理：进程间的通信、切换、调度，同步等功能是微内核 OS 最基本的功能，应放入微内核中

   在进程管理中设置一个或多个进程优先级队列，属于调度功能的机制部分，放入微内核

   对用户进程如何分类，以及优先级的确认方式，则属于策略问题，放入进程管理服务器

2. 低级存储器管理：在微内核中，只配置最基本的低级存储器管理机制

   将逻辑地址变换为物理地址等的页表机制和地址变换机制，依赖于硬件，放入微内核

   虚拟存储器管理的策略，如页面置换算法，内存分配与回收的策略，放在存储器管理服务器

3. 中断和陷入处理：将与硬件紧密相关的一小部分放入微内核，主要功能是捕获中断和陷入事件，发送给相关的服务器

微内核操作系统将进程管理、存储器管理以及 I/O 管理这些功能一分为二，属于**机制的很小一部分放入微内核**，而**绝大部分放入微内核外的各种服务器实现**，大多数服务器都要比微内核大

#### 微内核的特点

微内核结构的优点主要有：

1. **内核功能少，结构清晰，方便维护**
2. 扩展、灵活、**可靠**、安全
3. **可移植性**：与 CPU 和 I/O 硬件有关的代码均放在内核中，而其他各种服务器均与硬件平台无关
4. **分布式计算**：CS、SS 之间的通信采用消息传递机制，使得能很好地支持分布式系统和网络系统

缺点：**需要频繁地在核心态和用户态之间切换，性能低**；用户态下的功能模块**只能通过内核的"消息传递"来间接通信**

### 外核

![image-20220702193905975](..\images\image-20220702193905975.png)

**内核负责进程调度、进程通信等功能，外核负责为用户进程分配未经抽象的硬件资源，且由外核负责保证资源使用安全**

优点：

1. **可直接给用户进程分配"不虚拟、不抽象"的硬件资源，使用户进程可以更灵活的使用硬件资源**

2. **减少了虚拟硬件资源的"映射层"，提升效率**（如页表等）

缺点：

1. **降低了系统的一致性**（有的有映射有的没映射）
2. **使系统变得更复杂**

### 总结

![image-20220906191718872](..\images\image-20220906191718872.png)

## 操作系统引导

操作系统引导是指计算机利用 CPU 运行特定程序，通过程序识别硬盘，识别硬盘分区，识别硬盘分区上的操作系统，最后通过程序启动操作系统

![image-20220702210612117](..\images\image-20220702210612117.png)

常见操作系统的引导过程如下：

1. 激活 CPU：激活的 CPU 读取 **ROM 中的 boot 程序**，将指令寄存器置为 BIOS 的第一条指令
2. 硬件自检：进行**硬件自检**，检查硬件是否出现故障，如有故障，启动中止
3. 加载主引导记录 MBR：读取 Boot Sequence **按顺序查找引导盘**，如无启动设备，就会死机
4. 扫描硬盘分区表：主引导记录 MBR **扫描硬盘分区表，找到硬盘活动分区**（有操作系统的分区）
5. 加载分区引导记录 PBR：**读取活动分区的第一个扇区 PBR**
6. 加载启动管理器：分区引导记录 PBR 搜索活动分区中的启动管理器，**加载启动管理器**
7. 加载操作系统

硬盘以特定的标识符区分引导硬盘和非引导硬盘，硬盘分区表以特定的标识符区分活动分区和非活动分区

引导程序分为两种：**位于 ROM 中的自举程序**（BIOS 的组成部分），用于**启动具体的设备**；**位于活动分区的引导扇区中的引导程序**（称为启动管理器），用于**引导操作系统**

## 虚拟机

![image-20220702204244138](..\images\image-20220702204244138.png)

### 第一类虚拟机管理程序

第一类虚拟机管理程序就像一个操作系统，它是运行在最高特权级的程序，在裸机上运行并且具备多道程序功能

**虚拟机管理程序**向上层提供若干台虚拟机，**精确复制裸机硬件**，让**不同的虚拟机可以运行任何不同的操作系统**

虚拟机作为**用户态**的一个进程运行，**不允许执行敏感指令**，其之上的操作系统的内核态，称为**虚拟内核态**

- 当虚拟机操作系统执行了一条 CPU 处于内核态才允许执行的指令时，会陷入虚拟机管理程序
- 在支持虚拟化的 CPU 上，虚拟机管理程序检查这条指令是由虚拟机中的操作系统执行的还是由用户程序执行的
- 如果是前者，虚拟机管理程序将安排这条指令功能的正确执行
- 否则，虚拟机管理程序将模拟真实硬件面对用户态执行敏感指令时的行为

把特权指令分级，VMM 在最高 ring 0 级，只有 ring 0 级的特权指令 VMM 才会检查，ring 1 和 ring 2 级的指令不用管

### 第二类虚拟机管理程序

第二类虚拟机管理程序：依赖于 Windows、Linux 等操作系统分配和调度资源的程序，很像一个普通的进程

第二类虚拟机管理程序仍然伪装成具有 CPU 和各种设备的完整计算机，如 VMware Workstation

运行在两类虚拟机管理程序上的操作系统都称为**客户操作系统**，运行在底层硬件上的操作系统称为**宿主操作系统**

首次启动时，第二类虚拟机管理程序像一台刚启动的计算机那样运转，期望找到的驱动器可以是虚拟设备

然后将操作系统安装到虚拟磁盘上（一个大文件），客户操作系统安装完成后，就能启动并运行

有的教材将第一类虚拟化技术称为裸金属架构，将第二类虚拟化技术称为寄居架构

### 两类间的对比

<img src="..\images\image-20220703202110661.png" alt="image-20220703202110661" style="zoom:150%;" />

# 进程管理

## 进程与线程

### 进程的概念和特征

#### 进程的概念

引入了进程 Process 的概念，以便**更好地描述和控制程序的并发执行**，实现操作系统的并发性和共享性

由**程序段、相关数据段、PCB** 三部分构成了**进程映像（进程实体）**，所谓创建进程，实质上是创建进程映像中的 PCB；而撤销进程，实质上是撤销进程的 PCB，值得注意的是，**进程映像是静态的，进程则是动态的**

系统为**每个运行的程序配置一个数据结构**，称为进程控制块 PCB，用来描述进程的各种信息，PCB 是**进程存在的唯一标志**

引入进程实体的概念后，进程定义为：**进程是进程实体的运行过程，是系统进行资源分配和调度的一个独立单位**

这里说的系统资源，指处理机、存储器、其他设备**服务于某个进程的时间**，处理机资源应理解为**处理机的时间片**

进程是这些资源**分配和调度的独立单位**，即时间片分配的独立单位，这就决定了进程一定是一个**动态的、过程性的概念**

#### 进程的特征

进程是<u>由多道程序的并发执行而引出的</u>，它<u>和程序是两个截然不同的概念</u>

进程的基本特征是对比单个程序的顺序执行提出的，也是对进程管理提出的**基本要求**（只求理解）

1. 动态性：进程是**程序的一次执行**，它**具有一定的生命周期**，是动态地产生、变化和消亡的；是进程**最基本的特征**

2. 并发性：多个**进程实体**同时存于内存中，**能在一段时间内同时运行**，以提高资源利用率；是进程和操作系统的**重要特征**

3. 独立性：指进程实体**是一个能独立运行、获得资源、接受调度的基本单位**；未建立 PCB 的程序，不能作为一个独立的单位参与运行

4. 异步性：由于进程的相互制约，使得进程具有执行的**间断性**，即**进程按各自独立的、不可预知的速度向前推进**

   **异步性会导致执行结果的不可再现性**，为此在操作系统中必须配置相应的进程同步机制

5. 结构性：每个**进程都配置一个 PCB 对其进行描述**，进程实体是由程序段、数据段、进程控制块三部分组成的

### 进程的状态与转换

在进程生命周期内，系统中各进程之间的相互制约关系及系统的运行环境的变化，使得**进程的状态也在不断地发生变化**

通常进程有以下 5 种状态，其中 1~3 种是进程的**基本状态**：

1. 运行态：进程**正在处理机上运行**；单处理机，**<u>最多</u>只有一个**进程处于运行态

2. 就绪态：进程获得了**除处理机外的一切所需资源**，得到处理机后立即运行；将就绪态的进程排成一个队列，称为**就绪队列**

3. 阻塞态，等待态：**进程正在等待某一事件而暂停运行**，如 I/O，即使**处理机空闲，该进程也不能运行**

4. 创建态：进程**正在被创建**，尚未转到就绪态，创建进程通常需要多个步骤：

   1. 申请一个空白的 PCB，并**填写一些控制和管理进程的信息**
   2. 由系统为该进程**分配运行时所必需的资源**
   3. 把该进程**转入就绪态**

   若进程所需的资源不能得到满足，则创建工作尚未完成，处于创建态

5. 结束态：进程正从系统中消失，可能是进程**正常结束或其他原因中断退出运行**

   系统必须**先将该进程置为结束态**，然后进一步**处理资源释放和回收等工作**

注意区别就绪态和等待态：就绪态是指进程**仅缺少处理机**；而等待态是指进程**需要其他资源**

进程在运行过程中**频繁地转换到就绪态**，而进程切换到**等待态的次数就相对较少**（等待态需要时间长）

基本状态之间的转换如下：

![image-20211104142521312](..\images\image-20211104142521312.png)

- 就绪态 → 运行态：**就绪态的进程被调度后**，获得处理机资源，于是进程由**就绪态转换为运行态**

- 运行态 → 就绪态：运行态的进程在**时间片用完后**，不得不**让出处理机**，从而进程由**运行态转换为就绪态**

  **可剥夺的操作系统**中，当有**更高优先级的进程就绪**时，将<u>正在执行的进程转换为就绪态，让更高优先级的进程执行</u>

- 运行态 → 阻塞态：进程**请求某一资源（如外设）的使用**和分配或**等待某一事件的发生**时，它就从**运行态转换为阻塞态**

- 阻塞态 → 就绪态：进程**等待的事件到来时**（I/O 操作或中断结束）**中断处理程序**把相应进程的状态由**阻塞态转换为就绪态**

注意：从运行态变成阻塞态是**主动的**；从阻塞态变成就绪态是**被动的**，需要**其他相关进程的协助**

注意：不一定必须有进程处于运行态，可能所有进程都处于阻塞态，也可能没有进程任务 CPU 空闲

### 进程控制

进程控制的主要功能是**对系统中的所有进程实施有效的管理**，一般使用**原语**来控制进程，下面是进程控制的常用功能：

#### 进程的创建

<u>允许一个进程创建另一个进程，创建者称为父进程，被创建的进程称为子进程，子进程可以**继承父进程所拥有的资源**</u>

当子进程被撤销时，向父进程**归还从父进程获得的资源**；在撤销父进程时，必须**同时撤销其所有的子进程**

在操作系统中，<u>终端用户登录系统、作业调度、系统提供服务、用户程序的应用请求</u>等都会引起**进程的创建**

操作系统创建一个新进程的过程如下（创建原语）：

1. 为新进程**分配唯一的进程标识号**，并**申请一个空白的 PCB**（PCB 是有限的），若 PCB 申请失败，则创建失败
2. 为进程分配资源，为新进程的程序和数据及用户栈**分配必要的内存空间**，若**资源不足会处于创建态**，等待内存资源
3. **初始化 PCB**，主要包括<u>初始化标志信息、初始化处理机状态信息、初始化处理机控制信息、设置进程的优先级</u>等
4. 若进程就绪队列能够接纳新进程，则**将新进程插入就绪队列，等待被调度运行**

选择题：设备分配通过在系统中设置相应的数据结构实现的，不需要创建进程

选择题：父进程可与子进程共享一部分资源，但**不能共享虚拟地址空间**，临界资源一次只能为一**个进程所用**

#### 进程的终止

引起进程终止的事件主要有：

1. 正常结束，表示进程的**任务已完成并准备退出运行**
2. 异常结束，表示进程在运行时，**发生了某种异常事件，使程序无法继续运行**
3. 外界干预，指**进程应外界的请求而终止运行**

操作系统终止进程的过程如下（撤销原语）：

1. 根据被终止进程的标识符，**检索 PCB，读出该进程的状态**
2. 若处于执行状态，立即**终止该进程的执行**
3. 若该进程还有子孙进程，则应**将其所有子孙进程终止**
4. 将该进程所拥有的全部资源，**归还给其父进程或操作系统**
5. 将该 PCB 从所在队列（链表）中**删除**

#### 进程的阻塞和唤醒

正在执行的进程，由于期待的某些事件未发生，由**系统自动执行阻塞原语**由运行态变为阻塞态

进程的阻塞是进程自身的一种**主动行为**，也因此**只有处于运行态的进程**，才可能将其转为阻塞态

阻塞原语的执行过程如下（Block）：

1. 找到将要被**阻塞的进程的标识号对应的 PCB**
2. **保护其现场**，将其状态**转为阻塞态**，停止运行
3. 把该 PCB **插入相应事件的等待队列**，将处理机资源**调度给其他就绪进程**

当**被阻塞进程所期待的事件出现**时，有关进程（**释放设备、提供数据**的进程）调用唤醒原语，**唤醒等待该事件的进程**

唤醒原语的执行过程如下（Wakeup）：

1. 在该事件的等待队列中**找到相应进程的 PCB**
2. 将其从等待队列中移出，并**置其状态为就绪态**
3. 把该 PCB **插入就绪队列**，等待调度程序调度

注意：Block 原语和 Wakeup 原语是一对作用刚好相反的原语，<u>必须成对使用</u>

### 进程的组织

进程是一个**独立的运行单位**，也是操作系统进行**资源分配和调度的基本单位**

不严谨的讲，进程由**程序段、相关数据段、进程控制块**组成，其中最核心的是进程控制块

#### 进程控制块

进程创建时，操作系统为它新建一个 PCB，该结构之后常驻内存，**PCB 是进程实体的一部分，是进程存在的唯一标志**

- 进程执行时，系统**通过 PCB 了解进程的现行状态信息**
- 进程结束时，系统**收回其 PCB，该进程随之消亡**

在进程的**整个生命期**中，系统总是通过 PCB **对进程进行控制**，系统唯有通过进程的 PCB 才能**感知到该进程的存在**：

- 当操作系统欲调度某进程运行时，要从该进程的 PCB 中**查出其现行状态及优先级**
- 调度到某进程后，根据其 PCB 中所保存的处理机状态信息**恢复运行的现场**，根据各段指针**找到其程序和数据**
- 进程在运行过程中，当需要**和与之合作的进程实现同步、通信或访问文件**时，也需要访问 PCB
- 当进程由于某种原因而暂停运行时，又需**将其断点的处理机环境保存在 PCB 中**

下图是一个 PCB 的实例，各部分的主要说明如下：

![image-20211104163851819](..\images\image-20211104163851819.png)

1. 进程描述信息：
   - 进程标识符：标志各个进程，**每个进程的唯一标识号**
   - 用户标识符：**进程归属的用户**，用户标识符主要为共享和保护服务
2. 进程控制和管理信息：
   - 进程当前状态：描述**进程的状态信息**，作为处理机分配调度的依据
   - 进程优先级：描述进程**抢占处理机的优先级**，<u>优先级高的进程可优先获得处理机</u>
3. 资源分配清单：说明有关**内存地址空间或虚拟地址空间的状况**，**所打开文件的列表**和**所使用的输入/输出设备信息**
4. 处理机相关信息：**处理机中各寄存器的值**，当进程被切换时，处理机状态信息都必须保存在相应的 PCB 中

为了方便进程的调控和管理，要将 PCB 组织起来，组织方式有：

- 链接方式：**同一状态的 PCB 链接成一个队列**，不同状态对应不同的队列

  也可把处于阻塞态的 PCB，**根据其阻塞原因的不同，排成多个阻塞队列**

- 索引方式：同一状态的进程**组织在一个索引表中**，索引表的**表项指向相应的 PCB**，不同状态对应不同的索引表

选择题：进程时间片用完时，可降低其优先级以让其他进程被调度进入执行状态；**优先级可能可以决定在就绪队列的排序**

#### 程序段和数据段

**程序段**就是能被进程调度程序调度到 CPU 执行的**程序代码段**，**多个进程可以运行同一个程序**

一个进程的**数据段**，可以是进程对应的程序加工处理的**原始数据**，也可以是程序执行时产生的**中间或最终结果**

### 进程的通信

进程通信是指**进程之间的信息交换**，PV 操作是低级通信方式，高级通信方式是指以**较高的效率传输大量数据**的通信方式：

选择题：进程间的通信是有速度要求的，故不能使用外存的数据库来进行通信，但可以用数据库来交换数据

#### 共享存储

在通信的**进程之间存在一块可直接访问的共享空间**，通过对**这片共享空间进行写/读操作实现进程之间的信息交换**

![image-20211104183654443](..\images\image-20211104183654443.png)

两个进程对共享空间的**访问必须是互斥的**，互斥访问通过操作系统提供的工具实现（如 P、V 操作）

共享存储又分为两种：

- 低级方式的共享是基于数据结构的共享（共享空间的数据形式有所限制）
- 高级方式的共享则是基于存储区的共享

操作系统为通信进程提供**可共享使用的存储空间和同步互斥工具**，而**数据交换则由用户自己安排**读/写指令完成

注意：要想让两个用户进程共享空间，必须通过特殊的**系统调用实现**

#### 消息传递

在消息传递系统中，进程间的数据交换是**以格式化的消息 Message 为单位**的；若不能使用共享空间，就只能使用消息了

进程通过系统提供的**发送消息和接收消息**两个**原语**进行数据交换

1. 直接通信方式：发送进程**直接把消息发送给接收进程**（到消息缓冲队列上），接收进程**从消息缓冲队列中取得消息**

   ![image-20211104185152332](..\images\image-20211104185152332.png)

2. 间接通信方式：发送进程把消息**发送到某个中间实体**，接收进程**从中间实体取得消息**

   这种中间实体一般称为**信箱**，这种通信方式又称**信箱通信方式**，相应的通信系统称为**电于邮件系统**

#### 管道通信

管道（消息传递的一种特殊方式）：**实现读进程和写进程之间通信**的一个**共享文件**，又名 pipe 文件

发送进程**向管道提供输入**，以**字符流**形式将数据送入管道；接收进程**从管道中接收数据**

为了协调双方的通信，管道机制必须提供以下三方面的协调能力：**互斥、同步、确定对方的存在**

在 Linux 中，管道是一种使用<u>非常频繁的通信机制</u>，管道可以克服使用文件进行通信的两个问题，具体表现如下：

1. 管道是一个**固定大小的缓冲区**，在 Linux 中大小为 `4KB`，这使得它的大小不像文件那样**不加检验地增长**

   当把管道**写满后再写将默认地被阻塞**，等待数据被读取，以腾出足够的空间来调用 write() 来写

2. 当把管道**读空后再读将默认地被阻塞**，等待某些数据被写入，这解决了 **read() 调用返回文件结束的问题**

注意：从管道**读数据是一次性操作**，管道只能采用半双工通信，即**某一时刻只能单向传输**，要全双工需要定义**两个管道**

![image-20211104191839713](..\images\image-20211104191839713.png)

进程要访问共享存储空间，则必须**没有其他进程在该共享存储空间中进行写操作**，否则访问行为就会被阻塞

而管道通信中，缓冲区只允许**一边写入、另一边读出**，管道自带同步与互斥机制，<u>写数据的时候不允许读数据，读数据的时候不允许写数据</u>，这是为了解决数据的二义性问题；？**写进程写满，读进程才会读，读进程读到没数据，写进程才会写**？

### 线程概念和多线程模型

#### 线程的基本概念

引入线程的目的是**减小程序在并发执行时所付出的时空开销**，提高操作系统的并发性能

线程最直接的理解就是**轻量级进程**，它是一个基本的 CPU 执行单元，由**线程 ID、程序计数器、寄存器集合、堆栈组成**

线程是进程中的一个实体，是被系统**独立调度和分派的基本单位**，线程自己**不拥有系统资源**，只拥有一点儿在运行中必不可少的资源，但它可与同属一个进程的其他线程**共享进程所拥有的全部资源**

一个线程可以**创建和撤销另一个线程**，同一进程中的**多个线程之间可以并发执行**，线程也有**就绪、阻塞、运行**三种基本状态

引入线程后，进程只作为**除 CPU 外的系统资源的分配单元**，而线程则作为**处理机的分配单元**

选择题：整个系统只有一个键盘，键盘输入是人的操作，速度比较慢，完全可以使用一个线程来处理整个系统的键盘输入

#### 线程与进程的比较

1. 调度：在引入线程的操作系统中，**线程是独立调度的基本单位，进程是拥有资源的基本单位**

   在**同一进程**中，线程的切换**不会引起进程切换**；在**不同进程**中进行线程切换，才**会引起进程切换**

2. 拥有资源：**进程是拥有资源的基本单位**，而线程**不拥有系统资源**（拥有一点），但线程可以**访问其隶属进程的系统资源**

3. 并发性：在引入线程的操作系统中，不仅**进程之间可以并发执行**，而且多个**线程之间也可以并发执行**，从而使操作系统具有更好的并发性，提高了系统的吞吐量

4. 系统开销：由于创建或撤销进程时，系统都要为之分配或回收资源，因此所付出的**开销远大于创建或撤销线程时的开销**

   在进行**进程切换**时，要进行 CPU 环境等的切换**开销大**；**线程切换**时只需保存和设置少量寄存器内容，**开销很小**

   同一进程内的多个线程共享进程的地址空间，**线程之间的同步与通信非常容易实现**，甚至无须操作系统的干预

5. 地址空间和其他资源：**进程的地址空间之间互相独立**，**同一进程的各线程间共享进程的资源**

6. 通信方面：进程间通信需要**进程同步和互斥手段**，以保证数据的一致性，而线程间可以**直接读/写进程数据段**来进行通信

多线程与多任务的区别：多任务代表操作系统可以同时执行的程序个数；多线程代表一个程序可以同时执行的线程个数

#### 线程的属性

多线程操作系统**把线程作为独立运行或调度的基本单位**，进程已不再是一个基本的可执行实体，但仍具有与执行相关的状态

所谓进程**处于执行状态**，实际上是指**该进程中的某线程正在执行**，线程的主要属性如下：

1. 线程是一个轻型实体，每个线程都有**一个唯一的标识符和一个线程控制块**（记录了线程**执行的寄存器和栈等现场状态**）

2. **不同的线程可以执行相同的程序**，即同一个服务程序被不同的用户调用时，操作系统把它们创建成不同的线程

3. 线程是处理机的独立**调度单位**，**多个线程是可以并发执行的**，在单 CPU 的计算机系统中，各线程可**交替**地占用 CPU

   在多 CPU 的计算机系统中，各线程可**同时占用不同的 CPU**，若一个进程占用多个 CPU，则可**缩短进程的处理时间**

4. 一个线程被创建后，便开始了它的生命周期（**阻塞态、就绪态、运行态**），直至终止

线程切换时，可能会发生进程切换，也可能不发生进程切换，**平均每次切换所需的开销就变小了**，就能开更多的线程

#### 线程的状态与转换

线程间存在共享资源和相互合作的制约关系，致使其运行时也具有**间断性**

线程在运行时也具有下面三种基本状态（转换与进程差不多）：

- **执行状态**：线程已获得处理机而正在运行
- **就绪状态**：线程已具备各种执行条件，只需再获得 CPU 便可立即执行
- **阻塞状态**：线程在执行中因某事件受阻而处于暂停状态

#### 线程的组织与控制

##### 线程控制块

系统也为每个线程配置一个**线程控制块 TCB**，用于**记录控制和管理线程的信息**

线程控制块通常包括：

1. 线程标识符，线程的 ID
2. 一组寄存器，包括程序计数器、状态寄存器和通用寄存器
3. 线程运行状态，用于描述线程正处于何种状态
4. 优先级
5. 线程专有存储区，线程切换时用于保存现场等
6. 堆栈指针，用于过程调用时保存局部变量及返回地址等

同进程的线程共享地址空间和全局变量，所以一个线程可以读、写或甚至清除另一个线程的堆栈

##### 线程的创建

线程**由创建而产生，由调度而执行，由终止而消亡**，其控制由系统调用或库函数实现

用户程序启动时，仅有“初始化线程”的线程在执行，用于创建新线程

创建线程时，调用创建函数，提供相应的参数，如程序的入口指针、堆栈的大小、线程优先级等

线程创建函数执行完后，将返回一个线程标识符

##### 线程的终止

当一个线程**完成自己的任务后，或线程运行中出现异常**，则终止线程 调用相应的函数执行终止操作

但是有些线程（系统线程）一旦被建立，便一直运行而不会被终止

线程被终止后并**不立即释放资源**，当其他线程执行了分离函数后，被终止线程才与资源分离，资源才能被其他线程利用

被终止但尚未释放资源的线程仍可被其他线程调用，以使**被终止线程重新恢复运行**

#### 线程的实现方式

![image-20211104194842591](..\images\image-20211104194842591.png)

##### 用户级线程 ULT

用户级线程中，有关线程管理的所有工作都由应用程序（使用线程库）在用户空间中完成，**内核意识不到线程的存在**

应用程序从单线程开始，在其运行的任何时刻，可以调用线程库中的派生例程创建一个新线程

对于用户级线程，**处理机的分配是以进程为单位**，无论该进程里面有多少个线程，都只能执行一个时间片

优点：

1. 线程切换**不需要转换到内核空间**，节省了模式切换的开销
2. 调度算法可以是进程专用的，**不同的进程可以选择不同的线程调度算法**
3. **用户级线程的实现与操作系统平台无关**，对线程管理的代码是属于用户程序的一部分

缺点：

1. **系统调用的阻塞问题**，当线程执行一个系统调用时，不仅该线程被阻塞，而且**进程内的所有线程都被阻塞**
2. **不能发挥多处理机的优势**，内核每次分配给一个进程的仅有一个 CPU，进程中仅有一个线程能执行

##### 内核级线程 KLT

线程管理的所有工作也是在内核空间内实现的，内核空间也为每个内核级线程设置一个线程控制块，用于线程控制

优点：

1. 能发挥多处理机的优势，内核能同时调度同一进程中的**多个线程并行执行**
2. 如果进程中的一个线程被阻塞，内核可以**调度其他线程（本进程或其他进程）占用处理机**
3. 内核支持线程具有很小的数据结构和堆栈，**线程切换比较快、开销小**
4. 内核本身也可采用多线程技术，可以**提高系统的执行速度和效率**

缺点：同进程的线程切换，要从用户态转到核心态进行，**系统开销较大**（线程的运行在用户态，调度和管理在内核态）

##### 组合方式

组合方式：内核支持多个内核级线程的建立、调度和管理，同时允许用户程序建立、调度和管理用户级线程

如把 5 个用户级线程，通过时分多路复用 3 个内核级线程，能结合 KLT 和 ULT 的优点，并克服各自的不足

---

线程库是为程序员提供创建和管理线程的 API，实现线程库主要的方法有如下两种：

1. <u>在用户空间中提供一个没有内核支持的库</u>，调用库内的一个函数只导致用户空间中的一个本地函数的调用
2. <u>实现由操作系统直接支持的内核级的一个库</u>，调用库中的一个 API 函数通常会导致对内核的系统调用

目前使用的三种主要线程库是：`POSIX Pthreads`、Windows API、Java

1. `Pthreads` 作为 `POSIX` 标准的扩展，可以提供用户级或内核级的库（类 UNIX 系统的线程库）
2. Windows 线程库是用于 Windows 操作系统的内核级线程库
3. Java 线程 API 允许线程在 Java 程序中直接创建和管理，通常采用宿主系统的线程库来实现

#### 多线程模型

![image-20220704181200871](..\images\image-20220704181200871.png)

有些系统同时支持用户线程和内核线程，由此产生了不同的多线程模型，即实现用户级线程和内核级线程的连接方式

1. 多对一模型：**多个用户级线程映射到一个内核级线程**，线程管理在用户空间完成，**用户级线程对操作系统不可见**

   优点：线程管理是在用户空间进行的，因而**调度效率比较高**

   缺点：**一个线程在使用内核服务时被阻塞，整个进程都会被阻塞**；多个线程不能并行地运行在多处理机上

2. 一对一模型：**每个用户级线程映射到一个内核级线程**

   优点：当一个线程被阻塞后，允许另一个线程继续执行，所以**并发能力较强**

   缺点：每**创建一个用户级线程都需要创建一个内核级线程**，这样创建线程的**开销比较大**，会影响到应用程序的性能

3. 多对多模型。将 **n 个用户级线程映射到 m 个内核级线程上，要求 m ≤ n**

   特点：多对多模型是**多对一模型和一对一模型的折中**，既克服两者的缺点，还拥有两者各自的优点

## 处理机调度

### 调度的概念

#### 调度的基本概念

在多道程序系统中，<u>进程的数量往往多于处理机的个数</u>，因此进程争用处理机的情况在所难免

处理机调度是**对处理机进行分配**，即从就绪队列中按照一定的算法选择一个进程并将处理机分配给它运行

处理机调度是**多道程序操作系统的基础**，是操作系统设计的**核心问题**

#### 调度的层次

一个作业从提交开始直到完成，往往要经历以下三级调度（注意理解图片）：

![image-20211105195656691](..\images\image-20211105195656691.png)

##### 作业调度

又称**高级调度**，按一定的原则从**<u>外存上</u>处于后备状态**的作业中**挑选一个或多个作业**，给它**分配**内存、输入/输出设备等必要的资源，并**建立相应的进程**，并送入就绪队列，以使它**获得竞争处理机的权利**；对于每个作业**只调入一次、调出一次**

多道批处理系统中大多配有作业调度，而其他系统中通常不需要配置作业调度

作业调度的**执行频率较低**，通常为几分钟一次

额外：通常把**用户要求计算机完成的这一串任务称为作业**，作业运行时会创建一个或多个进程

##### 内存调度

又称**中级调度**，其作用是**提高内存利用率和系统吞吐量**

将那些**暂时不能运行的进程调至外存等待**（PCB 不会被调出），把此时的进程状态称为**挂起态**

当它们已**具备运行条件且内存又稍有空闲**时，由中级调度把外存上的进程**重新调入内存**，并**设置好设置为就绪态所需**

理解：内存不够时，把暂时不用的进程调出内存，再加载新进程来运行；等内存宽松时，再把可运行的已挂载的进程唤醒

##### 进程调度

又称**低级调度**，按照某种方法和策略**从就绪队列中选取一个进程，改状态为运行态，并将处理机分配给它**

进程调度是操作系统中**最基本的一种调度**，在一般的操作系统中都**必须配置进程调度**

进程调度的**频率很高**，一般几十毫秒一次

#### 三级调度的联系

1. 作业调度**为进程活动做准备**，进程调度**使进程正常活动起来**，中级调**度将暂时不能运行的进程挂起**
2. 中级调度处于作业调度和进程调度之间
3. <u>作业调度次数少，中级调度次数略多，进程调度频率最高</u>
4. 进程调度是**最基本的，不可或缺的**

### 调度的实现

#### 调度程序（调度器）

调度程序：在 OS 中，用于调度和分派 CPU 的组件，由三部分组成

![image-20220705220008150](..\images\image-20220705220008150.png)

1. 排队器：将系统中的所有就绪进程按照一定的策略排成<u>一个或多个队列</u>，以便于调度程序选择

2. 分派器：依据调度程序所选的进程，将其<u>从就绪队列中取出，将 CPU 分配给新进程</u>

3. 上下文切换器：在对处理机进行切换时，会发生两对上下文的切换操作

   第一对，将当前进程的上下文保存到其 PCB 中，再<u>装入分派程序的上下文</u>，以便分派程序运行

   第二对，移出分派程序的上下文，<u>将新选进程的 CPU 现场信息装入处理机的各个相应寄存器</u>

在上下文切换时，需要执行大量 load 和 store 指令，以保存寄存器的内容，因此会花费较多时间

通常采用两组寄存器，其中一组供内核使用，一组供用户使用，上下文切换时，指向要使用的寄存器组即可

思考：进程切换由内核的进程实现，所以多搞一套寄存器，切换到内核进程进行进程调度更加简单

#### 调度的时机、切换与过程

<u>请求调度的事件发生后，才可能运行进程调度程序，调度了新的就绪进程后，才会进行进程间的切换</u>

现代操作系统中，**不能进行进程的调度与切换的情况**有以下几种：

1. 在**处理中断的过程中**：中断处理是系统工作的一部分，<u>逻辑上不属于某一进程，不应被剥夺处理机资源</u>

2. 进程**在操作系统内核程序临界区中**：进入操作系统内核临界区后，需要**独占式地访问共享数据**，在**解锁前不应切换到其他进程运行**，以加快该共享数据的释放

   注意：**普通临界区可以进行处理机调度**，在普通临界区中处理器是不用的，如打印机；而在内核临界区中处理机仍然要用，如访问就绪队列；**临界区：访问临界资源的那段代码**

3. 其他需要完全屏蔽中断的**原子操作过程中**：在原子过程中，连中断都要屏蔽，更不应该进行进程调度与切换

若在上述过程中发生了引起调度的条件，应**置上系统的请求调度标志**，直到**上述过程结束后才进行相应的调度与切换**

应该进行进程调度与切换的情况如下：

1. **发生引起调度条件**且**当前进程无法继续运行下去**时，可以马上进行调度与切换
2. 中断处理或自陷处理结束后，**返回用户态程序执行现场前**，若**置上请求调度标志**，则进行进程调度与切换

进程切换**在调度完成后立刻发生**，切换时内核把**原进程现场信息放入其内核的堆栈**，并用**新进程的内核堆栈恢复现场信息**

#### 进程调度方式

指当某个进程正在处理机上执行时，若有**优先权更高的进程进入就绪队列**，此时**应如何分配处理机**

通常有以下两种进程调度方式：

##### 非剥夺调度方式

又称**非抢占方式**：**仍然执行当前进程**，直到该进程**结束或进入阻塞态**时，才**把处理机分配给更为重要或紧迫的进程**

非剥夺调度方式下，进程拿到 CPU 后就会**保持 CPU 直到终止或转换到等待态**

这种方式的优点是实现简单、系统开销小，适用于大多数的批处理系统，但它<u>不能用于分时系统和大多数的实时系统</u>

##### 剥夺调度方式

又称**抢占方式**：立即**暂停正在执行的进程**，将处理机**分配给这个更为重要或紧迫的进程**

采用剥夺式的调度，对**提高系统吞吐率和响应效率都**有明显的好处

**剥夺必须遵循一定的原则**，主要有优先权、短进程优先、时间片原则等

#### 闲逛进程

在进程切换时，如果**系统中没有就绪进程，就会调度闲逛进程 idle 运行**，并在执行过程中测试中断

闲逛进程的优先级最低，没有就绪进程时才会运行闲逛进程，只要<u>有进程就绪，就会立即让出处理机</u>

闲逛进程<u>不需要 CPU 之外的资源</u>，它不会被阻塞

#### 两种线程的调度

1. 用户级线程调度：仅选择一个进程，并给予时间控制，由进程中的调度程序决定哪个线程运行
2. 内核级线程调度：内核选择一个特定线程运行，赋予一个时间片，通常不用考虑该线程属于哪个进程

用户级线程的线程切换在同一进程中进行，仅需少量的机器指令；内核级线程的线程切换可能需要完整的上下文切换、修改内存映像、使高速缓存失效，这就导致了若干数量级的延迟

### 调度的基本准则

下面介绍主要的几种**比较处理机调度算法的性能准则**：

1. CPU 利用率 = $\dfrac{CPU有效工作时间}{CPU有效工作时间+CPU空闲等待时间}$：应尽可能使 CPU 保持忙状态，使 CPU 资源利用率最高

2. 系统吞吐量：表示**单位时间内 CPU 完成作业的数量**；调度算法和方式的不同，会对系统的吞吐量产生较大的影响

   <u>长作业执行时间长，系统的吞吐量小；短作业执行时间短，系统的吞吐量大</u>

3. 周转时间：周转时间是指**从作业提交到作业完成所经历的时间**

   - **周转时间** = 作业完成时间 - 作业提交时间
   - **平均周转时间** = (作业 1 的周转时间 + … + 作业 n 的周转时间) / n
   - **带权周转时间** = $\dfrac{作业周转时间}{作业实际运行时间}$
   - **平均带权周转时间** = (作业 1 的带权周转时间 + .…. + 作业 n 的带权周转时间) / n

4. 等待时间：**进程处于等处理机状态的时间之和**，等待时间越长，用户满意度越低

   处理机调度算法只影响**作业在就绪队列中等待所花的时间**；因此衡量一个调度算法的优劣，**只需简单地考察等待时间**

5. 响应时间：从**用户提交请求到系统首次产生响应所用的时间**

   在<u>交互式系统中，一般采用响应时间作为衡量调度算法的重要准则之一</u>

   从用户角度来看，调度策略应尽量降低响应时间，使**响应时间处在用户能接受的范围之内**

得到一个满足所有用户和系统要求的算法几乎是不可能的，设计调度程序要考虑：

<u>① 特定系统用户的要求；② 系统整体效率；③ 调度算法的开销</u>

### 典型的调度算法

#### 先来先服务 FCFS 调度算法

FCFS 是最简单的调度算法，它**属于不可剥夺算法**，它既可用于作业调度，又可用于进程调度：

- 作业调度：从后备作业队列中选择**最先进入该队列的一个或几个作业**，对它们进行作业调度
- 进程调度：从就绪队列中选择**最先进入该队列的进程**，对它进行进程调度

系统中有 4 个作业，它们的提交时间分别是 8、8.4、8.8、9，运行时间依次是 2、1、0.5、0.2，性能为下表

![image-20211105214442218](..\images\image-20211105214442218.png)

若一个长作业先到达系统，就会使后面的许多短作业等待很长时间，因此它**不能作为分时系统和实时系统的主要调度策略**

FCFS 调度算法的特点：

1. 算法简单，但效率低
2. **对长作业比较有利，但对短作业不利**
3. **有利于 CPU 繁忙型作业，而不利于 I/O 繁忙型作业**

#### 短作业优先 SJF 调度算法

- 短作业优先：从**后备队列**中选择一个或若干**估计运行时间最短的作业**，将它们调入内存运行
- 短进程优先：从**就绪队列**中选择一个**估计运行时间最短的进程**，进行进程调度

使用 FCFS 的例子的数据，来描述 SJF 算法的性能：

![image-20211105214515620](..\images\image-20211105214515620.png)

SJF 调度算法也存在不容忽视的缺点：

1. SJF 调度算法中长作业的周转时间会增加，**对长作业不利**；更严重的是，可能导致**长作业长期不被调度饥饿现象**
2. 该算法完全**未考虑作业的紧迫程度**，因而不能保证紧迫性作业会被及时处理
3. 由于作业的长短只是根据用户所提供的**估计执行时间**而定的，致使该算法**不一定能真正做到短作业优先调度**

注意：**SJF 调度算法的平均等待时间、平均周转时间最少**

#### 优先级调度算法

又称优先权调度算法，该算法中的优先级用于描述**作业运行的紧迫程度**

- 作业调度：从后备作业队列中选择**优先级最高的一个或几个作业**，进行作业调度
- 进程调度：从就绪队列中选择**优先级最高的进程**，进行进程调度

当有更急迫的进程进入就绪队列时，有两种优先级调度算法：

1. 非剥夺式优先级调度算法：**仍然运行当前进程，直到其主动让出处理机**时，才把处理机分给更急迫的进程
2. 剥夺式优先级调度算法：**立即暂停当前进程**，把处理机分给更急迫的进程

根据进程创建后其优先级是否可以改变，可以分为：

1. 静态优先级：优先级是**在创建进程时确定的**，且在进程的**整个运行期间保持不变**

   确定静态优先级的主要依据：<u>进程类型、进程对资源的要求、用户要求</u>

2. 动态优先级：在进程运行过程中，**根据进程情况的变化动态调整优先级**

   动态调整优先级的主要依据：<u>进程占有 CPU 时间的长短、就绪进程等待 CPU 时间的长短</u>

一般来说，进程优先级的设置可以参照以下原则：

1. **系统进程 > 用户进程**
2. **交互型进程 > 非交互型进程**（或前台进程 > 后台进程）
3. **I/O 型进程 > 计算型进程**，若 I/O 型进程的优先级更高，I/O 设备就更早开始工作，进而提升系统的整体效率

#### 高响应比优先调度算法 HRRN

**主要用于作业调度**，是对 FCFS 和 SJF 的一种**综合平衡**，考虑了每个作业的**等待时间**和**估计的运行时间**

<u>在每次进行作业调度时，先计算后备作业队列中每个作业的响应比，从中**选出响应比最高的作业投入运行**</u>

响应比的变化规律可描述为：$响应比 R_p=\dfrac{等待时间+要求服务时间}{要求服务时间}$

根据公式可知：

1. 等待时间相同时，要求服务时间越短，响应比越高，**有利于短作业**
2. <u>要求服务时间相同时，响应比由其等待时间决定</u>，因此**它实现的是先来先服务**
3. 对于长作业，<u>等待时间足够长时也可获得处理机</u>，**因此克服了饥饿状态，兼顾了长作业**

#### 时间片轮转 RR 调度算法

就绪进程**按时间的先后次序排成一个队列**，总选择就绪队列的**第一个进程执行**（FCFS 原则）且**仅运行一个时间片**

使用完一个时间片后，它**<u>必须释放</u>出处理机给下一个进程**，然后**回到就绪队列的末尾重新排队**，等候再次运行

这种算法**主要适用于分时系统**，在时间片轮转调度算法中，**时间片的大小对系统性能的影响很大**：

- 时间片足够大：**所有进程都能在一个时间片内执行完毕**，就相当于先来先服务调度算法
- 时间片很小：处理机在进程间**过于频繁地切换**，而切换进程需要时间，导致用于运行用户进程的时间变小

时间片的长短通常由以下因素确定：**系统的响应时间、就绪队列中的进程数目、系统的处理能力**

应用题：一个进程的时间片用完了，先开始计时下一个时间片，再进行进程的调度和切换（时钟每隔一定时间发生中断）

#### 多级队列调度算法

系统中按进程类型设置多个队列，进程创建成功后插入某个队列

![image-20220708200521330](..\images\image-20220708200521330.png)

**队列之间可采取固定优先级，或时间片划分**：

- 固定优先级：高优先级空时，低优先级进程才能被调度
- 时间片划分：如三个队列分配时间 50%、40%、10%

**各队列可采用不同的调度策略**，如：

- 系统进程队列采用优先级调度
- 交互式队列采用时间片轮转 RR
- 批处理队列采用先来先服务 FCFS

运行时：先根据队列间的调度算法，选取队列，在根据队列内的算法选择进程

#### 多级反馈队列调度算法

多级反馈队列调度算法是<u>时间片轮转调度算法、优先级调度算法的综合与发展</u>

通过**动态调整进程优先级和时间片大小**，多级反馈队列调度算法**可以兼顾多方面的系统目标**：

1. 为提高系统吞吐量和缩短平均周转时间，而照顾短进程
2. 为获得较好的 I/O 设备利用率和缩短响应时间，而照顾 I/O 型进程

![image-20211105214701715](..\images\image-20211105214701715.png)

多级反馈队列调度算法的实现思想如下：

1. **设置多个就绪队列，并为各个队列赋予不同的优先级**，如第 1 级队列的优先级最高，第 2 级队列次之

2. **各队列的时间片大小各不相同**，在优先级越高的队列时间片越小

   如 <u>i + 1 级队列的时间片要比 i 级队列的时间片长 1 倍</u>

3. **每个队列使用的调度算法可以不一样**，如前面的队列是 FCFS，最后一级队列是时间分片轮询调度

   新进程首先放入 1 级队列；若它<u>不能在该时间片内完成，就放入 2 级队列</u>；但最后一级队列放回最后一级

4. **仅当第 1 级队列为空时，调度程序才调度第 2 级队列中的进程运行**

   有新进程进入优先级较高的队列，则<u>新进程将抢占正在运行进程的处理机</u>，**当前进程放回当前队列**

**多级反馈队列的优势有以下几点**：

1. 终端型作业用户：短作业优先
2. 短批处理作业用户：周转时间较短
3. 长批处理作业用户：经过前面几个队列得到部分执行，不会长期得不到处理

#### 总结

![image-20220705220217966](..\images\image-20220705220217966.png)

### 进程切换

任何进程都是在**操作系统内核的支持下运行的**，是与内核紧密相关的

#### 上下文切换

切换进程需要**保存当前进程状态到其 PCB 中，然后加载经调度而要执行的新进程的上下文**，这个任务称为**上下文切换**

上下文切换是指处理机**从一个进程的运行转到另一个进程上运行**，进程的**运行环境产生了实质性的变化**

上下文切换的流程如下：

1. **挂起一个进程，保存 CPU 上下文**，包括程序计数器和其他寄存器
2. 更新 PCB 信息
3. 把进程的 PCB **移入相应的队列**，如就绪、在某事件阻塞等队列
4. **选择另一个进程执行**，并更新其 PCB
5. 跳转到新进程 PCB 中的程序计数器所指向的位置执行
6. **恢复处理机上下文**

注意：调度和切换的区别：

- 调度：**决定**资源分配给哪个进程的行为，是一种决策行为
- 切换：**实际**分配的行为，是执行行为

一般来说，**先有资源的调度，然后才有进程的切换**

#### 上下文切换的消耗

上下文切换通常是计算密集型的，每秒要进行几十上百次的纳秒量级的切换，对系统来说意味着消耗大量的 CPU 时间

有些处理器提供多个寄存器组，上下文切换就只需要简单改变当前寄存器组的指针

#### 上下文切换与模式切换

模式切换与上下文切换是不同的，模式切换时，CPU 逻辑上**可能还在执行同一进程**

用户态和内核态之间的切换称为模式切换，**没有改变当前的进程**（没有改变环境信息），上下文切换只能发生在**内核态**

## 进程同步

### 进程同步的基本概念

在多道程序环境下，进程是并发执行的，不同进程之间存在着<u>不同的相互制约关系</u>，而**进程同步用于协调进程间的制约关系**

同步即制定一定的机制去约束一个进程的某个任务，让它在另一个进程完成某个任务之后才发生

注意：多个线程**访问同一个全局变量的时候可以同时读**，但**不能一写一读，或者两个写**（进程也一样）

#### 临界资源

我们将**一次仅允许一个进程使用的资源称为临界资源**，如打印机等物理设备，和可以被若干进程共享的变量、数据等

对临界资源的访问，**必须互斥地进行**，为了保证临界资源的正确使用，可把临界资源的访问过程分成 4 个部分：

1. 进入区：先**检查可否进入临界区**，若能进入临界区，则<u>设置正在访问临界区的标志，以阻止其他进程同时进入临界区</u>
2. 临界区：进程中**访问临界资源的那段代码**，又称临界段
3. 退出区：**清除正在访问临界区的标志**
4. 剩余区：代码中的其余部分

```c
do {
    entry section;  // 进入区
    critical section;  // 临界区
    exit section;  // 退出区
    remainder section;  // 剩余区
} while (true);
```

#### 同步

同步亦称**直接制约关系**，是指为多个进程**为需要在某些位置上协调它们的工作次序而等待**

进程间的直接制约关系源于它们之间的相互合作

例如，进程 A 的 a 任务必须在进程 B 的 b 任务之后，那么进程 A 运行到 a 时就要等待进程 B 运行完 b 才继续运行

#### 互斥

互斥也称**间接制约关系**，<u>当一个进程进入临界区使用临界资源时，另一个进程必须等待直到它退出临界区</u>

例如，程序 A 在使用一个临界资源，这时程序 B 也要使用，那么程序 B 就要等程序 A 用完了才能使用

思考：同步是解决任务先后顺序的问题；互斥是解决两个任务不能同时进行的问题

#### 同步准则

为禁止两个进程同时进入临界区，同步机制应遵循以下准则：

1. **空闲让进**：临界区空闲时，可以允许一个请求进入临界区的进程立即进入临界区
2. **忙则等待**：当已有进程进入临界区时，其他试图进入临界区的进程必须等待
3. **有限等待**：对请求访问的进程，应保证**能在有限时间内进入临界区**
4. **让权等待**：当进程**不能进入临界区时，应立即释放处理器**，防止进程忙等待

### 实现临界区互斥的基本方法

#### 软件实现方法

在进入区检查及设置标志，退出区修改标志的方法达到互斥，下面有介绍 4 种算法：

##### 单标志法

该算法设置一个公用整型变量 turn，用于**指示被允许进入临界区的进程编号**，即若 turn = 0，则允许 $P_0$ 进程进入临界区

该算法**可确保每次只允许一个进程进入临界区**，但两个进**程必须交替进入临界区**

若 $P_0,P_1,P_1$ 的顺序进入，那么第二次 $P_1$ 进入时会被卡住，违背了空闲让进

![image-20211107160220889](..\images\image-20211107160220889.png)

##### 双标志法先检查

算法的基本思想：<u>在每个进程访问临界区资源之前，先查看临界资源是否正被访问，访问则等待；否则进入临界区</u>

设置一个数据 flag[i]，其第 i 个元素表示 $P_i$ 进程是否进入了临界区，TRUE 已为入临界区

![image-20211107160335963](..\images\image-20211107160335963.png)

优点：不用交替进入，可连续使用

缺点：**可能同时进入临界区**，按如序列 1234 执行时，会同时进入临界区**违背忙则等待**

##### 双标志法后检查

算法基本思想：<u>先将自己的标志设置为 TRUE，再检测对方的状态标志</u>

![image-20211107160449801](..\images\image-20211107160449801.png)

**两个进程几乎同时都想进入临界区时**，双方会互相谦让，结果**谁也进不了临界区**，从而导致饥饿现象

##### Peterson's Algorithm

使用**单标志的思想实现一次只能进一个进程**，使用**双标志后检查的思想实现不用交替进入**，本算法就是这**两个的结合**

![image-20211107160607518](..\images\image-20211107160607518.png)

为了防止双标志后检查的饥饿现象，加入了 turn 变量，<u>利用 turn 总会设置成另一个值，来谦让另一个进程先行</u>

具体：两进程同时进入，且同时设置各自的 flag 为 TRUE；$P_i$ 设置 turn = i 后进入 while 阻塞，$P_j$ 设置 turn = j 后 $P_i$ 就跳出了 while 循环，而 $P_j$ 进入 while 循环，当 $P_i$ 完成后设置 flag 为 FALSE，$P_j$ 也跳出 while

#### 硬件实现方法

通过硬件支持实现临界段问题的方法称为低级方法，或称元方法

##### 中断屏蔽方法

**防止两个进程同时进入临界区**的最简方法是：**禁止一切中断发生**，或称之为屏蔽中断、关中断

**CPU 只在发生中断时引起进程切换**，因此**屏蔽中断能够保证当前进程不会被切换**，进而保证互斥的正确实现

```c
:
关中断;
临界区;
开中断;
:
```

这种方法**限制了处理机交替执行程序的能力**，因此执行的效率会明显降低（中间的临界区不能切换进程）

在**多处理器中，仍会出现两个进程同时进入临界区**，一个处理器运行关中断代码并不影响其他处理器切换进程

使用关中断来更新变量很方便，但**不能将关中断的权力交给用户**，若关中断后不再开中断，则系统可能会因此终止

注意：这里只是假设，**用户并不能使用开/关中断实现互斥**，因为开/关中断指令是特权指令，不能让用户直接访问

##### 硬件指令方法

###### `TestAndSet` 指令

`TSL` 指令利用硬件实现的这条指令是原子操作，即执行该代码时不允许被中断，逻辑代码为：

```java
boolean TestAndset (boolean *lock) {
    boolean old;
    old = *lock;
    *lock = true;
    return old;
}
```

利用 `TestAndSet` 指令实现进程互斥的算法描述如下：

```c
// 共享 bool 变量 lock 初始值 false
while TestAndSet(&lock);  // 若 lock 空闲(为 false 时)，lock->true,ret false 跳出循环
进程的临界区代码段;
lock = false;
进程的其他代码;
```

###### Swap 指令

汇编 `XCHG` 的功能是交换两个字（字节）的内容，逻辑代码为：

```java
Swap (boolean *a, boolean *b) {
    boolean temp;
    temp = *a;
    *a = *b;
    *b = temp;
}
```

注意：`TestAndSet` 和 Swap 指令是**由硬件直接实现的，不会被中断**，上面只是逻辑功能

利用 `Swap` 指令实现进程互斥的算法描述如下：

```c
// 共享 bool 变量 lock 初始值 false
key = true;
while (key != false)  // 若 lock 空闲，swap 后 key->false,lock->true 跳出循环
	Swap (&lock, &key);
进程的临界区代码段;
lock = false;
进程的其他代码;
```

------

硬件方法的优点：

1. 适用于**任意数目的进程**，且不管是**单处理机还是多处理机**
2. 简单、容易验证其正确性
3. **支持进程内有多个临界区**，只需为每个临界区设立一个布尔变量

硬件方法的缺点：

1. 进程等待进入临界区时要耗费处理机时间，**不能实现让权等待**（软件方法也一样）
2. 从等待进程中**随机选择一个进入临界区**，有的进程可能**一直选不上**，从而导致饥饿现象

无论是软件实现方法还是硬件实现方法，读者只需理解它的执行过程即可，**关键是软件实现方法**

### 互斥锁

使用互斥锁 mutex lock 来解决临界区，**一个进程在进入临界区时应获得锁，在退出临界区时释放锁**

当一个进程试图获取不可用的锁时，会被阻塞，直到锁被释放

```c
acquire() {  // 获得锁
    while(!available);  // 忙等待
    available = false;  // 获得锁
}

release() {  // 释放锁
	available = true;  // 释放锁
}
```

acquire() 或 release() 的执行必须是原子操作，因此互斥锁通常采用硬件机制来实现

互斥锁的主要缺点是<u>忙等待</u>，当多个进程共享同一 CPU 时，就浪费了 CPU 周期

互斥锁通常用于多处理器系统，一个线程可以在一个处理器上等待，不影响其他线程的执行

### 信息量

信号量只能被**两个标准的原语 wait(S) 和 signal(S)** 访问，也可记为 Р 操作和 V 操作，**用于解决进程同步与互斥问题**

若能够找到一种解决临界区问题的元方法，就可以实现对共享变量操作的原子性

#### 整型信号量

整型信号量被定义为一个<u>用于表示资源数目的整型量 S</u>，wait 和 signal 操作可描述为：

```c
wait(S) {
	while (S <= 0);
    S = S - 1;
}

signa1(S) {
	S = S + 1;
}
```

该机制并未遵循让权等待的准则，而是**使进程处于忙等的状态**

#### 记录型信号量

记录型信号量是**不存在忙等现象**的进程同步机制，记录型信号量得名于采用了记录型的数据结构：

```c
typedef struct {
    int value;  // 代表资源数目
    struct process *L;  // 进程链表，用于链接所有等待该资源的进程
} semaphore;
```

相应的 wait(S) 和 signal(S) 的操作如下：

```c
void wait(semaphore S) {  // 相当于申请资源
    S.value--;  // 进程请求一个该类资源
    if(S.value < 0) {  // 若该类资源已分配完毕
        add this process to S.L;  // 插入该类资源的等待队列
	    block(S.L);  // 自我阻塞，放弃处理机
    }
}

void signal(semaphore S)(  // 相当于释放资源
    S.value++;  // 进程释放一个资源
    if (S.value <= 0) {  // 若仍有等待该资源的进程被阻塞
        remove a process P from S.L;  // 弹出 S.L 的第一个进程
        wakeup(P);  // 唤醒弹出的进程
    }
}
```

由于调用了 block 方法自我阻塞，可见该机制**遵循了让权等待的准则**；思考：当 value 为 -k 时，就表示有 k 个进程在等待

#### 利用信号量实现同步

设 S 为实现进程 $P_1,P_2$ 同步的公共信号量，初值为 0；其中 P 和 V 就是上面的 wait 和 signal

当 `P1` 进程的 x 执行完后才可以执行 `P2` 进程的 y，其实现进程同步的算法如下：

```c
semaphore S = 0;
// 初始化信号量
P1() {
    X;
    V(S);  // 告诉进程 P2，语句 x 已经完成
    …
}

P2() {
    …
	P(S);  // 检查语句 x 是否运行完成
    y;  // 检查无误，运行 y 语句
    …
}
```

注意：同步时，**初始信号量不一定是 0**，如生产者消费者，它的信号量初始信号量就是 N

#### 利用信号量实现进程互斥

由于可用资源数为 1，所以 S 的**初值应为 1**，**只需把临界区置于 P(S) 和 V(S) 之间，即可实现互斥**，其算法如下：

```c
semaphore S = 1;  // 初始化信号量
P1() {
    …
    P(S);  // 准备开始访问临界资源，加锁
    进程 P1 的临界区;
    V(S);  // 访问结束，解锁
    …
}
P2() {
    …
    P(S);  // 准备开始访问临界资源，加锁
    进程 P2 的临界区;
    V(S);  // 访问结束，解锁
    …
}
```

下面简单总结一下 PV 操作在同步互斥中的应用：

- 同步问题：在要**用到某种资源前进行 P 操作**；在**提供某种资源后进行 V 操作**
- 互斥问题：**PV 操作要紧夹使用互斥资源的那个行为**，中间不能有其他冗余代码

#### 利用信号量实现前驱关系

使用信号量来描写下图的前驱关系，其实就是**多重同步的关系**，为每个向量设置一个信号量就可以

![image-20211107203715705](..\images\image-20211107203715705.png)

实现算法如下：

```c
semaphore a1 = a2 = b1 = b2 = c = d = e = 0;  // 初始化信号量
S1() {
    …;
    v(a1); V(a2);  // S1 已经运行完成
}
S2() {
    P(a1);  // 检查 S1 是否运行完成
    …;
    V(b1); V(b2);  // S2 已经运行完成
}
s3() {
    P(a2);  // 检查 S1 是否已经运行完成
    …;
    V(c);  // S3 已经运行完成
}
S4() {
    P(b1);  // 检查 S2 是否已经运行完成
    …;
    V(d);  // S4 已经运行完成
}
S5() {
    P(b2);  // 检查 S2 是否已经运行完成
    …;
    v(e);  // S5已经运行完成
}
S6() {
    P(c);  // 检查 S3 是否已经运行完成
    P(d);  // 检查 S4 是否已经运行完成
    P(e);  // 检查 S5 是否已经运行完成
    …;
}
```

#### 分析问题的方法步骤

1. 关系分析：找出问题中的进程数，并**分析它们之间的同步和互斥关系**，参照上面例子的范式改写
2. 整理思路：找出解决问题的关键点，**根据进程的操作流程确定 Р 操作、V 操作的大致顺序**
3. 设置信号量：根据上面的两步，**设置需要的信号量，确定初值，完善整理**

### 管程

在信号量机制中，大量分散的同步操作给系统管理带来了麻烦，且容易因同步操作不当而导致系统死锁，因此管程诞生了

#### 管程的定义

系统中的各种硬件资源和软件资源，均可用数据结构抽象地描述其资源特性，即<u>用少量信息和对资源所执行的操作来表征该资源，而忽略它们的内部结构和实现细节</u>

管程 monitor 是由**一组数据**以及定义在这组数据之上的**对这组数据的操作**组成的**软件模块**，这组操作能**初始化和改变管程中的数据**以及**同步进程**

由上述定义可知，管程由 4 部分组成：

1. 管程的**名称**
2. 局部于管程内部的**共享结构数据**说明
3. 对该数据结构进行操作的**一组过程（或函数）**
4. 对局部于管程内部的共享数据**设置初始值的语句**

管程的定义描述举例如下：

```c
monitor Demo { // 1 定义一个名称为 Demo 的管程
    // 2 定义共享数据结构，对应系统中的某种共享资源
    共享数据结构 S;
    // 4 对共享数据结构初始化的语句
    init_code() {
		S = 5;  // 初始资源数等于 5
    }

	// 3 过程 1: 申请一个资源
    take_away() {
        对共享数据结构 x 的一系列处理;
        S--;  // 可用资源数 - 1
        ...
	}

    // 3 过程 2: 归还一个资源
    give_back() {
        对共享数据结构 x 的一系列处理;
        S++;  // 可用资源数 + 1
        ...
	}
}
```

不难注意到，管程很像一个类；管程的基本特征：

1. **局部于管程的数据只能被局部于管程的过程所访问**
2. 一个进程**只有通过调用管程内的过程才能进入管程访问共享数据**
3. **每次仅允许一个进程进入管程，从而实现进程互斥**

选择题：管程是由**编译语言**支持的进程同步机制

#### 条件变量

管程用**使用条件变量 condition 来释放管程（阻塞）和唤醒管程**，对应有 **wait 和 signal**，条件变量**可以有多个**

**每个条件变量仅保存了一个等待队列**，用于记录**因该条件变量而阻塞的所有进程**

- `x.wait`：当 x 对应的条件不满足时，调用 `x.wait` **将自己（进程）插入 x 条件的等待队列**，并**释放管程**
- `x.signal`：x 对应的条件发生了变化，则调用 `x.signal`，**唤醒一个因 x 条件而阻塞的进程**

下面给出条件变量的定义和使用：

```c
monitor Demo{
	共享数据结构 S;
    condition x;  // 定义一个条件变量 x
    init_code() { ... }
    take_away() {
        if(S <= 0) x.wait();  // 资源不够, 在条件变量 x 上阻塞等待
        资源足够,分配资源,做一系列相应处理;
    }
    give_back() {
        归还资源,做一系列相应处理;
        if(有进程在等待) x.signal();  // 唤醒一个阻塞进程
    }
}
```

条件变量和信号量的比较：

相似点：条件变量的 wait/signal 操作类似于信号量的 P/V 操作，**可以实现进程的阻塞/唤醒**

不同点（作用不同）：

1. **条件变量是没有值的**，仅实现了排队等待功能
2. **信号量是有值的**，信号量的值反映了剩余资源数
3. 在管程中，**剩余资源数用共享数据结构记录**

#### 例子*

用管程解决生产者消费者问题，这是管程代码：

```c
monitor ProducerConsumer
    condition full, empty;  // 条件变量用来实现同步(排队)
	int count = 0;  // 缓冲区中的产品数
    
    void insert(Item item) {  // 把产品 item 放入缓冲区
        if(count == N)
        	wait(full);
        count++;
        insert_item(item);
        if(count == 1)  // 感觉有点问题，若有多个用户被阻塞，有连续多次生产，则只会在第一次唤醒
            signal(empty);
    }
    
    Item remove(){  // 从缓冲区中取出一个产品
        if(count == 0)
	        wait(empty);
        count--;
        if(count == N - 1)
            signal(full);
        return remove_item();
    }
end monitor;
```

生产者和消费者的代码：

```c
// 生产者进程
producer() {
    while(1) {
        item = 生产一个产品;
        ProdecerConsumer.insert(item);
    }
}
// 消费者进程
consumer() {
    while(1) {
        item = ProdecerConsumer.remove();
        消费产品 item;
    }
}
```

### 经典同步问题

#### 生产者 - 消费者问题

问题描述：一组生产者进程和一组消费者进程共享一个初始为空、大小为 n 的缓冲区，只有缓冲区没满时，生产者才能把消息放入缓冲区，否则必须等待；只有缓冲区不空时，消费者才能从中取出消息，否则必须等待。由于缓冲区是临界资源，它只允许一个生产者放入消息，或一个消费者从中取出消息

这里较为简单，所以[关系分析、整理思路、设置信号量](#分析问题的方法步骤)就跳过了

```c
semaphore mutex = 1;  // 临界区互斥信号量
semaphore empty = n;  // 空闲缓冲区
semaphore ful1 = 0;  // 缓冲区初始化为空
producer() {  // 生产者进程
    while(1) {
        produce an item in nextp;  // 生产数据
        P(empty);(要用什么,P一下)  // 获取空缓冲区单元
        P(mutex);(互斥夹紧)  // 进入临界区
        add nextp to buffer;(行为)  // 将数据放入缓冲区
        V(mutex);(互斥夹紧)  // 离开临界区,释放互斥信号量
        V(full);(提供什么,V一下)  // 满缓冲区数加 1
    }
}
consumer() {  // 消费者进程
    while(1) {
        P(fu11);  // 获取满缓冲区单元
        P(mutex);  // 进入临界区
        remove an item from buffer;  // 从缓冲区中取出数据
        V(mutex);  // 离开临界区, 释放互斥信号量
        V(empty);  // 空缓冲区数加 1
        consume the item;  // 消费数据
    }
}
```

#### 家庭水果问题

问题描述：桌子上有一个盘子，每次只能向其中放入一个水果。爸爸专向盘子中放苹果，妈妈专向盘子中放橘子，儿子专等吃盘子中的橘子，女儿专等吃盘子中的苹果。只有盘子为空时，爸爸或妈妈才可向盘子中放一个水果；仅当盘子中有自己需要的水果时，儿子或女儿可以从盘子中取出

```c
semaphore plate = 1, apple = 0, orange = 0;
dad() {  // 父亲进程
    while(1) {
        prepare an apple;
        P(plate);  // 互斥向盘中取、放水果
        put the apple on the plate;  // 向盘中放苹果
        v(apple);  // 允许取苹果
    }
}
mom() {  // 母亲进程
    while(1) {
        prepare an orange;
        P(plate):  // 互斥向盘中取、放水果
        put the orange on the plate;  // 向盘中放橘子
        V(orange);  // 允许取橘子
    }
}
son() {  // 儿子进程
    while(1) {
        P(orange);  // 互斥向盘中取橘子
        take an orange from the plate;
        v(plate);  // 允许向盘中取、放水果
        eat the orange;
    }
}
daughter() {  // 女儿进程
    while(1) {
        P(apple);  // 互斥向盘中取苹果
        take an apple from the plate;
        V(plate);  // 运行向盘中取、放水果
        eat the apple;
    }
}
```

#### 读者 - 写者问题

问题描述：有读者和写者两组并发进程，共享一个文件，当两个或以上的读进程同时访问共享数据时不会产生副作用，但若某个写进程和其他进程（读进程或写进程）同时访问共享数据时则可能导致数据不一致的错误。因此要求：

1. 允许多个读者可以同时对文件执行读操作
2. 只允许一个写者往文件中写信息
3. 任一写者在完成写操作之前不允许其他读者或写者工作
4. 写者执行写操作前，应让已有的读者和写者全部退出

```c
int count = 0;  // 用于记录当前的读者数量
semaphore mutex = 1;  // 用于保护更新 count 变量时的互斥
semaphore rw = 1;  // 用于保证读者和写者互斥地访问文件
semaphore w = 1;  // 用于实现“写优先”
writer() {  // 写者进程
    while(1) {
        P(w);  // 在无写进程请求时进入
        P(rw);  // 互斥访问共享文件
        writing;  // 写入
        V(rw);  // 释放共享文件
        v(w);  // 恢复对共享文件的访问
    }
}
reader() {  // 读者进程
    while(1) {
        P(w);  // 在无写进程请求时进入
        P(mutex);  // 互斥访问 count 变量
        if(count == 0)  // 当第一个读进程读共享文件时
        	P(rw);  // 阻止写进程写
        count++;  // 读者计数器加 1
        v(mutex);  // 释放互斥变量 count
        V(w);  // 恢复对共享文件的访问
        reading;  // 读取
        P(mutex);  // 互斥访问 count 变量
        count--;  // 读者计数器减 1
        if(count == 0)  // 当最后一个读进程读完共享文件
         	V(rw);  // 允许写进程写
        v(mutex);  // 释放互斥变量 count
    }
}
```

这是读写公平法，如果把信号 w 去掉的话就是读优先法了

#### 哲学家进餐问题

问题描述：一张圆桌边上坐着 5 名哲学家，每两名哲学家之间的桌上摆一根筷子，两根筷子中间是一碗米饭。哲学家们倾注毕生精力用于思考和进餐，哲学家在思考时，并不影响他人。只有当哲学家饥饿时，才试图拿起左、右两根筷子（一根一根地拿起）。若筷子已在他人手上，则需要等待。饥饿的哲学家只有同时拿到了两根筷子才可以开始进餐，进餐完毕后，放下筷子继续思考

![image-20211108194532229](..\images\image-20211108194532229.png)

```c
semaphore chopstick[5] = {1, 1, 1, 1, 1};  // 初始化信号量
semaphore mutex = 1;  // 设置取筷子的信号量
Pi() {  // i 号哲学家的进程
    do {
        P(mutex);  // 在取筷子前获得互斥量
        P(chopstick[i]);  // 取左边筷子
        P(chopstick[(i + 1) % 5]);// 取右边筷子
        v(mutex);// 释放取筷子的信号量
        eat;  // 进餐
        V(chopstick[i]);  // 放回左边筷子
        V(chopstick[(i + 1) % 5]);  // 放回右边筷子
        think;  // 思考
    } while(1);
}
```

#### 吸烟者问题

问题描述：假设一个系统有三个抽烟者进程和一个供应者进程。每个抽烟者不停地卷烟并抽掉它，但要卷起并抽掉一支烟，抽烟者需要有三种材料：烟草、纸和胶水。三个抽烟者中，第一个拥有烟草，第二个拥有纸，第三个拥有胶水。供应者进程无限地提供三种材料，供应者每次将两种材料放到桌子上，拥有剩下那种材料的抽烟者卷一根烟并抽掉它，并给供应者一个信号告诉已完成，此时供应者就会将另外两种材料放到桌上，如此重复（让三个抽烟者轮流地抽烟）

```c
int num = 0;  // 存储随机数
semaphore offer1 = 0;  // 定义信号量对应烟草和纸组合的资源
semaphore offer2 = 0;  // 定义信号量对应烟草和胶水组合的资源
semaphore offer3 = 0;  // 定义信号量对应纸和胶水组合的资源
semaphore finish = 0;  // 定义信号量表示抽烟是否完成

process P1() {  // 供应者
    while(1) {
        num++;
        num = num % 3;
        if(num == 0)
	        V(offer1);  // 提供烟草和纸
        else if (num == 1)
         	V(offer2);  // 提供烟草和胶水
        else
	        V(offer3);  // 提供纸和胶水
        任意两种材料放在桌子上;
        P(finish);
    }
}

process P2() {  // 拥有烟草者
    while(1) {
        P(offer3);
        拿纸和胶水,卷成烟,抽掉;
        V(finish);
    }
)
    
process P3() {  // 拥有纸者
    while(1) {
        P(offer2);
        拿烟草和胶水,卷成烟,抽掉;
        V(finish);
    }
)

process P4() {  // 拥有胶水者
    while(1) {
        P(offer1);
        拿烟草和纸，卷成烟,抽掉;
        V(finish);
    }
}
```

## 死锁

### 死锁的概念

#### 死锁的定义

在多道程序系统中，由于**多个进程的并发执行**，改善了系统资源的利用率并提高了系统的处理能力，但也**带来了死锁**

死锁：指**多个进程因竞争资源而造成的一种僵局（互相等待），若无外力作用，这些进程都将无法向前推进**

例子：有一座仅供一辆汽车使用的桥，若有两辆汽车分别同时从桥的左右两端驶上该桥，那么谁也过不了只能干等着

思考：操作系统**只会处理多个进程访问有限资源产生死锁的情况**；而信号（公共变量操作）和死循环是程序员的问题

#### 死锁产生的原因

##### 系统资源的竞争

通常系统中的<u>不可剥夺资源的数量不足以满足多个进程运行的需要，使得进程在运行过程中，会因争夺资源而陷入僵局</u>

如磁带机、打印机等；只有**对不可剥夺资源的竞争才可能产生死锁**，**对可剥夺资源的竞争是不会引起死锁的**

##### 进程推进顺序非法

进程在运行过程中，**请求和释放资源的顺序不当，也同样会导致死锁**

例子：并发进程 $P_1,P_2$ 分别保持了资源 $R_1,R_2$，而进程 $P_1$ 申请资源 $R_2$、进程 $P_2$ 申请资源 $R_1$ 时，这时两者都会陷入阻塞

信号量使用不当也会造成死锁，如进程间彼此**相互等待对方发来消息**

#### 死锁产生的必要条件

产生死锁必须同时满足以下 4 个条件，**只要其中任意一个条件不成立，死锁就不会发生**：

1. **互斥条件**：在一段时间内某资源只能为一个进程所占有（其他进程只能等待）

2. **不剥夺条件**：进程所获得的**资源在未使用完之前，不能被其他进程强行夺走**（自己的资源**只能由自己来释放**）

3. **请求并保持条件**：请求新资源而**被阻塞时，仍保持原有的资源不放**

4. **循环等待条件**：存在一种进程资源的循环等待链，链中每个进程**已获得的资源**同时**被链中下一个进程所请求**

   存在一个处于等待态的进程集合 $\{P_0,P_1,\cdots,P_n\}$，其中 $P_i$ 等待的资源被 $P_{i+1},i\in [0,n-1]$ 占有，$P_n$ 等待的资源被 $P_0$ 占有

按死锁定义构成等待环所要求的条件更严，它**要求 $P_i$ 等待的资源<u>必须</u>由 $P_{i+1}$ 来满足**，而循环等待条件则无此限制

如 $P_k$ 不在循环圈，但它有其中一个 $P_i$ 需要的资源，等 $P_k$ 释放后 $P_i$ 就拿到资源可以执行，从而打破循环等待

![image-20211109201758881](..\images\image-20211109201758881.png)

**循环等待只是死锁的必要条件**，含圈不死锁是因为**同类资源数大于 1**

因此死锁的**充要条件是系统中每类资源只有一个资源，且出现循环等待**

### 死锁的处理策略

1. 死锁预防：设置某些限制条件，**破坏产生死锁的 4 个必要条件中的<u>一个</u>，即可防止发生死锁**

2. 避免死锁：在资源的动态分配过程中，**用某种方法防止系统进入不安全状态，从而避免死锁**

3. 死锁的检测及解除：

   <u>无须采取任何限制性措施</u>，**允许进程在运行过程中发生死锁**

   通过系统的检测机构及时地**检测出死锁的发生，然后采取某种措施解除死锁**

预防死锁和避免死锁都属于**事先预防策略**：

- 预防死锁的限制条件比较严格，**实现起来较为简单**，但往往导致**系统的效率低，资源利用率低**
- 避免死锁的限制条件相对宽松，资源分配后需要通过算法来判断是否进入不安全状态，**实现起来较为复杂**

<img src="..\images\image-20211109212641630.png" alt="image-20211109212641630" style="zoom:125%;" />

### 死锁预防

#### 破坏互斥条件（不可行）

若**允许系统资源都能共享使用**，则系统不会进入死锁状态（思考：可以通过假脱机技术来破坏）

但有些资源**根本不能同时访问**，如打印机等临界资源只能互斥使用，而且在有的场合应该保护这种互斥性

#### 破坏不剥夺条件

进程**请求新的资源而得不到满足时**，它**必须释放已经保持的所有资源**，待以后**需要时再重新申请**，从而破坏不剥夺条件

缺点：

1. 该策略**实现起来比较复杂**

2. 释放已获得的资源**可能造成前一阶段工作的失效**

   常用于状态易于保存和恢复的资源（如 CPU 的寄存器），一般不能用于打印机等

3. **反复地申请和释放资源会增加系统开销**，降低系统吞吐量

4. 可能一直把资源谦让给其他进程**导致自己饥饿**

#### 破坏请求并保持条件

采用**预先静态分配方法**，即**进程在运行前一次申请完它所需要的全部资源**，在它的**资源未满足前，不把它投入运行**

一旦投入运行，这些资源就一直归它所有，**不用提出其他资源请求**，这样就可以**保证系统不会发生死锁**

**缺点：**

1. **系统资源被严重浪费**，其中有些资源可能仅在运行初期使用
2. **会导致饥饿现象**，由于需要一次性申请完全部资源，那么需要资源多的进程，可能一直不能一次性申请完资源

#### 破坏循环等待条件

采用**顺序资源分配法**，首先**给系统中的资源编号**，规定每个进程**必须按编号递增的顺序请求资源**，<u>同类资源一次申请完</u>

缺点：

1. 编号必须相对稳定，这就**限制了新类型设备的增加**，可能需要重新分配所有编号
3. **造成资源的浪费**，如程序 A 先使用 7 再使用 5，但申请时会先申请 5 再申请 7，造成 5 时间上的浪费
4. 这种按规定次序申请资源的方法，**会给用户的编程带来麻烦**，如两个 OS 的资源编号不一样

思考：因为拥有大编号资源的进程不会申请小编号资源，所以就不会出现循环等待

### 死锁避免

避免死锁属于**事先预防策略**，是在资源动态分配过程中，**防止系统进入不安全状态**，以避免发生死锁

这种方法所施加的限制条件较弱，可以获得**较好的系统性能**

#### 系统安全状态

避免死锁的方法中，**允许进程动态地申请资源**，但系统在进行**资源分配之前**，应先**计算此次分配的安全性**，若此次分配<u>不会导致系统进入不安全状态，则允许分配；否则让进程等待</u>

安全序列：指根据当前**资源的分配状况和剩余情况**，**计算出一种可以顺利推进进程运行的序列**，这个序列叫安全序列

安全状态：若系统**能找到一个安全序列**，那么**就处于安全状态**，否则系统处于不安全状态，[安全状态判断的例子](#安全性算法举例)

注意：**不安全状态不一定是死锁状态**，在不安全状态进程继续申请资源导致阻塞后才是死锁；但**死锁必定是不安全状态**，而**安全状态必定不是死锁状态**

#### 银行家算法

银行家算法是最著名的死锁避免算法，其思想是：

1. 进程运行之前先**声明对各种资源的最大需求量**
2. 在运行中**不允许进程获得超过其声明的最大需求量**，且**不允许系统进入不安全状态**

##### 数据结构猫述

下面的二维矩阵**一行代表一个进程，一列代表一类资源**

- 可利用资源向量 Available：含有 m 个元素的数组，其中**每个元素代表一类可用的资源数目**

  如 Available[j] = K 表示系统中现有 $R_j$ 类资源 K 个

- 最大需求矩阵 `Max`：n × m 矩阵，**定义系统中 n 个进程中的每个进程对 m 类资源的最大需求**

  Max[i, j] = K 表示进程 i 需要 $R_j$ 类资源的最大数目为 K

- 分配矩阵 `Allocation`：n × m 矩阵，**定义系统中每类资源当前已分配给每个进程的资源数**

  Allocation[i, j] = K 表示进程 i 当前已分得 $R_j$ 类资源的数目为 K

- 需求矩阵 `Need`：n × m 矩阵，**表示每个进程接下来最多还需要多少资源**

  Need[i, j] = K 表示进程 i 还需要 $R_j$ 类资源的数目为 K

- 上述三个矩阵间存在下述关系：**Need = Max - Allocation**

##### 银行家算法描述

设 $Request_i$ 是进程 $P_i$ 的请求向量，$Request_i[j]=K$ 表示进程 $P_i$ 需要 j 类资源 K 个

当 $P_i$ 发出资源请求后，系统按下述步骤进行检查：

1. **检查请求不能大于需要** $Request_i≤Need[i]$，若它所**需要的资源数超过它所宣布的最大值，则认为出错**

2. **检查请求不能大于可用** $Request_i≤Available$，若**无足够资源 $P_i$ 等待**

3. 系统**试探着把资源分配给进程 $P_i$**，并修改下面数据结构中的数值：

   1. $Available = Available-Request_i$
   2. $Allocation[i]=Allocation[i]+Request_i$
   3. $Need[i]=Need[i]-Request_i$

4. 系统**执行安全性算法**，检查此次资源分配后，系统**是否处于安全状态**

   若安全，才**正式将资源分配给进程 $P_i$**；**否则，分配作废**，恢复原来的资源分配状态，让进程 $P_i$ 等待

##### 安全性算法

设置工作向量 Work，有 m 个元素，表示**系统中的剩余可用资源数目**，开始时 Work = Available

1. 初始时安全序列为空

2. 从 Need 矩阵中**找出符合下面条件的行**：

   该行对应的进程**不在安全序列**中，而且**该行小于等于 Work 向量**

   找到后，把对应的进程 $P_i$ 加入安全序列；若找不到，则执行步骤 4

3. **执行 Work = Work + Allocation[i]**（因为 $P_i$ 已获得需要的资源，可以顺利完成）返回步骤 2

4. <u>若此时安全序列中已有所有进程，则系统处于安全状态，否则系统处于不安全状态</u>

应用题：在计算过程中，将每步可满足需求的进程作为一个集合，同时执行并释放资源，可以简化计算

#### 安全性算法举例

假定系统中有 5 个进程 $\{P_0, P_1, P_2,P_3,P_4\}$ 和三类资源 {A, B, C}，各种资源的数量分别为 10, 5, 7：

<img src="..\images\image-20211110150933639.png" alt="image-20211110150933639" style="zoom:150%;" />

利用安全性算法判断 $T_0$ 时刻的资源分配是否安全：

1. 求 Need 矩阵 Need = Max - Allocation：

   ![image-20211110151016360](..\images\image-20211110151016360.png)

2. 将 Work 向量与 Need 矩阵的各行进行比较，找出比 Work 矩阵小的行
   $$
   (3,3,2) > (1,2,2)\\
   (3,3,2)> (0,1,1)
   $$
   找到 $P_1$ 和 $P_3$，这里我们选择 $P_1$（也可以选择 $P_3$）暂时加入安全序列

3. 释放 $P_1$ 所占的资源，即把 $P_1$ 进程对应的 Allocation 矩阵中的一行与 Work 向量相加：
   $$
   (3,3,2)+(2,0,0)=(5,3,2)=Work
   $$
   此时需求矩阵更新为（去掉了 $P_1$ 对应的一行）：
   
   ![image-20211110151059669](..\images\image-20211110151059669.png)
   
   再用更新的 Work 向量和 Need 矩阵重复步骤 2

最后得到一个安全序列 $\{P_1,P_3, P_4, P_2, P_0\}$，利用安全性算法分析 $T_0$ 时刻的资源分配情况如下：

![image-20211110151136647](..\images\image-20211110151136647.png)

#### 银行家算法举例

先使用银行家算法的前三步，拿到更新的 Allocation 和 Need，再按照安全性算法进行判断，就能知道系统能否满足资源请求

假设当前系统中资源的分配和剩余情况如下表：

![image-20211110150933639](..\images\image-20211110150933639.png)

1. $P_1$ 请求资源：$P_1$ 发出请求向量 $Request_1(1, 0, 2)$，系统按银行家算法进行检查：

   $Request_1(1,0,2)≤Need_1(1,2,2)$，请求小于需要

   $Request_1(1,0,2) \leq Available(3,3,2)$，请求小于可用

   系统先假定可为 $P_1$ 分配资源，并修改：

   $Available = Available -Request_1=(2,3,0)$

   $Allocation_1= Allocation_1+ Request_1= (3,0,2)$

   $Need_1 = Need_1 - Request_1= (0,2,0)$

   令 Work = Available = (2 ,3, 0)，再利用安全性算法检查此时系统是否安全，如下表：

   ![image-20211110170756463](..\images\image-20211110170756463.png)

   可找到一个安全序列 $\{P_1,P_3,P_4, P_2,P_0\}$，系统是安全的，可以立即将 $P_1$ 所申请的资源分配给它

   ![image-20211110170830306](..\images\image-20211110170830306.png)

2. $P_4$ 请求资源：$P_4$ 发出请求向量 $Request_4(3,3,0)$，系统按银行家算法进行检查：

   $Request_4(3,3,0)≤Need_4(4,3,1)$

   $Request_4(3,3,0)>Available(2,3,0)$，让 $P_4$ 等待

3. $P_0$ 请求资源：$P_0$ 发出请求向量 $Requst_0(0,2,0)$，系统按银行家算法进行检查：

   $Request_0(0,2,0)≤Need_0(7,4,3)$

   $Request_0(0,2,0)≤Available(2,3,0)$

   系统暂时先假定可为 $P_0$ 分配资源，并修改有关数据：

   $Available = Available - Request_0= (2,1,0)$

   $Allocation_0= Allocation_0+ Request_0=(0,3,0)$

   $Need_0= Need_0- Request_0=(7,2,3)$，结果如下表：

   ![image-20211110170902631](..\images\image-20211110170902631.png)

   进行安全性检查：可用资源 $Available(2,1,0)$ 已不能满足任何进程的需要，系统进入不安全状态，因此拒绝 $P_0$ 的请求，让 $P_0$ 等待，并将 $Available, Allocation_0, Need_0$ 恢复为之前的值

### 死锁检测和解除

#### 资源分配图

系统死锁可利用**资源分配图**来描述，**用圆圈代表一个进程，用框代表一类资源，框中的一个圆代表一类资源中的一个资源**

从**进程到资源的有向边称为请求边**，表示该进程**申请一个单位的该类资源**

从**资源到进程的边称为分配边**，表示该类资源**已有一个资源分配给了该进程**

![image-20211110185311649](..\images\image-20211110185311649.png)

如图所示：

- 进程 $P_1$ 已经分得了两个 $R_1$ 资源，并又请求一个 $R_2$ 资源
- 进程 $P_2$ 分得了一个 $R_1$ 资源和一个 $R_2$ 资源，并又请求一个 $R_1$ 资源

#### 死锁定理

![image-20211110185349394](..\images\image-20211110185349394.png)

简化资源分配图可检测系统状态 S 是否为死锁状态，简化方法如下：

1. 在资源分配图中，**找出既不阻塞又不孤点的进程 $P_i$ 消去它所有的请求边和分配边**，使之成为孤立的结点

   在上图 a 中，$P_1$ 是满足这一条件的进程结点，将 $P_1$ 的所有边消去，便得到图 b 所示的情况

   注意：**一个资源的空闲数量**等于它的**资源数量减去它在资源分配图中的出度**

2. 进程 $P_i$ 所释放的资源，**可以唤醒某些因等待这些资源而阻塞的进程**，原来的阻塞进程可能变为非阻塞进程，如图中 $P_2$

   进行一系列简化后，**若能消去图中所有的边，则称该图是可完全简化的**，如图 c 所示

   **S 为死锁的条件是当且仅当 S 状态的资源分配图是不可完全简化的**，该条件为死锁定理

#### 死锁解除

死锁解除的主要方法有：

1. 资源剥夺法：**挂起某些死锁进程，并抢占它的资源，将这些资源分配给其他的死锁进程**

   但<u>应防止被挂起的进程长时间得不到资源</u>而处于资源匮乏的状态

2. 撤销进程法：**强制撤销部分甚至全部死锁进程并剥夺这些进程的资源**

3. 进程回退法：**让一或多个进程回退到足以回避死锁的地步，进程回退时自愿释放资源而非被剥夺**

   要求<u>系统保持进程的历史信息，设置还原点</u>

应该对哪个进程使用进程解除*：

1. 进程优先级：优先对进程优先级低的进程下手
2. 已执行多长时间：执行时间越长下手的代价越大
3. 还要多久能完成：牺牲还需要时间较长的进程
4. 进程已经使用了多少资源：把有很多资源的进程干掉可以释放很多资源
5. 进程是交互式的还是批处理式的：撤销批处理式的进程用户感觉不明显

# 内存管理

## 内存管理概念

### 内存管理的基本原理和要求

不可能将全部程序与数据放入主存，因此**操作系统必须对内存进行划分和动态分配**，这就是内存管理的概念

有效的内存管理可以<u>方便用户使用存储器、提高内存利用率、通过虚拟技术从逻辑上扩充存储器</u>

内存管理的功能有：

- 内存空间的分配与回收：由操作系统完成主存储器空间的分配和管理，使程序员摆脱存储分配的麻烦，提高编程效率
- 地址转换：程序中的逻辑地址与内存中的物理地址不一致，需要存储管理**把逻辑地址转换成相应的物理地址**
- 内存空间的扩充：利用**虚拟存储技术或自动覆盖技术，从逻辑上扩充内存**
- 存储保护：保证**各道作业在各自的存储空间内运行**，互不干扰

#### 程序装入和链接

将用户源程序变为可在内存中执行的程序，通常需要以下几个步骤：

- 编译：由编译程序**将用户源代码编译成若干目标模块**
- 链接：由链接程序将编译后形成的**一组目标模块及所需的库函数链接成一个完整的装入模块**（如 `.exe` 文件）
- 装入：由装入程序**将装入模块装入内存运行**

注意：链接形成逻辑地址，而装入形成物理地址

![image-20211111224908120](..\images\image-20211111224908120.png)

程序的链接有以下三种方式：

- 静态链接：**将各目标模块及它们所需的库函数链接成一个完整的可执行程序**，需要解决两个问题：

  修改相对地址（内部变量等的地址），变换外部调用符号（其他模块函数或变量的地址）

- 装入时动态链接：**装入内存时，采用边装入边链接的方式**；其优点是**便于修改和更新及实现对目标模块的共享**

- 运行时动态链接：在程序执行中**需要目标模块时才进行链接**；其优点是**加快程序装入和节省内存空间**

- 思考：静态连接：生成 `exe` 文件；装入时动态连接：目标文件装入内存时再链接；运行时动态链接：加载并调用 dll

- 思考：装入时动态连接：目标文件在磁盘中只有一个，但在内存中可能有多个；运行时动态链接：磁盘和内存都只有一个

内存的装入模块在装入内存时，同样有以下三种方式：

1. 绝对装入：

   编译程序将**产生绝对地址的目标代码**，绝对装入程序**按照装入模块中的地址装入内存**，仅适用于**单道程序环境**

   通常程序员给出符号地址，让**编译或汇编程序转换成绝对地址**，也可由**程序员直接给出绝对地址**

2. 可重定位装入，静态重定向：**只在装入时进行重定向**

   在多道程序环境下，多个目标模块的**起始地址通常都从 0 开始**，程序中的**其他地址相对于始址**

   **根据内存的当前情况，装入内存的适当位置**，装入时对指令和数据的修改过程（逻辑地址→物理地址）称为**重定位**

   ![image-20211112132205564](..\images\image-20211112132205564.png)

   特点：

   - 作业装入内存时，必须给它分配要求的全部内存空间，若**没有足够的内存，则不能装入该作业**
   - 作业一旦进入内存，整个运行期间**不能在内存中移动和再申请内存空间**

3. 动态运行时装入，动态重定位：**在执行时才进行重定向**，现代操作系统使用

   <u>程序在内存中若发生移动，则需要采用动态的装入方式</u>，这种方法**需要一个重定位寄存器的支持**

   ![image-20211112133706111](..\images\image-20211112133706111.png)

   特点，这是需要在**运行时进行地址转换**才能做到的：

   - 可以**将程序分配到不连续的存储区中**
   - 在程序运行之前可以**只装入它的部分代码**即可投入运行，然后**在程序运行期间，根据需要动态申请分配内存**
   - **便于程序段的共享**，可以向用户**提供一个比存储空间大得多的地址空间**

思考：绝对装入是编译时生产内存地址；静态重定向是装入时生成内存地址；动态重定向是运行时转换内存地址（页表）

#### 逻辑地址空间与物理地址空间

编译后每个目标模块都**从 0 号单元开始编址**，这称为该目标模块的**相对地址**或**逻辑地址**

链接程序将各个模块**链接成一个完整的可执行程序后**，就**构成统一的从 0 号单元开始编址的逻辑地址空间**

用户程序和程序员**只需知道逻辑地址**；不同**进程可以有相同的逻辑地址**，因为会**映射到主存的不同位置**

**物理地址是主存储器的地址**，进程在运行时执行指令和访问数据，最后都要通过物理地址从主存中存取

OS 通过内存管理部件 `MMU` 将进程使用的逻辑地址转换为物理地址

#### 进程的内存映像

程序调入内存运行时，会构成进程的内存映像，它一般有几个要素：

- 代码段：二进制代码，代码段是**只读**的，可以被多个进程**共享**
- 数据段：即程序运行时加工处理的对象，包括**全局变量和静态变量**
- 进程控制块 PCB：存放在系统区，用来给 OS 控制和管理进程
- 堆：用来存放**动态分配的变量**，通过调用 malloc 分配
- 栈：用来实现**函数调用及局部变量**，从最大地址往低地址方向增长

代码段和数据段在程序调入内存时就指定了大小，而堆和栈会动态的扩展和收缩

![image-20220715192802240](..\images\image-20220715192802240.png)

这是一个进程在内存中的映像：

- 共享库：存放进程用到的共享函数库代码，如 printf()
- 读代码段：.init 是程序初始化时调用的 _init 函数；.text 是用户程序的机器代码；.rodata 是只读数据
- 读/写数据段：.data 是已初始化的全局变量和静态变量；.bss 是未初始化及所有初始化为 0 的全局变量和静态变量

#### 内存保护

内存保护是指：

- **保护操作系统不受用户进程的影响**
- **保护用户进程不受其他用户进程的影响**

内存保护可采取两种方法：

1. 在 CPU 中设置一对上、下限寄存器，**每当 CPU 要访问一个地址时，分别和两个寄存器的值相比，判断有无越界**

2. 采用重定位寄存器（或基址寄存器）和界地址寄存器（又称限长寄存器）来实现这种保护：

   重定位寄存器含最小的物理地址值，界地址寄存器含逻辑地址的最大值，**每个逻辑地址值必须小于界地址寄存器**

   内存管理机构**将逻辑地址与界地址寄存器进行比较，若未发生地址越界，则加上重定位寄存器的值后映射成物理地址**

   ![image-20211111225125773](..\images\image-20211111225125773.png)

注意：只有操作系统内核才可以加载重定位寄存器和界地址寄存器，加载必须使用**特权指令**

#### 内存共享

只有**只读的区域才可以共享**，如可重入代码（纯代码）就仅允许多进程访问，而不能被修改

在实际执行中，多个进程虽然**使用同一个代码**，但是各个进程会**在其内部为代码分配数据**（代码共享，数据独有）

例子：有 40 个进程，共享文本编辑程序，有 `160KB` 的可分享代码区和 `40KB` 的数据区，这样每个进程共享 `160KB` 的代码，且分配 `40KB` 的数据，共需要 `40KB × 40 + 160KB = 1760KB` 的内存

分页：页表中有 40 个页表项，指向共享代码区的物理页号；有 10 个页表项，指向私有数据区的物理页号

分段：只需为该段设置一个段表项，指明共享代码段始址，及段长 `160KB`，可见段的共享十分简单

#### 内存分配与回收

| 存储管理方式                                | 目的                           |      |
| ------------------------------------------- | ------------------------------ | ---- |
| 单一连续分配 → 固定分区分配                 | 实现 OS 从单道 → 多道          |      |
| 固定分区分配 → 动态分区分配                 | 更好地适应不同大小的程序要求   |      |
| 连续分配方式 → 离散分配方式（页式存储管理） | 更好地提高内存的利用率         |      |
| 引入分段存储管理                            | 满足用户在编程和使用方面的要求 |      |

### 覆盖与交换*

#### 覆盖

早期的计算机系统中，存储空间放不下一道用户进程的现象也经常发生，可以用覆盖技术来解决

覆盖的基本思想如下：

- 把用户空间分成一个<u>固定区和若干覆盖区</u>
- 将<u>经常活跃的部分放在固定区</u>，其余部分按调用关系分段
- 将<u>即将要访问的段放入对应的覆盖区替换其原有的内容，其他段放在外存中</u>

特点：

- <u>不需要将一个进程的全部信息装入主存后才能运行</u>，但<u>同时运行程序的代码量大于主存时仍不能运行</u>
- 内存中能够更新的地方只有覆盖区的段，<u>不在覆盖区中的段会常驻内存</u>
- <u>需要程序员指明固定区和覆盖区</u>（不透明），增加了用户编程负担

额外：覆盖要求覆盖段间相对独立且受内存容量大小影响，而虚拟存储没有

#### 交换

交换（对换）的基本思想是（中级调度采用的就是交换技术）：

- 换出：把处于<u>等待状态的程序从内存移到辅存</u>，把内存空间腾出来
- 换入：把<u>准备好竞争 CPU 运行的程序从辅存移到内存</u>

额外：交换是将整个进程换出早期连续存储时使用，而虚拟存储是换出进程的部分数据

有关交换，需要注意以下几个问题：

- 交换需要备份存储，通常是快速磁盘

- 为了有效使用 CPU，需要使每个进程的执行时间比交换时间长

- 若换出进程，则必须确保该进程<u>完全处于空闲状态</u>

- 交换空间通常作为磁盘的一整块，且独立于文件系统

  磁盘有对换区和文件区，<u>文件区采用离散方式，对换区采用连续方式效率高</u>

- <u>交换通常在有许多进程运行且内存空间吃紧时开始启动，而在系统负荷降低时就暂停</u>

- 普通的交换使用不多，但交换策略的某些变体在许多系统中仍发挥作用，如 UNIX 系统

选择题：若一个进程正在 I/O 操作，则不能交换出主存，但 OS 开辟 I/O 缓冲区后进程交换不受限制

选择题：可重入程序通过共享或动态链接来使用同一块存储空间，以减少对程序段的调出/调入，减少了对换数量

------

<u>交换技术主要在不同进程之间进行，而覆盖则用于同一个程序或进程中</u>

对于主存无法存放用户程序的矛盾，**现代操作系统是通过虚拟内存技术来解决**的

覆盖技术则已成为历史，而交换技术在现代操作系统中仍具有较强的生命力

### 连续分配管理方式

连续分配方式是指**为一个用户程序分配一个连续的内存空间**

连续分配方式主要包括单一连续分配、固定分区分配、动态分区分配：

#### 单一连续分配

内存分为**系统区和用户区，系统区在低地址部分**，这种方式**无须进行内存保护**（单任务不需要保护）

优点：简单、**无外部碎片**，可以采用覆盖技术，**不需要额外的技术支持**

缺点：只能用于**单用户、单任务**的操作系统中，**有内部碎片，存储器的利用率极低**

#### 固定分区分配

最简单的一种多道程序存储管理方式，**将用户内存空间划分为若干固定大小的区域，每个分区只装入一道作业**

使用：每当有空闲分区时，便可再从外存的后备作业队列中选择适当大小的作业装入该分区

固定分区分配在划分分区时有两种不同的方法：

- 分区大小相等：**用于利用一台计算机去控制<u>多个相同对象的场合</u>**，缺乏灵活性
- 分区大小不等：划分为<u>多个较小的分区、适量的中等分区和少量大分区</u>

![image-20211111232041170](..\images\image-20211111232041170.png)

为便于内存分配，通常将分区**按大小排队**，并为之建立一张分区说明表，其中各表项包括**每个分区的始址、大小及状态**

装入时，检索该表**找到合适的分区给予分配并将其状态置为已分配，未找到合适分区时，则拒绝分配**；回收时，只需将状态置为未分配

![image-20211111232108565](..\images\image-20211111232108565.png)

这种分区方式存在几个问题：

1. **程序可能太大而放不进任何一个分区中**，这时用户不得不使用覆盖技术来使用内存空间
2. 主存利用率低，**程序小于固定分区时也占整个固定分区**，这种现象称为**内部碎片**
3. **不能实现多进程共享一个主存区**，存储空间利用率低

#### 动态分区分配

又称**可变分区分配**，**在进程装入内存时，根据进程的大小动态地建立分区，并使分区的大小正好适合进程的需要**，内存利用率比固定分区分配高一些

如下图，首先装入三个进程，在某个时刻 CPU 出现空闲，换出进程 2 换入进程 4，中间产生了内存块等

![image-20211111232144689](..\images\image-20211111232144689.png)

动态分区会**导致内存中出现许多小的内存块**，随着时间的推移，内存中会产生越来越多的碎片，**内存的利用率随之下降**

这些小的内存块称为**外部碎片**，可以通过紧凑 Compaction 技术来解决，即**把动态分区移动到一起**，但这**需要动态重定位寄存器的支持**，且相对费时

分配策略：内存中**有多个足够大的空闲块**，操作系统必须**确定分配哪个内存块给进程使用**，有以下几种算法：

1. 首次适应 First Fit 算法：空闲分区**以地址递增的次序链接**，分配内存时顺序查找，分配**大小能满足要求的第一个空闲分区**

   会使内存的**低地址部分出现很多小的空闲分区**，查找时都要经过这些分区，因此**增加了查找的开销**

   首次适应算法不仅是最简单的，而且通常也是**最好和最快**的

2. 最佳适应 Best Fit 算法：空闲分区**按容量递增的方式形成分区链**，分配**第一个能满足要求的空闲分区**

   每次最佳的分配会留下很小的难以利用的内存块，会**产生最多的外部碎片，性能很差**

3. 最坏适应 Worst Fit，最大适应 Largest Fit 算法：空闲分区**以容量递减的次序链接**，分配**第一个能满足要求的空闲分区**

   总把最大的连续内存划分开，会**很快导致没有可用的大内存块，性能非常差**

4. 邻近适应 Next Fit，循环首次适应算法：与首次适应算法相比，分配内存时**从上次查找结束的位置开始继续查找**

   虽然查找链表的次数快了，但**不能形成较大的空闲分区**，当有程序需要较大的内存时不能满足，通常**比首次适应法差**

注意：**空闲分区可以使用数组或链表来管理**；实验表明**首次适应 > 最佳适应法 > 最大适应法**

注意：在回收操作中，当**回收的块与原来的空闲块相邻时，需要将这些块合并**；算法开销也是需要考虑的一个因素

![image-20211111232240726](..\images\image-20211111232240726.png)

实现：设置一张空闲分区链表，并按始址排序

分配内存：检索空闲分区链，找到所需的分区，若**大于请求大小较多**，则从中割一块空间分配给装入进程，否则直接分配

回收内存：系统根据回收分区的始址，从空闲分区链中找到相应的插入点，会出现两种情况：

1. 若回收区有相邻的空闲区，则将它们**合并，并修改表项**（前我、我后、前我后，删去后面的表项）
2. 若回收区没有相邻的空闲分区，此时应为回收区**新建一个表项**，填写始址和大小，并插入空闲分区链

### 非连续分配管理方式

非连续分配**允许一个程序分散地装入不相邻的内存分区**，但这也**需要额外的空间去存储分散区域的索引**，使得**非连续分配方式的存储密度低于连续存储方式的存储密度**

非连续分配管理方式**根据分区的大小是否固定**，分为<u>分页存储管理方式和分段存储管理方式</u>；在分页存储管理方式中，又**根据运行作业时是否要把作业的所有页面都装入内存才能运行**，分为<u>基本分页存储管理方式和请求分页存储管理方式</u>

注意：页式、段式、段页式寄存器中 PC 的值是逻辑地址，去指令时会进行转换，Push PC 时压的也是逻辑地址

#### 基本分页存储管理方式

为了内存的使用能尽量避免碎片的产生，引入了分页的思想：

- 把**主存空间划分为大小相等且固定的块**，块相对较小，作为**主存的基本单位**
- 每个**进程也以块为单位进行划分**，进程在执行时，**以块为单位逐个申请主存中的块空间**

进程只会在为最后一个不完整的块申请一个主存块空间时，才产生主存碎片，所以尽管会产生内部碎片，但这种碎片相对于进程来说也是很小的，**每个进程平均只产生半个块大小的内部碎片（也称页内碎片）**

##### 分页存储的几个基本概念

1. 页面和页面大小：

   **进程中的块称为页** Page 或页面，**内存中的块称为页框** Page Frame 或页帧，**外存直接称为块** Block

   进程在执行时要**为每个页面分配主存中的可用页框**，这就产生了页和页框的一一对应

   **页面大小应是 2 的整数幂**，同时页面大小应该适中：

   - 页面太小会使进程的页面数过多，这样**页表就会过长**，占用大量内存

     也会增加硬件地址转换的开销，降低页面换入/换出的效率（**即频繁换页**）

   - 页面过大又会使**页内碎片增多**，降低内存的利用率

   选择题：操作系统的内存分页大小一旦确定，所有的页面就是等长的，不能一个页面 `4KB` 一个 `8KB`

2. 地址结构：

   ![image-20211111232418494](..\images\image-20211111232418494.png)

   地址结构包含两部分：前一部分为**页号 P**，后一部分为**页内偏移量 W**

   注意：**地址结构决定了虚拟内存的寻址空间有多大**

3. 页表：

   系统**为每个进程建立一张页表**来实现**从页号到物理块号的地址映射**，**页表总是存放在内存中**

   **页表是由页表项组成**的，页表项由**页号和物理内存中的块号**组成；**物理内存块号和页内偏移量共同组成物理地址**

![image-20211111232457932](..\images\image-20211111232457932.png)

##### 基本地址变换机构

地址变换机构的任务是**将逻辑地址转换为内存中的物理地址**，地址变换是借助于页表实现的

![image-20211111232545922](..\images\image-20211111232545922.png)

通常设置一个**页表寄存器 PTR**，存放**页表在内存的起始地址** F 和**页表长度** M

进程**未执行时**，页表的始址和长度存**放在进程控制块 PCB 中**；进程**执行时**，才**将页表始址和长度存入页表寄存器**

设页面大小为 L，逻辑地址 A 到物理地址 E 的变换过程如下：

1. 计算**页号 P=A / L** 和**页内偏移量 W = A % L**

2. 比较页号 Р 和页表长度 M，**若 P ≥ M，则产生越界中断，否则继续执行**

3. **页表项地址 = 页表始址 F＋页号 P × 页表项长度**，根据表项地址**取出物理块号 b**

   注意：页表长度的值是指**一共有多少页**，页表项长度是指**页地址占多大的存储空间**

4. 计算**物理地址 E = b × L + W**，用得到的物理地址去访问内存

以上**整个地址变换过程均是由硬件自动完成**

页式管理**只需给出一个整数就能确定对应的物理地址**（页面大小固定），因此**页式管理中地址空间是一维的**

以 32 位逻辑地址空间、字节编址单位、一页 `4KB` 为例，确定页表项的大小：

1. `4KB` 共需要 12 位表示，剩下的 20 位用于表示页号的范围
2. 因为以字节作为编址单位，页表项的大小 ≥ $\lceil20/8\rceil =3B$，页表项**至少**是 `3B`
3. 为了**存储方便和放额外信息**，可以页表项可以**取大点**如 `4B`，这样一页正好装下 `1K` 个页表项

下面讨论分页管理方式存在的两个主要问题：

1. 每次访存操作都需要进行地址转换，**地址转换过程必须足够快，否则访存速度会降低**
2. 每个进程引入页表，用于存储映射机制，**页表不能太大，否则内存利用率会降低**

##### 具有快表的地址变换机构

若页表全部放在内存中，则存取一个数据或一条指令**至少要访问两次内存**，这种方法比通常执行指令的速度慢了一半

在地址变换机构中**增设快表  TLB**，存放若干页表项以**加速地址变换的过程**，而**主存中的页表常称为慢表**

![image-20211111232643969](..\images\image-20211111232643969.png)

在具有快表的分页机制中，地址的变换过程如下：

1. CPU 给出逻辑地址后，由硬件进行地址转换，**将此页号与快表中的所有页号同时进行比较**
2. 若找到匹配的页号，则直接**从快表中取出该页对应的页框号，形成物理地址**（一次访存）
3. 若未找到匹配的页号，则在内存中**读出页表项，将其存入快表**，若快表已满按照某算法进行替换

注意：有些处理机设计为<u>快表和慢表同时查找</u>，若<u>在快表中查找成功则终止慢表的查找</u>，**题目没写一般不是这种**

注意：快表访问成功<u>仍需访问一次内存</u>；快慢表非同时查找时，不管快表访问成不成功<u>访问快表的时间都要消耗</u>

由于基于局部性原理，快表的命中率可达 90% 以上，这样分页带来的速度损失就可降低至 10% 以下

##### 两级页表

引入分页管理后，进程在**执行时不需将所有页调入内存页框**，**只需将保存有映射关系的页表调入内存**，但仍需考虑页表大小

一个 `40MB` 的进程它需要 10 页框来保存页表，但是它实际执行时可能只需要几十个页框就可运行：

- 若要求 10 个页面大小的页表必须全部进入内存，相对于几十个页框来说，**降低了内存利用率**
- 在大多数情况下，**映射所需要的页表项都在页表的同一个页面中**，没必要 10 个页表都在内存
- 需要**连续**的 10 个页框空间来存放页表，系统内可能找不到这么大的连续空间

注意：**一般进程需要全部地址映射**，单页表就需要连续 `4MB`，因为一般程序会用到高位和低位地址，如栈在高位，代码在低位

为了减少页表占用空间，进一步延申页表映射思想，得到了二级页表，**对页表也进行地址映射，建立上一级页表，来存储页表的映射关系**，以下是二级页表的逻辑地址空间的格式（为查询方便，**顶级页表只能有 1 个页面**）

![image-20211111232816798](..\images\image-20211111232816798.png)

例如：页面大小为 `4KB`，页内偏移地址为 12位，页号部分为 20 位，顶级页表可以放 `4KB / 4B = 1024` 个表项，占 10 位，因此逻辑地址空间就剩下了 10 位，二级页表的大小正好在一页之内，这样就得到了 10 10 12 的格式

![image-20211111232851361](..\images\image-20211111232851361.png)

建立多级页表的目的在于建立索引，以便**不用浪费主存空间去存储无用的页表项**，也**不用盲目地顺序式查找页表项**

思考：若采用二级页表，当程序挂起时，最高一级页表必须在内存；运行时仅需要用到的二级页表在内存

#### 基本分段存储管理方式

分段管理方式**为考虑了用户和程序员而提出**，以满足**方便编程、信息保护和共享、动态增长、动态链接**等多方面的需要

额外：分段后汇编语句：Load [D] | \<A\> 把 D 段的 A 加载，这样编程更方便，可读性更高

额外：分页用户不可见，而分段用户可见；段内必须连续导致段太长时找不到连续空间

##### 分段

段式管理方式**按照用户进程中的自然段划分逻辑空间**，每段**从 0 开始编址**，并分配一段**连续的地址空间**，其逻辑地址由**段号** S 与**段内偏移量** W 两部分组成，**最多拥有 $2^S$ 个段号，每段最长 $2^W$**

![image-20211111232955044](..\images\image-20211111232955044.png)

在段式系统中，**段号和段内偏移量必须由用户显式提供**，在<u>高级程序设计语言中，这个工作由编译程序完成</u>

##### 段表

每个进程都有一张段表，**用于实现从逻辑段到物理内存区的映射**，其中**每个段表项对应进程的一段**

段表项由**段号、段基址、段长**组成，每个段表项**长度相同**，**段长位数和逻辑地址中的段长一样，基址位数和内存大小一样**

![image-20211111233027685](..\images\image-20211111233027685.png)

这是进程的段与物理内存的映射关系：

![image-20211111233103169](..\images\image-20211111233103169.png)

##### 地址变换机构

![image-20211111233139262](..\images\image-20211111233139262.png)

为了实现进程从逻辑地址到物理地址的变换功能，在系统中设置了**段表寄存器**，用于存放**段表始址** F 和**段表长度** M

从逻辑地址 A 到物理地址 E 之间的地址变换过程如下：

1. 从逻辑地址 A 中取出前几位为段号 S，后几位为段内偏移量 W
2. 比较段号 S 和段表长度 M，**若 S ≥ M，则产生越界中断，否则继续执行**
3. **段表项地址 = 段表始址 F＋段号 S × 段表项长度**
4. 从段表项取出段长 C，**若段内偏移量 ≥ C，则产生越界中断，否则继续执行**
5. 从段表项取出该段的始址 b，计算**物理地址 E = b + W**，用得到的物理地址去访问内存

##### 段的共享与保护

段的共享是通过**两个作业的段表中相应表项指向被共享的段的同一个物理副本**来实现的

当一个作业正从共享段中读取数据时，必须防止另一个作业修改此共享段中的数据，因此：

**不能修改的代码**称为纯代码或可重入代码，这样的代码和**不能修改的数据可以共享**，而**可修改的代码和数据不能共享**

分段管理的保护方法主要有两种：

1. **存取控制保护**：访问内存时查看段表项的保护码检查是否有该操作的权限
2. **地址越界保护**：校验段号和段内地址偏移，保证不会访问过界

**访问内存时要给出段号和段内偏移，因此分段管理的地址空间是二维的**

#### 段页式管理方式

段页式存储管理方式是**页式存储和分段存储的结**合，即**有效地提高内存利用率**，又**反映程序的逻辑结构并有利于段的共享**

在段页式系统中，作业的地址空间首**先被分成若干逻辑段**，每段都有自己的段号，**再将每段分成若干大小固定的页**

对**内存空间的管理仍然和分页存储管理一样**，将其分成若干和页面大小相同的存储块，对内存的分配以存储块为单位

![image-20211111233312557](..\images\image-20211111233312557.png)

在段页式系统中，作业的逻辑地址分为三部分：**段号、页号、页内偏移量**

![image-20211111233335202](..\images\image-20211111233335202.png)

系统为**每个进程建立一张段表，每个分段有一张页表**：段表表项中至少包括**段号、页表长度和页表始址**；页表表项中至少包括**页号和块号**。系统中有一个**段表寄存器**，指出作业的**段表始址和段表长度**

进行地址变换步骤：

1. 通过段表查到页表始址
2. 通过页表找到页帧号
3. 形成物理地址

进行**一次访问实际需要三次访问主存**，可以使用快表来加快查找速度，其**关键字由段号、页号组成**，**值是页帧号和保护码**

![image-20211111233427333](..\images\image-20211111233427333.png)

**访问内存时要给出段号和页号，因此段页式管理的地址空间是二维的**

## 虚拟内存管理

### 虚拟内存的基本概念

#### 传统存储管理方式的特征

上一节的存储管理方式都具有以下两个共同的特征：

1. 一次性：**作业必须一次性全部装入内存后，才能开始运行**这导致：
   - 当<u>作业很大而不能全部被装入内存</u>时，将使该作业无法运行
   - 当<u>大量作业要求运行时，内存不足以容纳所有作业</u>，只能使少数作业先运行，导致多道程序度的下降
2. 驻留性：作业被装入内存后，**不会换出任何内存，直至作业运行结束**，即使进程会因等待 I/O 而被阻塞

程序运行中**暂时不用的程序或数据占据大量的内存空间**，而一些需要运行的作业又无法装入运行，浪费了内存资源

#### 局部性原理

<u>快表、页高速缓存、虚拟内存技术</u>从广义上讲，都属于高速缓存技术，其<u>所依赖的原理是局部性原理</u>

局部性原理适用于程序结构和数据结构，它表现在以下两个方面：

1. 时间局部性：

   - 某条指令一旦执行，不久后**该指令可能再次执行**
   - 某数据被访问过，不久后该**数据可能再次被访问**

   将近来使用的指令和数据保存到高速缓冲存储器中，并使用高速缓存的层次结构实现

2. 空间局部性：一旦程序访问了某个存储单元，在不久后，其**附近的存储单元也将被访问**

   使用较大的高速缓存，并将预取机制集成到高速缓存控制逻辑中实现

虚拟内存技术就是**使用内存对外存进行高速缓存**，使得有外存的容量和内存的速度，**利用局部性原理实现**

#### 虚拟存储器的定义和特征

根据局部性原理得：

1. 程序运行的**部分装入内存，就可启动程序执行**
2. 程序执行过程中，所访问的信息**不在内存时，将其调入内存继续执行**
3. OS 将**暂时不使用的内容换出到外存上，腾出空间放要调入内存的信息**

这样，系统似乎给用户提供了一个比实际内存大得多的存储器，称为**虚拟存储器**（实际上不存在）

这是由系统提供了对用户透明的<u>部分装入、请求调入、置换功能</u>实现的

- **虚拟内存的实际容量 ≤ 内存容量和外存容量之和**
- **虚拟内存的最大容量 ≤ 计算机的地址位数能容纳的最大容量**

虚拟存储器有以下三个主要特征：

1. 多次性：无须在作业运行时一次性地全部装入内存，而**允许被分成多次调入内存运行**
2. 对换性：无须在作业运行时一直常驻内存，而**允许在作业的运行过程中，进行换进和换出**
3. 虚拟性：从逻辑上扩充内存的容量，使**用户所看到的内存容量远大于实际的内存容量**

#### 虚拟内存技术的实现

**虚拟内存的实现需要建立在离散分配的内存管理方式的基础上**，否则将作业分多次调入内存时，难以分配连续内存

虚拟内存的实现有**以下三种方式**：

- 请求分页存储管理
- 请求分段存储管理
- 请求段页式存储管理

不管哪种方式，都需要有一定的**硬件支持**，一般需要：

- 一定容量的**内存和外存**
- **页表机制或段表机制**，作为主要的数据结构
- **中断机构**，当用户程序要访问的部分尚未调入内存时，则产生中断
- **地址变换机构**，逻辑地址到物理地址的变换

### 请求分页管理方式

在基本分页系统基础之上，增加了**请求调页功能和页面置换功能**，从而支持虚拟存储器功能

在请求分页管理方式中：

1. 只需将<u>当前需要的一部分页面装入内存</u>，便可以启动作业运行
2. 在作业执行过程中，<u>要访问的页面不在内存中时，通过调页功能将其调入</u>
3. 还可通过置换功能<u>将暂时不用的页面换出到外存上，以便腾出内存空间</u>

为了实现请求分页需要：**一定容量的内存及外存、页表机制、缺页中断机构、地址变换机构**

#### 页表机制

因为没有一次加载进内存，请求分页系统必须解决的两个基本问题：**如何发现和处理要访问的页面不在内存中的情况**

因此在请求页表项中增加了 4 个字段：

![image-20211113205422298](..\images\image-20211113205422298.png)

- 状态位 P：指示**该页是否已调入内存**，供程序访问时参考
- 访问字段 A：记录本页在一段时间内被访问的次数或多长时间未被访问，**供置换算法换出页面时参考**
- 修改位 M：标识该页在**调入内存后是否被修改过**
- 外存地址：用于指出该页**在外存上的地址**，供调入该页时参考，通常和**物理块号共用**

思考：当程序被挂起时，把页面都调到外存，并修改页表的物理块号，令其为外存地址；这样可以只留最高级页表在内存

#### 缺页中断机构

在请求分页系统中，每当所要访问的页面不在内存中时：

1. **产生一个缺页中断**，请求操作系统将所缺的页调入内存
2. **将缺页的进程阻塞**，调页完成后唤醒
3. 若内存没有空闲块，则要**淘汰某页**，若其**修改位为 1，则要将其写回外存**，此时有空闲块
4. **分配一个空闲块**，将要调入的页装入该块，并**修改页表中的相应页表项**

缺页中断与一般的中断相比，有以下不同的区别：

- 在**指令执行期间产生和处理中断信号**，属于**内部中断**
- 一条指令在执行期间，可能**产生多次缺页中断**
- 执行完中断后会**回到引发中断的指令重新执行**

#### 地址变换机构

请求分页系统中的地址变换机构，是**在分页系统地址变换机构的基础上**，为实现虚拟内存又**增加了某些功能**而形成的

![image-20211113205529519](..\images\image-20211113205529519.png)

一般来说**只需修改快表中的快表项**，只有要将**快表项删除时才需要写回内存中的页表**

1. 当快表查询成功时，要**修改访问位，写指令要额外修改修改位**，最后**计算出物理地址**；若失败就去读页表
2. 页表找到表项后检查状态位，若**在内存将表项复制到快表**转步骤 1，若**在外存则产生缺页中断**
3. 页面调入内存后，需要**修改页表**，同时也需要**将表项复制到快表中**，转步骤 1

### 页面置换算法

页面对换时，若内存已无空闲空间，就需要**使用页面置换算法从内存中调出一页程序或数据**到外存

好的页面置换算法应有较低的页面更换频率，应将**以后或较长时间内不会再访问的页面先调出**

#### 最佳 OPT 置换算法

最佳置换算法：被淘汰页面是**永不使用或最长时间内不再被访问**的页面，**缺页率最低**，因无法预知未来**该算法无法实现**

最佳置换算法**用来评价其他算法**；下面是例子有 3 个物理块，和页面引用串，**每次置换出最晚访问的页面**：

![image-20211113224027924](..\images\image-20211113224027924.png)

#### 先进先出 FIFO 页面置换算法

优先**淘汰最早进入内存的页面**；该算法**与进程实际运行时的规律不适应**，进入内存的时间和以后是否访问没有关系

下面是例子，数据和上面的一样，但这里进行了 12 次页面置换：

![image-20211113224308406](..\images\image-20211113224308406.png)

Belady 异常：产生所分配的**物理块数增大而页故障数不减反增**的异常现象，**只有 FIFO 算法可能出现 Belady 异常**

下面是 Belady 的例子，物理块增大了，但缺页次数不减反增：

![image-20211113224342794](..\images\image-20211113224342794.png)

#### 最近最久未使用 LRU 置换算法

淘汰**最近最长时间未访问过的页面**，它认为过去一段时间内未访问过的页面，在最近的将来可能也不会被访问

该算法为每个页面**设置一个访问字段**，记录页面自上次被访问以来所经历的时间，淘汰时**选择现有页面中值最大的予以淘汰**

![image-20211113224416563](..\images\image-20211113224416563.png)

LRU 算法是向前看的，最佳置换算法是向后看的；LRU 算法的性能较好，但**需要寄存器和栈的硬件支持**

LRU 是堆栈类的算法，**堆栈类算法不可能出现 Belady 异常**；LRU 耗费高的原因是要对所有页进行排序

#### 时钟 CLOCK 置换算法

CLOCK 算法给每帧关联一个附加位，称为**使用位**：

1. 当某页**首次装入主存或再被访问**时，将该帧的**使用位设置为 1**
2. 有一个指针指向用于替换的候选帧集合（看作循环缓冲区），**一页被替换时，指针指向下一帧**
3. 需要替换一页时，**从指针位置开始循环查找**，找出**使用位为 0 的来替换**，把**跳过的帧的使用位 1 的帧置为 0**

因为算法要**循环扫描缓冲区**，像时钟的指针一样转动，所以称为 CLOCK 算法，又称**最近未用 NRU 算法**

CLOCK 算法的性能比较接近 LRU 算法，而通过增加使用的位数目，可以使得 CLOCK 算法更加高效

下面使用一个例子来详细说明 CLOCK 算法：

![image-20211114165819204](..\images\image-20211114165819204.png)

进程依次访问 1, 3, 4, 2, 5 号页面，系统会将这些页面连成一个循环队列，刚开始扫描指针指向第一个被访问的页面，如图 a

进程请求访问 6 号页面，选择一个页面置换出去，在第一轮扫描中，指针扫过的页面的使用位置为 0，如图 b

第二轮扫描中换出首个使用位为 0 的页面，换入 6 号页面并设置访问位为 1，将扫描指针后移，下次从 3 号页开始，如图 c

注意：1 号页面原先占有的是 x 号物理块，则 6 号页面换入内存后也放在 x 号物理块中

#### 改进型 CLOCK 置换算法

改进型 CLOCK 置换算法：在使用位的基础上**再增加一个修改位**

每帧都处于以下 4 种情况之一：

1. 未访问未修改：u = 0, m = 0
2. 被访问未修改：u = 1, m = 0
3. 未访问被修改：u = 0, m = 1
4. 被访问被修改：u = 1, m = 1

算法执行如下操作步骤：

1. 从指针的当前位置开始，扫描帧缓冲区**选择 u = 0, m = 0 来替换，不做任何修改**
2. 若第 1 步失败，则重新扫描，**选择 u = 0, m = 1 来替换**，每个**跳过的帧的使用位设置成 0**
3. 若第 2 步失败，返回第 1 步

改进型 CLOCK 算法**首选没访问的页，次选没修改的页**，没修改的页被替换时**不用写回**，这样做会节省时间

优化页面置换算法的原则：**尽可能保留曾经使用过的页面**，而**淘汰未使用的页面**，认为可以在总体上减少换页次数

### 页面分配策略

#### 驻留集大小

进程的**驻留集**：给一个进程**分配的物理页框的集合**；操作系统必须**决定给特定的进程分配几个页框**

需要考虑以下几点：

1. 驻留集越小，驻留在主存中的进程数就越多，可以**提高处理机的时间利用效率**
2. 驻留集过少，则尽管有局部性原理，**页错误率仍然会相对较高**
3. 驻留集过多，则由于局部性原理，分配更多的主存空间**对该进程的错误率没有明显的影响**

页面的分配置换策略有：

- 固定分配：操作系统为进程分配好物理块后，**驻留集大小不变**
- 可变分配：操作系统为进程分配好物理块后，**驻留集大小可变**
- 局部置换：只能选进程**自己的物理块进行置换**
- 全局置换：可以**从操作系统拿物理块**，也可以**抢其他进程的物理块**

现代操作系统通常采用三种策略，<u>开始时都为进程分配一定的物理块</u>：

1. 固定分配 + 局部置换：**驻留集固定**，缺页时**只能从自己的物理块进行置换**

   **难以确定驻留集大小**：太少会频繁出现缺页中断，太多又会使 CPU 和其他资源利用率下降

2. 可变分配 + 全局置换：**驻留集可变**，缺页时 OS 会**从空闲块中分配一个物理块给该进程**，最简单的策略

   可以动态的增加物理块，但也**会盲目地给进程增加物理块**，从而**导致系统多道程序的并发能力下降**

3. 可变分配 + 局部置换：**驻留集可变**，缺页时只能从自己的物理块进行置换，但 OS **根据缺页率动态调整驻留集**

   优点：在**保证进程不会过多地调页**的同时，也**保持了系统的多道程序并发能力**

   缺点：需要**更复杂的实现**，也需要**更大的开销**，但对比频繁地换入/换出所浪费的计算机资源，这种牺牲是值得的

注意：没有固定分配 + 全局置换，因为全局置换就会增加物理块与固定分配矛盾

#### 物理块调入算法

采用固定分配策略时，将系统中的空闲物理块分配给各个进程的算法有：

1. 平均分配算法：将系统中所有可供分配的物理块**平均分配给各个进程**
2. 按比例分配算法：根据进程的大小**按比例分配物理块**
3. 优先权分配算法：为**重要和紧迫**的进程分配较多的物理块

通常把所有可分配的物理块分成两部分：部分按比例分配；部分按优先权分配

#### 调入页面的时机

为确定系统将进程运行时所缺的页面调入内存的时机，有以下调页策略：

1. 预调页策略：<u>一次调入多页比多次调入多页时间要短</u>，可以根据局部性原理，**一次调入多个相邻页**

   这样可能会更高效，但若调入页面中大多数都未被访问又是低效的

   因此需要采用以预测为基础的预调页策略，但目前预调页的成功率仅约 50%

   因此**主要用于进程的首次调入**，由程序员指出应先调入哪些页，如调入 main 函数

2. 请求调页策略：访问的页面不在内存时，**请求 OS 将所需页面调入内存**

   调入的页**一定会被访问**，且策略**更易于实现**，故目前的虚拟存储器中**大多采用此策略**

   缺点：每次只调入一页，<u>调入/调出页面数多时会花费过多的 I/O 开销</u>

预调入就是**运行前的调入**，请求调页就是**运行期间调入**；通常两种调页策略会**同时使用**

#### 从何处调入页面

外存分为**离散分配方式的文件区**和**连续分配方式的对换区**，因此**对换区的磁盘 I/O 速度比文件区的更快**

从何处调入页面存在三种情况：

1. 系统拥有足够的对换区空间：运行前，将进程有关的文件**复制到对换区**；运行时，**从对换区调入所需页面**

2. 系统缺少足够的对换区空间：

   刚开始进程有关的文件**都从文件区读入**，换出时：

   - 不会被修改的文件**直接覆盖**
   - 可能被修改的文件**换到对换区**，需要时再从对换区调入（读比写快）

3. UNIX 方式：

   与进程有关的文件都放在文件区，因此**未运行过的页面都应从文件区调入**

   **换出是都换出到对换区**，曾经运行过但又被换出的页面，下次调入时应从对换区调入

   进程请求的共享页面若已被其他进程调入内存，则无须再从对换区调入

#### 如何调入页面

1. 当进程访问的页面的**存在位为 0**，则向 CPU 发出缺页中断，转入缺页中断处理程序

2. 如果内存未满，则启动磁盘 I/O，将所缺页**调入内存，并修改页表**

3. 如果内存已满，则按某种置换算法**从内存中选出一页准备换出**

   如果该页修改位为 0，则无须写回磁盘；如果该页修改位为 1，则必须写回磁盘（对换区）

   将所缺页调入内存，并修改页表中的相应表项，置其存在位为 1

4. 调入完成后，进程就可通过页表得到要访问数据的内存地址

### 抖动

抖动，颠簸：**频繁进行页面调度**，如刚换出又要换入，刚换入又要换出，这是由 CPU 的**调度算法不合理**引起的

进程在颠簸：一个进程**在换页上用的时间多于执行时间**

频繁发生缺页中断的主要原因：某个进程频繁**访问的页面数目高于可用的物理页帧数目**

虚拟内存技术可在内存中**保留更多的进程以提高系统效率**

在稳定状态，几乎主存的所有空间都被进程块占据，处理机和操作系统可以直接访问到尽可能多的进程

如果管理不当，那么处理机的**大部分时间都将用于交换块**，会大大降低系统效率

### 工作集

基于局部性原理，可以**用最近访问过的页面来确定工作集**，最近访问的页面以后很可能会再访问

工作集：**在某段时间间隔内，进程要访问的页面集合**，工作集 W 可由时间 t 和工作集窗口大小 $\Delta$ 来确定

工作集<u>反映了进程在接下来的一段时间内很有可能会频繁访问的页面集合</u>

例如，某进程对页面的访问次序如下：

假设工作集窗口大小 $\Delta$ 为 5，则在 $t_1$ 时刻，进程的工作集为{2,3,5}，在 $t_2$ 时刻，进程的工作集为{1,2,3,4}

![image-20211113224837075](..\images\image-20211113224837075.png)

实际应用中，工作集窗口会设置得很大，即对于<u>局部性好的程序，工作集大小一般会比工作集窗口 $\Delta$ 小很多</u>

若**驻留集大小小于工作集大小**，则该进程就很有**可能频繁缺页**，为防止这种抖动现象，**驻留集大小要大于工作集大小**

工作集模型的原理是：

- 让操作系统**跟踪每个进程的工作集**，并为进程**分配大于其工作集的物理块**
- 工作集内的页面需要**调入驻留集中**，工作集外的页面可**从驻留集中换出**
- 若还有**空闲物理块**，则可以再**调一个进程到内存**以增加多道程序数
- 若所有**工作集之和超过可用物理块数**，则**暂停一个进程**，将其页面调出并将其物理块分配给其他进程，以防止抖动

### 内存映射文件

内存映射文件：用**系统调用**将磁盘文件**映射到虚拟地址空间的某处**，以**访问内存的方式**访问文件，文件 I/O 由 OS 处理

这种特性非常适合用来管理大尺寸文件，磁盘的周期性分页是由操作系统在后台隐蔽实现的，对用户透明

虚拟存储器以统一的方式处理所有磁盘 I/O，当进程**退出或显式地解除文件映射时**，所有被改动的页面会被**写回磁盘文件**

多个进程允许**并发地内存映射到同一文件**，来进行**进程通信**，内存映射文件充当通信进程之间的共享内存区域

一个进程写了共享内存，此刻当另一个进程读这个映射文件时，就能立刻看到上一个进程的写结果

优点：

- **程序员编程更简单**，已建立映射的文件，只需按访问内存的方式读写即可
- 文件数据的读入/写出完全由操作系统负责，**I/O 效率可以由操作系统负责优化**（预读入，缓写出等）



![image-20220718223920318](..\images\image-20220718223920318.png)

### 虚拟存储器性能影响因素

缺页率（缺页率高即为抖动）是影响虚拟存储器性能的主要因素

缺页率受到**页面大小、分配给进程的物理块数、页面置换算法、程序的编制方法**的影响：

1. 选择合适的页面大小，页面较大则缺页率较低，内部碎片会更大；页面较小则缺页率较高，页表会更长

2. 分配给进程的物理块数越多，缺页率就越低，但无需分配太多，**保证活跃页面在内存中**，使缺页率在很低的范围即可

3. **选择 LRU、CLOCK 等置换算法**，将未来有可能访问的页面尽量保留在内存中，从而提高页面的访问速度

   建立一个**已修改换出页面的链表**，长度达到某值时一起写回磁盘，来**减少磁盘 I/O 的次数**，减少已修改页面换出开销

   在未写回磁盘时再次访问这些页面，就**直接从已修改换出页面链表上获取**，减少页面换进的开销

4. **编写程序的局部化程度越高，执行时的缺页率就越低**：若存储采用的是按行存储，访问时就应尽量采用按行访问

# 文件管理

## 文件系统基础

### 文件的概念

#### 文件的定义

文件是**以计算机硬盘为载体的存储在计算机上的信息集合**，可以是文本文档、图片、程序等

在用户进行的输入、输出中，<u>以文件为基本单位</u>；大多数应用程序**从文件输入，也输出到文件**，以实现信息长期存储

操作系统中的文件系统 File System 用于实现用户或应用程序对文件进行**创建、访问、修改**等

文件包括：**一块存储空间**用于存储数据、**分类和索引的信息**、**访问权限的信息**

文件系统提供了<u>与二级存储（除内存外可以访问数据的存储器）相关的资源的抽象</u>，让用户可以<u>方便快捷地使用文件</u>

文件的结构（自底向上）如下：

1. 数据项：数据项是文件系统中最低级的数据组织形式，分为：
   - 基本数据项：描述**一个对象的某种属性的一个值**，是数据中可命名的最小逻辑数据单位，即原子数据
   - 组合数据项：由**多个基本数据项组成**
2. 记录：**一组相关的数据项的集合**，用于描述一个对象在某方面的属性
3. 文件：文件是指由创建者所定义的一组相关信息的集合，逻辑上可分为：
   - 有结构文件：**由一组相似的记录组成**，又称记录式文件，如 Excel 表
   - 无结构文件：二进制文件或字符文件，又称流式文件

在操作系统中，通常将程序和数据组织成文件；文件基本访问单元可以是字节、行或记录

文件可以长期存储于硬盘或其他二级存储器中，**允许可控制的进程间共享访问，能够被组织成复杂的结构**

额外：逻辑地址：**逻辑上磁盘的块号**，因为一块可能等于多个扇区；物理地址：**柱面号·盘面号·扇区号**

#### 文件的属性

文件通常包括如下属性：

1. 名称：文件名称**唯一**，以容易读取的形式保存
2. 创建者：文件创建者的 ID
2. 所有者：文件当前所有者的 ID
3. 类型：被支持不同类型的文件系统所使用，如 `.txt` 类型
4. 位置：指向设备和设备上文件的指针
5. 大小：文件当前大小，也可包含文件允许的最大值
6. 保护：对文件进行保护的访问控制信息
7. 时间：创建、修改、访问日期和用户标识

所有**文件的信息都保存在目录结构中**，而目录结构保存在外存上，需要时才调入内存

### 文件控制块和索引结点

#### 文件控制块

文件控制块 FCB 是用来存放控制文件需要的各种信息的数据结构，以实现“按名存取”

FCB 的有序集合称为文件目录，**一个 FCB 就是一个文件目录项**

创建一个新文件，系统将分配一个 FCB 并存放在文件目录中，成为目录项

![image-20220720212541797](..\images\image-20220720212541797.png)

FCB 主要包含以下信息：

- **基本信息**，如文件名、文件的物理位置、文件的逻辑结构、文件的物理结构等
- **存取控制信息**，如文件存取权限等
- **使用信息**，如文件建立时间、修改时间等

一个文件目录也被视为一个文件，称为目录文件

#### 索引结点

在检索目录文件的过程中，只用到了文件名，仅当找到一个目录项时，才需要从该目录项中读出该文件的物理地址

因此，有的系统采用**文件名和文件描述信息分开**的方法，文件描述信息**单独形成一个称为索引结点的数据结构**，简称 i 结点

在文件目录中的每个目录项仅由**文件名**和指向该文件所对应的 **i 结点的指针**构成（把 FCB 分割为两部分）

![image-20211116163535479](..\images\image-20211116163535479.png)

使用索引结点后，目录项的大小缩小很多，一个盘块可以装更多的目录项，从而**减少平均启动磁盘次数**

注意：读入索引结点也需要一次磁盘 I/O 操作，要注意审题

##### 磁盘索引结点

存放在磁盘上的索引结点称为**磁盘索引结点**，UNIX 中的每个文件都有一个唯一的磁盘索引结点

磁盘索引节点主要包括以下内容：

- 文件主标识符：拥有该文件的个人或小组的标识符
- 文件类型：包括普通文件、目录文件或特别文件
- 文件存取权限：各类用户对该文件的存取权限
- 文件物理地址：每个索引结点中含有 13 个**地址项**，即 `iaddr(0)-iaddr(12)`，直接或间接地**给出数据文件所在盘块的编号**
- 文件长度：以字节为单位
- 文件链接计数：在本文件系统中所有**指向该文件的文件名的指针计数**
- 文件存取时间：本文件最近被进程存取的时间、最近被修改的时间及索引结点最近被修改的时间

##### 内存索引结点

是指存放在内存中的索引结点，文件被打开时，磁盘索引结点复制到内存的索引结点中，以便于使用

内存索引结点中又增加了以下内容：

- 索引结点编号：用于标识内存索引结点
- 状态：指示 i 结点是否上锁或被修改
- 访问计数：每当有一进程要访问此 i 结点时，计数加 1，访问结束减 1
- 逻辑设备号：文件所属文件系统的逻辑设备号
- 链接指针：设置分别**指向空闲链表**和散列队列的指针

### 文件操作

#### 文件的基本操作

文件属于**抽象数据类型**，下面是有关文件的操作，通过系统调用使用：

1. 创建文件，两个必要步骤：

   - 在文件系统中**为文件找到空间**
   - **在目录中为新文件创建条目**

2. 写文件：

   对于给定文件名称，系统搜索目录以**查找文件位置**

   系统维护一个写位置的指针，每当发生写操作时，**写入并更新写指针**

3. 读文件：

   对于给定文件名称，系统搜索目录以**查找文件位置**

   系统维护一个读位置的指针，每当发生读操作时，**读出并更新读指针**

   一个进程通常对一个文件只进行读或写，因此**只维护文件位置指针，由读写共用**

5. 重新定位文件，文件定位：搜索目录以找到适当的条目，**修改文件位置指针到给定值**（不涉及读、写文件）

6. 删除文件：先从目录中找到要**删除文件的目录项**，然后**回收该文件所占用的存储空间**，最后删除目录条目

7. 截断文件：允许文件所有属性不变，**仅删除文件内容**

基本操作可以**组合起来执行其他文件操作**，如复制 = 创建 + 读 + 写；对于实际的系统调用如 read 等，**参数以 Linux 为准**

#### 文件的打开与关闭

操作系统在处理 open 系统调用时，主要做了：

1. 根据文件存放路径找到相应的目录文件，从目录中**找到文件名对应的的目录项**，并检查该用户的操作权限
2. 若有权限，则将**目录项复制到内存中的“打开文件表”**中。并将**对应表目的编号返回给用户**（文件描述符）

注意：在打开文件以后，对文件的操作不需要文件名，而**使用打开文件表的编号来指明要操作的文件**

**整个系统有一个打开文件表**，记录 FCB 和其他信息；**每个进程有一个打开文件表**，记录系统打开表的索引和其他信息

![image-20220720220231922](..\images\image-20220720220231922.png)

每个打开文件都有如下关联信息：

- 文件指针：**当前文件内的位置的指针**，对打开文件的某个**进程来说是唯一的**
- 文件打开计数：**在系统打开表中**，以**记录多少进程打开了该文件**，打开时加一，关闭时减一，**为零时才回收资源**
- 文件磁盘位置：该信息保存在系统打开表项中，以免为每个操作都从磁盘中读取
- 访问权限：每个进程打开文件都需要有一个访问模式，以便操作系统能够允许或拒绝之后的 I/O 请求

注意：打开已经被打开的文件时，为**对应进程的打开表增加条目**，系统打开表的对应条目的**文件打开计数加一**

### 文件保护

为了<u>防止文件共享可能会导致文件被破坏或未经核准的用户修改文件</u>，文件系统必须控制用户对文件的存取

文件保护通过口令保护、加密保护和访问控制等方式实现

口令保护和加密保护是为了**防止用户文件被他人存取或窃取**，而访问控制则用于**控制用户对文件的访问方式**

#### 访问类型

对文件的保护可从限制对文件的访问类型中出发：

- 读：从文件中读
- 写：向文件中写
- 执行：将文件装入内存并执行
- 添加：将新信息添加到文件结尾部分
- 删除：删除文件，释放空间
- 列表清单：列出文件名和文件属性

此外还可以对文件的重命名、复制、编辑等加以控制，这些功能可以**由上面的功能完成**，故**保护可以只在低层提供**

如具有读访问权限的用户同时也就具有了复制和打印权限

#### 访问控制

##### 访问控制

**根据用户身份进行控制**，为每个文件和目录**增加一个访问控制列表 ACL**，以**规定每个用户名及其所允许的访问类型**

优点：可以使用复杂的访问方法；缺点：长度无法预计并且可能导致复杂的空间管理

精简的访问列表可以解决这个问题，它采用**拥有者、组和其他**三种用户类型：

1. 拥有者：创建文件的用户
2. 组：与创建文件在同一个用户组的用户
3. 其他：系统内的所有其他用户

只需用三个域即可列出访问表中这三类用户的访问权限：

1. 文件拥有者在创建文件时，**说明创建者用户名及所在的组名**，系统会**列在文件的 FCB 中**
2. 用户**访问该文件时，查看其访问权限**：
   - 若是拥有者，按拥有者权限
   - 若用户和拥有者在同一个用户组，则按照同组权限
   - 否则按其他用户权限

选择题：用户访问**优先级**，指多个用户访问同一个文件谁先访问，但文件不是谁先访问谁就能访问的

- 文件属性是文件自带的属性，如 pdf 文件是只读的，即使有写权限也不能写

##### 口令和密码

- 口令：用户在**创建文件时提供一个口令**，放在 FCB 上，告诉共享此文件的其他用户，访问时**必须提供相应的口令**

  优点：时间和空间的开销不多；缺点：口令直接存在系统内部，不够安全

- 密码：用户**对文件进行加密**，文件被**访问时需要使用密钥**

  优点：保密性强，节省了存储空间；缺点：编码和译码要花费一定的时间

口令和密码都是**防止用户文件被他人存取或窃取**，并没有控制用户对文件的访问类型

注意两个问题：

1. 现代 OS 常用方法：将**访问控制列表**与**用户、组和其他成员访问控制方案**一起组合使用
2. 目录结构而言，需要保护单个文件和子目录内的文件，故需要提供目录保护机制（与文件保护机制不同）

### 文件的逻辑结构

文件的逻辑结构：从**用户观点**出发看到的文件的组织形式

文件的物理结构：从**实现观点**出发看到的文件在外存上的存储组织形式

思考：文件逻辑结构：文件是怎么样的；文件物理结构：文件是怎样存储的

注意：这里的文件逻辑结构是**文件的内部逻辑结构**，外部逻辑结构是[目录结构](#目录结构)

注意：这里是逻辑结构，里面的地址或指针的内容都是**逻辑地址**，而不是物理地址

#### 无结构文件（流式文件）

无结构文件是最简单的文件组织形式，它将数据按顺序组织成记录，是有序相关信息项的集合，<u>以字节 Byte 为单位</u>

由于无结构文件没有结构，因而对记录的访问只能通过穷举搜索的方式，因此这种文件形式对大多数应用不适用

但字符流的无结构文件管理简单，<u>用户可以方便地对其进行操作</u>

所以，那些对基本信息单位操作不多的文件较适于采用字符流的无结构方式，如源程序文件、目标代码文件等

#### 有结构文件（记录式文件）

##### 顺序文件

文件中的记录**一个接一个地顺序排列**，记录通常是定长的，可以**顺序存储或链表形式存储**

顺序文件有以下两种结构：

1. 串结构：记录之间的**顺序与关键字无关**，通常由时间决定

2. 顺序结构：指文件中的所有记录**按关键字顺序排列**

   只有顺序结构，**顺序存储且记录定长**时可随机存储（按关键字随机存储）

在对记录进行批量操作，即每次要读或写一大批记录时，顺序文件的效率是**所有逻辑文件中最高的**

只有顺序文件才能存储在磁带上，并能有效地工作，但顺序文件对**增加或删除单条记录的操作比较困难**

##### 索引文件

索引文件由**索引表和逻辑文件**组成，索引表指出逻辑文件长度及在整个文件中的相对位置，是**逻辑地址**

**顺序文件的变长记录只能顺序查找**系统开销较大，故建立一张索引表以加快检索速度，**索引表本身是定长记录的顺序文件**

在记录很多或访问要求高的文件中，需要引入索引以提供有效的访问，这样即使变长记录也能随机访问以提高速度

思考：这里的索引号其实是键值 int 型，而索引顺序文件的键值是字符串型，所以分两张表查找更快

![image-20211116163246366](..\images\image-20211116163246366.png)

##### 索引顺序文件

索引顺序文件是**顺序和索引两种组织形式的结合**，索引顺序文件**将顺序文件中的所有记录分为若干组**

为顺序文件建立一张索引表，在索引表中**为每组中的第一条记录建立一个索引项**，包含记录的关键字值和指向该记录的指针

主文件中记录分组排列，**同一个组中的关键字可以无序，但组与组之间的关键字必须有序**

查找一条记录时，首先**通过索引表找到其所在的组**，然后**在该组中使用顺序查找**，就能很快地找到记录

![image-20211116163339142](..\images\image-20211116163339142.png)

在索引顺序文件中，N 条记录分为 $\sqrt N$ 组，每组有 $\sqrt N$ 条记录，则平均查找查找次数为 $\dfrac {\sqrt N} 2+\dfrac{\sqrt N}2 =\sqrt N$

**索引顺序文件提高了查找效率**，若记录数很多，则可采用两级或多级索引（数据结构的分块查找）

索引文件和索引顺序文件都提高了存取的速度，但**因为配置索引表而增加了存储空间**

##### 直接文件或散列文件

给定记录的键值或**通过散列函数转换的键值直接决定记录的逻辑地址**

这种映射结构不同于顺序文件或索引文件，**没有顺序的特性**

散列文件有很高的存取速度，但是会引起冲突，即不同关键字的散列函数值相同

思考：有结构文件的逻辑上的组织，是为在文件中查找数据服务的

### 文件的物理结构

文件实现就是研究**文件数据在物理存储设备上是如何分布和组织的**

文件的分配方式，是**对磁盘非空闲块的管理**，指**如何为文件分配磁盘块**

常用的分配方法有三种：连续分配、链接分配和索引分配；通常一个文件系统只支持一种方法，但也有三种都支持的

思考：因为文件分配是**按块（簇）分配**，不足两个扇区的内容也会占两个扇区（**块是扇区的整数倍**），**会有内部碎片**

额外：块是 UNIX 的说法，簇是 Windows 的说法，它们是一个东西；文件的 xx 结构说得就是物理结构

#### 连续分配

连续分配方法要求**每个文件在磁盘上占有一组连续的块**，这种方法作业访问磁盘时需要的**寻道数和寻道时间最小**

![image-20211118110140439](..\images\image-20211118110140439.png)

文件的连续分配的一个文件的目录条目包括**开始块的地址和该文件所分配区域的长度**

连续分配支持**顺序访问和直接访问**，其优点是**实现简单、存取速度快**

缺点：

1. **文件长度不宜动态增加**
2. 反复增删文件后**会产生外部碎片**
3. 很难确定一个文件需要的空间大小，因而**只适用于长度固定的文件**

#### 链接分配

链接分配采取离散分配的方式，**消除了外部碎片**，显著**提高了磁盘空间的利用率**

可以动态地为文件分配盘块，**无须事先知道文件的大小**，对文件的**增、删、改也非常方便**

选择题：记录成组分解技术是不可跨越“块”存储记录，会有内部碎片（一个记录不会被放在两个块中）

##### 隐式链接

文件的**磁盘块分散**，除最后一个盘块外，每个盘块**有指向下一个盘块的指针**，目录条目 = **首块地址 + 尾块地址或块数**

![image-20211118110249291](..\images\image-20211118110249291.png)

文件刚创建时，**首块的指针为 NULL**，**大小字段为 0**，写文件会把空闲块链接到文件的尾部

缺点是无法直接访问盘块，**只能通过指针顺序访问文件**，且**盘块指针会消耗一定的存储空间**

- 将几个盘块组成簇，按簇来分配，可以成倍地减少查找时间和指针空间，但会增加内部碎片

稳定性也是一个问题：系统在运行过程中由于软件或硬件错误导致链表中的指针丢失或损坏，会**导致文件数据的丢失**

##### 显式链接

把下一块指针从每个物理块的块末尾中**提取出来**，显式地**存放在内存的一张链接表中**，称为**文件分配表 FAT**

FAT 在**整个磁盘中仅设置一张**，每个**表项中存放对应块的下一块链接指针**

文件的**第一个盘块号记录在目录条目中**，后续的盘块可通过查 FAT 找到

可以用一个特殊的数字 -1 表示文件的最后一块，用 -2 表示这个磁盘块是空闲的，如下图

![image-20211118110405890](..\images\image-20211118110405890.png)

FAT 记录了**文件各块之间的先后链接关系**和**空闲的磁盘块**，OS 可以通过 FAT **对文件存储空间进行管理**

当某进程请求操作系统分配一个磁盘块时，操作系统**从 FAT 中找到空闲块分配给进程**

FAT 表在系统**启动时就会被读入内存**，因此**查找 FAT 的过程是在内存中进行的**，提高了检索速度，减少了访问磁盘的次数，但同时也需要**消耗一定的内存资源**（打开某文件时，其实只需将其盘块的编号放入内存即可）

#### 索引分配

索引分配在链接分配的基础上**解决了不能直接访问**和 FAT 占用内存大，它用**每个文件**的所有的盘块号**构成索引块**（表）

![image-20211118110536939](..\images\image-20211118110536939.png)

**每个文件都有其索引块**，索引块的第 i 个条目指向文件的第 i 个块，**目录条目包括索引块的地址**

创建文件时，索引块的**所有指针都设为空**，首次写入第 i 块时，OS 分配空闲块并**将其地址写到索引块的第 i 个条目**

优点：索引分配**支持直接访问**，且**没有外部碎片问题**；缺点：由于索引块的分配，**增加了系统存储空间的开销**

索引块大小难以确定，可以采用以下机制来处理索引块大小问题：

- 链接方案：当索引块大小**超过一个磁盘块时**，按磁盘块拆开并**链接起来**

- 多层索引：**第一层索引块指向第二层的索引块，第二层索引块再指向文件块**，可扩展更多层

- 混合索引：将多种索引分配方式相结合的分配方式，如索引表包含 3 个直接索引 1 个单级索引 1 个二级索引

  这样既可以在**文件小时索引表小**，又在**文件大时索引表仍然可以索引**

通常将文件的索引块读入内存的缓冲区中，以加快文件的访问速度

#### 三种分配方式的比较

![image-20211118110658949](..\images\image-20211118110658949.png)

#### 混合索引分配

采用混合索引分配方式来照顾到小型、中型、大型和特大型文件：

- 小文件：**盘块地址直接放入 FCB**，直接从 FCB 中获得该文件的盘块地址，即直接寻址
- 中型文件：先从 FCB 中找到该文件的**索引表**，再获取该文件的盘块地址，即为一次间址
- 大型或特大型文件：采用**两级和三级索引分配方式**

![image-20220721194042172](..\images\image-20220721194042172.png)

UNIX 系统采用的就是这种分配方式，在其索引结点中，共设有 13 个地址项 `i.addr(0) ~ i.addr(12)`：

1. 直接地址：**用 `i.addr(0) ~ i.addr(9)` 来存放直接地址**（设置10个直接地址项）共 `40KB`
2. 一次间接地址：利用索引结点中的地址项 **`i.addr(10)` 存放一次间接地址**，块中可存放 1024 个盘块号，共 `4MB`
3. 多次间接地址：地址项 **`i.addr(11)` 存放二次间接地址**，共 `4GB`；**地址项 `iaddr(12)` 作为三次间址块**，共 `4TB`

### FAT 真题

某磁盘文件系统使用链接分配方式组织文件，簇大小为 `4KB`。目录文件的每个目录项包括文件名和文件的第一个簇号，其他簇号存放在文件分配表 FAT 中。

![image-20220722205218078](..\images\image-20220722205218078.png)

1. 假定目录树如图所示，各文件占用的簇号及顺序如下表所示，其中 `dir, dir1` 是目录，`file1, file2` 是用户文件。请给出所有目录文件的内容。
2. 若 FAT 的每个表项仅存放簇号，占 `2B`，则 FAT 的最大长度为多少字节？该文件系统支持的文件长度最大是多少？
3. 系统通过目录文件和 FAT 实现对文件的按名存取，说明 `file1` 的 106, 108 两个簇号分别存放在 FAT 的哪个表项中。
4. 假设仅 FAT 和 `dir` 目录文件已读入内存，若需将文件 `dir/dir1/file1` 的第 5000 个字节读入内存，则要访问哪几个簇？

解答：

1. 两个目录文件 `dir` 和 `dirl` 的内容如下表所示

   ![image-20220722205321395](..\images\image-20220722205321395.png)

2. 由于 FAT 的簇号为 2 个字节，因此在 FAT 表中最多允许 $2^{16}$ 个表项，即 $2^{16}$ 个簇

   FAT 的最大长度为 $2^{16}×2B = 128KB$，文件的最大长度是 $2^{16}×4KB = 256MB$

3. 在 FAT 的每个表项中存放下一个簇号，`file1` 的簇号106 在 FAT 的 100 号表项中，簇号 108 在 FAT 的 106 号表项中

4. 由于 `dir` 目录已在内存中，先在 `dir` 目录文件里找到 `dir1` 的簇号，然后读取 48 号簇，得到 `dir1` 目录文件，接着找到 `file1` 的第一个簇号，据此在 FAT 里查找 `file1` 的第 5000 个字节所在的簇号，最后访问磁盘中的该簇

   因此，需要访问目录文件 `dir1` 所在的 48 号簇，及文件 `file1` 的 106 号簇

## 目录

### 目录的基本概念

文件目录把**文件管理系统和文件集合相关联**，它包含有关文件的信息，这些信息主要由操作系统进行管理

首先我们来看目录管理的基本要求：

1. 从用户的角度看，目录管理**要实现按名存取**
2. 目录存取的效率直接影响到系统的性能，所以**要提高对目录的检索速度**
3. 在共享系统中，目录还需**要提供用于控制访问文件的信息**

应允许**不同用户对不同文件采用相同的名字**，以便于用户按自己的习惯给文件命名，目录管理通过树形结构来解决和实现

目录结构即多个文件之间在逻辑上是如何组织的，这实际上是<u>文件“外部”的逻辑结构的问题</u>

### 目录结构

#### 单级目录结构

在整个文件系统中**只建立一张目录表**，每个文件占一个目录项

![image-20211116163653000](..\images\image-20211116163653000.png)

- 访问文件：先按文件名在该目录中**查找到相应的 FCB**，经合法性**检查后执行相应的操作**
- 创建文件：先检索所有目录项确保**没有重名的情况**，然后在该目录中**增设一项**，把 FCB 的全部信息保存在该项中
- 删除文件：先从该目录中找到该文件的目录项，**回收该文件所占用的存储空间，然后清除该目录项**

实现了按名存取，但是存在查找速度慢、**文件不允许重名、不便于文件共享**等缺点，而且不适合多用户的操作系统

#### 两级目录结构

单级目录很容易造成文件名称的混淆，因此将文件目录分成**主文件目录和用户文件目录**两级

主文件目录项记录**用户名及相应用户文件目录所在的存储位置**，用户文件目录项记录**该用户文件的 FCB 信息**

当用户访问其文件时，<u>在自己的目录中搜索</u>，则用户间不会重名，且一定程度上保证了文件的安全

优点：解决**多用户之间的文件重名问题**，文件系统可以**在目录上实现访问限制**；缺点：缺乏灵活性，不能对文件分类

![image-20211116163800336](..\images\image-20211116163800336.png)

#### 多级目录结构

**将两级目录结构的层次关系加以推广**，就形成了多级目录结构，即**树形目录结构**，可以明显地提高对目录的检索速度

访问文件：用**文件的路径名标识文件**，文件路径名是个字符串，**目录名与数据文件名用分隔符 “/” 链接而成**

绝对路径：**从根目录出发的路径**，当层次较多时，每次从根目录查询会浪费时间

相对路径：进程对各文件的访问都是**相对于当前目录进行（工作目录）的**，一般使用 ./ 表示当前目录

![image-20211116163855139](..\images\image-20211116163855139.png)

每个用户<u>都有各自的当前目录</u>，登录后自动进入该用户的当前目录，用户可以<u>使用系统调用随时改变当前目录</u>

优点：**很方便地对文件进行分类**，层次结构清晰，**有效地进行文件的管理和保护**

缺点：查找一个文件时，需要按路径名逐级访问中间结点，**增加了磁盘访问次数，影响查询速度**

**减少磁盘 I/O 方法**：使用索引结点、设置当前目录（当前目录会放入内存中）

#### 无环图目录结构

在树形目录结构的基础上<u>增加了一些指向同一结点的有向边</u>，使整个目录成为一个**有向无环图**，**以便实现文件共享**

如下图，使用这种结构就很方便的实现 dict 和 spell 目录共享 count 文件和 p 目录

![image-20211116163941652](..\images\image-20211116163941652.png)

删除一个共享结点时，若只是简单地将它删除，则另一个用户访问时会发生错误

所以给每个共享结点设置一个共享计数器：

- 每当图中**增加对该结点的共享链时，计数器加 1**
- 每当某用户提出**删除该结点时，计数器减 1**
- 仅当共享计数器**为 0 时，才删除该结点**，否则仅删除请求用户的共享链

优点：方便地**实现了文件的共享**；缺点：使**系统的管理变得更加复杂**

### 目录的操作

在目录这个层次上所需要执行的操作：

- 搜索：搜索目录，找到该文件的对应目录项
- 创建文件：创建文件时，在目录中增加目录项
- 删除文件：删除文件时，在目录中删除目录项
- 创建目录：创建自己的用户文件目录，并可再创建子目录
- 删除目录：有两种方式：
  1. 不删除非空目录：删除时要先删除目录中的所有文件，并递归地删除子目录
  2. 可删除非空目录：目录中的文件和子目录同时被删除
- 移动目录：将文件或子目录在不同的父目录之间移动，文件的路径名也会随之改变
- 显示目录：显示目录的内容，如目录的属性及所有文件
- 修改目录：文件的一些属性放在目录中，修改这些属性时必须修改目录

### 目录实现*

目录实现的基本方法有线性列表和哈希表两种，线性列表实现对应线性查找，哈希表的实现对应散列查找

思考：目录的实现是指**目录项在目录中逻辑上是如何存放的**，相应的查找方法是什么，物理存放还是通过[文件分配方式](#文件的物理结构)

#### 线性列表

线性列表优点在于**实现简单**，不过由于线性表的特殊性，**比较费时**，最简单的目录表项是**存储文件名 + 数据块指针**

可以采用顺序表和链表：

- 顺序表：查找文件快速，但插入和删除文件比较费时间
- 链表：减少删除文件的时间，但查找文件时只能顺序查找

重用（删除）目录项有许多方法：

1. 将目录项标记为不再使用
2. 将它加到空闲目录项表上
3. 将目录表中的最后一个目录项复制到空闲（删除）位置，并降低目录表长度

#### 哈希表

根据文件名得到一个值，并返回一个指向线性列表中元素的指针

优点：**查找非常迅速，插入和删除也较简单**；缺点：需要一些预备措施来避免冲突

最大的困难是哈希表长度固定以及哈希函数对表长的依赖性

------

目录查询是通过在磁盘上反复搜索完成的，需要不断地进行 I/O 操作，开销较大

所以**把当前使用的文件目录复制到内存**，以降低了磁盘操作次数，**提高了系统速度**

### 文件共享

文件共享使多个用户或进程**共享同一个文件**，系统中**只需保留该文件的一个副本**

随着计算机技术的发展，文件共享的范围已由单机系统发展到多机系统，进而通过网络扩展到全球

注意：不能建立文件与文件的链接，因为文件里面不能包含文件，但可以建立目录与文件的链接

#### 基于索引结点的共享方式

也称**硬链接**，有两个或多个用户要共享一个子目录或文件时，**将共享文件或子目录链接到两个或多个用户的目录中**

![image-20211116164138785](..\images\image-20211116164138785.png)

在这种共享方式中，在文件目录中只设置**文件名及指向相应索引结点的指针**，**文件信息放在索引结点中**

在索引结点中还应有一个链接计数 count，用于表示**链接到本索引结点上的用户目录项的数目**

1. A 创建一个文件，是该文件的所有者，将 count 置为 1
2. B 共享此文件，在 B 的**目录中增加一个目录项**，并设置一个指针**指向该文件的索引结点**，count = 2
3. A 删除此文件时，将该文件的 count 减 1，仅删除**自己目录中的相应目录项**，B 仍可以使用该文件
4. B 也删除 count = 0 时，系统将负责删除该文件；过程如下图

![image-20211116164235156](..\images\image-20211116164235156.png)

#### 利用符号链实现文件共享

也称**软链接**，B 共享文件时在 B 的目录中**创建一个 LINK 类型的文件，内部放被共享文件的路径**，这称为符号链接

新文件中的路径名只被视为符号链，当用户访问 LINK 文件时，操作系统**根据 LINK 文件中的路径名去读该文件**

只有文件的拥有者**才拥有指向其索引结点的指针**，其他用户只有该文件的路径名

当文件的拥有者**把共享文件删除后**，**通过符号链去访问它时，会出现访问失败**，于是将符号链删除

当文件拥有者将文件删除后，在未删除 LINK 文件前，有人**在同一路径下创建了同样名称的文件，则该符号链将仍然有效**

其他用户读共享文件时，需要**根据文件路径名逐个地查找目录**，使得访问文件的**开销变大并增加了启动磁盘的频率**，而且符号链的索引结点也要**耗费一定的磁盘空间**

符号链方式有一个很大的优点，即**网络共享**只需提供该文件所在**机器的网络地址及该机器中的文件路径**

选择题：即使把引用的文件删除了，LINK 文件的引用计数器也是不变的，它仅表示 LINK 文件的共享数

------

两种链接方式共同问题：每个共享文件会被多处引用，当我们试图去遍历整个文件系统时，将**会多次遍历到该共享文件**

硬链接和软链接都是文件系统中的**静态共享方法**；两个进程同时对同一个文件进行操作，这样的共享称为**动态共享**

当多个进程共享一个文件时，**共享同一个系统打开表的表项**（FCB），但**各自进程打开表的表项是不同的**，如记录读写位置

硬链接：**多个指针指向一个索引结点**，只要还有一个指针指向索引结点，索引结点就不能删除（**速度更快**）

软链接：**把到达共享文件的路径记录下来**，当要访问文件时，根据路径寻找文件

## 文件系统实现

### 文件系统层次结构*

现代操作系统有多种文件系统类型如 `FAT32，NTF` 等，因此文件系统的层次结构也不尽相同

![image-20211118105923873](..\images\image-20211118105923873.png)

1. 用户调用接口：

   文件系统**提供与文件及目录有关的调用**，如新建、打开、读写、关闭、删除文件，建立、删除目录等

   此层**由若干程序模块组成**，每个模块对应一条系统调用，用户发出系统调用时，转入相应的模块

2. 文件目录系统：

   文件目录系统的主要功能是**管理文件目录**，其任务有管理活跃文件目录表、管理读写状态信息表、管理用户进程的打开文件表、管理与组织存储设备上的文件目录结构、调用下一级存取控制模块

3. 存取控制验证模块：

   **实现文件保护主要由该级软件完成**，它把用户的访问要求与 FCB 中指示的访问控制权限进行比较，以确认访问的合法性

4. 逻辑文件系统与文件信息缓冲区：

   主要功能是，根据文件的逻辑结构<u>将用户要读写的逻辑记录转换成文件逻辑结构内的相应块号</u>

   文件信息缓冲区用于缓冲如索引文件的索引表之类的信息

5. 物理文件系统：

   主要功能是**把逻辑记录所在的相对块号转换成实际的物理地址**

6. 辅助分配模块：

   主要功能是管理辅存空间，即负责**分配辅存空闲空间和回收辅存空间**

7. 设备管理程序模块：

   主要功能是分配设备、分配设备读写用缓冲区、磁盘调度、启动设备、处理设备中断、释放设备读写缓冲区、释放设备等

例子：用户要使用文件 F ：

1. 调用 OS 的系统调用，这是第 0 级
2. 系统调用内部查找 F 的 FCB，这是第 1 级
3. 在 FCB 上检查用户权限，这是第 2 级
4. 通过验证后，把记录索引转换为逻辑地址，这是第 3 级
5. 把逻辑地址转换成物理地址，这是第 4 级
6. 若要释放空间，则把任务就交给辅助分配模块
7. 若要输入/输出，则把任务交给设备管理程序模块

### 文件系统布局

#### 文件系统在磁盘中的结构

文件系统包括：启动存储在那里的 OS 的方式、总的块数、空闲块的数量和位置、目录结构以及各个具体文件等

![image-20220726193314484](..\images\image-20220726193314484.png)

1. 主引导记录 MBR：位于磁盘的 0 号扇区，用来**引导计算机**，MBR **后面是分区表**，该表给出每个分区的起始和结束地址

   有一个分区被标记为活动分区，当计算机启动时 BIOS 读入并执行 MBR 确定活动分区，并读入它的第一块（引导块）

2. 引导块：MBR 执行引导块中的程序后，该程序负责**启动该分区中的操作系统**，为了方便每个分区都从引导块开始

   磁盘分区的布局是**随着文件系统的不同而变化的**，不一定从引导块开始，Windows 系统称引导块为分区引导扇区

3. 超级块：包含文件系统的所有**关键信息**，在计算机启动或者文件系统首次使用时，超级块**会被载入内存**

   超级块中包括分区的<u>块的数量、大小、空闲块的数量和指针、空闲的 FCB 数量和 FCB 指针</u>等

4. 文件系统中空闲块的信息：可以使用位示图或指针链接的形式给出（位示图与超级块相似但还是有自己的作用）

5. 然后是一组 i 结点，根目录，磁盘的其他部分存放了其他所有的目录和文件

#### 文件系统在内存中的结构

内存中的信息用于管理文件系统并通过缓存来提高性能，在安装文件系统时加载，在操作时更新，在卸载时丢弃

这些结构的类型可能包括：

1. 内存中的安装表，包含**每个已安装文件系统分区的有关信息**
2. 内存中的目录结构的缓存包含**最近访问目录的信息**，对安装分区的目录，它可以包括一个指向分区表的指针
3. **整个系统的打开文件表**，包含每个打开文件的 FCB 副本及其他信息
4. **每个进程的打开文件表**，包含一个指向整个系统的打开文件表中的适当条目的指针，以及其他信息

创建新文件时，调用逻辑文件系统为文件**分配 FCB**，并写入相关信息，最后写入磁盘**更新相应的目录**

系统调用 open() 将文件名传递给逻辑文件系统：

1. 首先搜索整个系统的打开文件表

2. 如果已被使用，则**在进程打开文件表中创建一个条目**，指向系统打开文件表的相应条目（打开数加 1）

3. 如果尚未打开，则根据给定文件名来搜索目录结构，部分目录结构通常缓存在内存中

   找到文件后，**复制 FCB 到系统打开文件表中**，并在进程打开文件表中创建一个条目，并指向系统打开文件表

4. 最后，返回指向进程打开文件表中的适当条目的**指针**（Linux 的 FD 或 Windows 的句柄）

关闭一个文件时：删除进程打开文件表中的相应条目，所有用户都关闭该文件后，更新的元数据将写到磁盘的目录结构中

### 外存空闲空间管理

1. 文件存储器空间的划分与初始化：

   一个文件存储在一个文件卷中，文件卷可以是物理盘的一部分，也可以是整个物理盘，也可由多个物理盘组成

   ![image-20211118110834360](..\images\image-20211118110834360.png)

   在一个文件卷中，**文件数据信息的空间**（文件区）和**存放文件控制信息 FCB 的空间**（目录区）是**分离的**

   <u>逻辑卷在提供文件服务前，必须由对应的文件程序进行初始化</u>，如划分好目录区和文件区等

   一个卷有一个文件系统，卷是 Windows 的名称，在其它 OS 叫分区

2. 文件存储器空间管理：

   文件存储设备**分成许多大小相同的物理块**，并以块为单位交换信息

   **文件存储设备的管理实质上是对空闲块的组织和管理**，它包括空闲块的组织、分配与回收等问题

#### 空闲表法

空闲表法**属于连续分配方式**，与内存的动态分配方式类似，用于**分配一块连续的存储空间**

系统**为外存上的所有空闲区建立一张空闲盘块表**，每个空闲区对应于一个**空闲表项，其中包括表项序号、该空闲区第一个盘块号、该区的空闲盘块数**等信息，再将所有空闲区按其起始盘块号递增的次序排列

![image-20211118110933921](..\images\image-20211118110933921.png)

空闲盘区的分配**与内存的动态分配类似**，同样**采用首次适应算法、循环首次适应算法**等

系统在对用户所释放的存储空间进行回收时，当**回收的区与原来的空闲区相邻时，需要进行合并**

#### 空闲链表法

**将所有空闲盘区拉成一条空闲链**，根据构成链所用的基本元素不同，可把链表分成两种形式：

- 空闲盘块链：将磁盘上的所有空闲空间**以盘块为单位拉成一条链**

  分配存储空间时：系统**从链首开始，依次摘下适当数目的空闲盘块**分配给用户

  释放存储空间时：系统**将回收的盘块依次插入空闲盘块链的末尾**

  优点：分配和回收一个盘块的过程非常简单；缺点：**为一个文件分配盘块时可能要重复多次操作**，空闲盘块链长

- 空闲盘区链：将磁盘上的所有**空闲盘区（每个盘区可包含若干盘块）拉成一条链**

  在每个盘区上含有用于**指示下一个空闲盘区的指针和本盘区的大小信息**

  分配盘区的方法与内存的动态分区分配类似，通常采用首次适应算法

  在回收盘区时，同样也要**将回收区与相邻接的空闲盘区合并**
  
  优缺点：分配与回收的过程比较复杂，但效率通常较高，且空闲盘区链较短

#### 位示图法

利用二进制的一位来表示磁盘中一个盘块的使用情况，磁盘上的**每个盘块都有一个二进制位与之对应**

当其值为 0 时，表示**对应的盘块空闲**；当其值为 1 时，表示**对应的盘块已分配**

![image-20211118111054282](..\images\image-20211118111054282.png)

盘块的分配：

1. 顺序扫描位示图，从中**找出一个或一组其值为 0 的二进制位**
2. **转换成与之对应的盘块号**，如位于位示图的第 i 行、第 j 列，每行有 n 位，则盘块号为：b = n(i - 1) + j
3. **修改位示图，令 map[i, j] = 1**

盘块的回收：

1. 将回收盘块的**盘块号转换成位示图中的行号和列号**，转换公式为 i = (b - 1) DIV n + 1，j = (b - 1) MOD n + 1
2. **修改位示图，令 map[i, j] = 0**

特别注意：上面公式是从 1 开始编号，<u>若题目中指明从 0 开始编号，则上述计算方法要进行相应调整</u>

#### 成组链接法

空闲表法和空闲链表法都不适用于大型文件系统，因为这会使空闲表或空闲链表太大

在 UNIX 系统中采用的是成组链接法，这种方法结合了空闲表和空闲链表两种方法，**克服了表太大的缺点**

用来**存放一组空闲盘块号的盘块**称为成组链块，**其大致思想是：**

- 把顺序的 n 个空闲扇区地址保存在第一个空闲扇区内
- n 个空闲扇区中的某一个，一般是第一个或最后一个，再保存顺序的 n 个空闲扇区的地址
- 如此继续，直至所有空闲扇区均予以链接
- 系统只需要保存一个指向第一个空闲扇区的指针

通过这种方式**可以迅速找到大批空闲块地址**

![image-20211118111200473](..\images\image-20211118111200473.png)

盘块的分配：

- 根据第一个成组链块的指针，将其对应的盘块分配给用户，然后将指针下移一格
- 若该指针指向的是最后一个盘块（成组链块）将该盘块读入内存，并将指针指向它的第一条记录

盘块的回收：

- 成组链块的指针上移一格，再记入回收盘块号
- 当成组链块的链接数达到 n 时，将当前成组链块号记入新回收的盘块，新回收的盘口就变成成组链块

表示空闲空间的**位向量表或第一个成组链块**，以及卷中的目录区、文件区划分信息都要存放在磁盘中，一般放在卷头位置

在 UNIX 的 UFS 文件系统中称为**超级块**，NTFS 中称为主控文件表

在对卷中的文件进行操作前，需要预先把超级块读入系统的空闲主存，并且<u>经常保持主存超级块与辅存卷中超级块的一致性</u>

### 虚拟文件系统

虚拟文件系统 VFS 为用户程序提供了文件系统操作的**统一接口**，**屏蔽了不同文件系统的差异和操作细节**

![image-20220727191709687](..\images\image-20220727191709687.png)

虚拟文件系统，抽象出一个通用的文件系统模型，**定义了通用文件系统都支持的接口**，新的文件系统只需**实现这些接口**

如 Linux 的 write() 会在 VFS 中通过 sys_write() 找到具体文件系统，来与物理介质交互并读出数据

![image-20220727191752699](..\images\image-20220727191752699.png)

Linux 主要抽象了四种对象类型来实现 VFS，每个 VFS 对象包括对象的**属性和指向方法表的指针**

- 超级块对象：表示一个已安装（或称挂载）的特定文件系统
- 索引结点对象：表示一个特定的文件
- 目录项对象：表示一个特定的目录项
- 文件对象：表示一个与进程相关的已打开文件

Linux **将目录当作文件对象**来处理，文件操作能同时应用于文件或目录，而文件系统是由层次目录组成的

1. 超级块对象：超级块对象对应于磁盘上特定扇区的文件系统**超级块**，用于存储**已安装文件系统的元信息**

   元信息中包含文件系统的基本属性信息，如文件系统的<u>类型、基本块大小、所挂载的设备、操作方法指针</u>等

   操作方法指针指向超级块的操作方法表，主要有<u>分配、销毁、读、写 inode、文件同步</u>等

2. 索引结点对象：存放文件系统处理文件所需要的信息，索引结点**对文件是唯一的**

   只有当文件**被访问时**，才在内存中创建索引结点对象，**复制磁盘索引结点**包含的一些数据

   它有一个状态字段表示是否被修改，来判断是否更新磁盘索引结点

   索引结点对象还提供许多操作接口，如<u>创建新索引结点、创建硬链接、创建新目录</u>等

3. 目录项对象：用于提高效率，因为 VFS 经常执行切换到某个目录这种操作

   目录项对象是一个**路径的组成部分**，它要么是目录名，要么是文件名

   目录项对象包含指向关联索引结点的指针、**指向父目录和指向子目录的指针**

   目录项对象**在磁盘上没有对应的数据结构**，它是 VFS 在遍历路径的过程中逐渐形成的

   如查找 /test 过程中，先建立目录项 /，然后在 / 下建立 test 的二级目录项对象（内存中）

4. 文件对象：文件对象代表进程打开的一个文件，通过 open() 打开一个文件，通过 close() 关闭一个文件

   同一文件在内存中可能存在**多个对应的文件对象**，但对应的**索引结点和目录项是唯一的**

   文件对象仅**在进程观点上代表已经打开的文件**，它具有指向其索引结点的指针

   文件对象包含与该文件相关联的目录项对象，包含该文件的文件系统、文件指针等，还包含一系列操作函数

三个不同的进程已打开了同一个文件，其中两个进程使用同一个硬链接：

- 每个进程都使用**自己的文件对象**，但只需要两个目录项对象，**每个硬链接对应一个目录项对象**
- 并指向**同一个索引结点对象**，这个索引结点对象标识的是超级块对象及随后的普通磁盘文件

![image-20220727191901832](..\images\image-20220727191901832.png)

VFS 还能提高系统性能：把常使用的目录项对象放在磁盘缓存中，以加速从文件路径的转换过程

VFS 对每个文件系统的所有细节进行抽象，使得**不同的文件系统在系统中运行的其他进程看来都是相同的**

VFS 并不是一种实际的文件系统，它**只存在于内存中**，在系统启动时建立，在系统关闭时消亡

### 分区和安装

一个磁盘可以划分为多个分区，每个分区都可以用于创建单独的文件系统，甚至包含不同的操作系统

分区可以是原始的，没有文件系统，当没有合适的文件系统时，可以使用原始磁盘

![image-20220727232241092](..\images\image-20220727232241092.png)

文件系统**在进程使用前必须先安装（挂载）**如 Windows 在启动时自动发现所有设备，并且安装所有找到的文件系统

Windows 有两级目录结构，如 C 盘其实路径是 /c，挂载是挂载到根目录 / 上的，安装文件系统的这个目录称为**安装点**

文件系统挂载要做的事：

1. 在 VFS 中注册新挂载的文件系统，**内存中的挂载表**包含每个文件系统的相关信息，包括文件系统类型、容量大小等

2. 新挂载的文件系统，要向 VFS 提供一个**函数地址列表**

3. 将新文件系统加到**挂载点**，也就是将新文件系统挂载在某个父目录下

   在目录 inode 的**内存副本**上加上一个标志，表示该目录是安装点

   加上一个域指向安装表的条目，由设备及其安装位置和文件系统超级块的指针组成

Linux 的挂载指令：`mount -t ext2 /dev/fd0 /flp` 将存放在 `/dev/fd0` 软盘上的 `ext2` 文件系统安装到 `/flp`

## 磁盘和固态硬盘

### 磁盘的结构

磁盘是由表面涂有磁性物质的圆形盘片，**通过磁头从磁盘存取数据**，在读/写操作期间，磁头固定，磁盘在下面高速旋转

一个盘面有多个磁道（**与磁头同宽**），一个磁道有多个扇区（大小固定），**一个扇区称为一个盘块**

相邻磁道及相邻扇区间通过一定的间隙分隔开，以避免精度错误

注意：扇区的**存储密度从最外道向里道增加**，磁盘的存储能力受限于最内道的最大记录密度

磁盘安装在一个磁盘驱动器中，它由<u>磁头臂、用于旋转磁盘的主轴、用于数据输入/输出的电子设备组成</u>

多个盘片垂直堆叠，组成磁盘组，**每个盘面对应一个磁头**，所有磁头固定在一起，**与磁盘中心的距离相同且一起移动**

所有盘片上**相同位置的磁道组成柱面**，扇区是**磁盘可寻址的最小存储单位**，**磁盘地址：柱面号·盘面号·扇区号**

![image-20211119162018734](..\images\image-20211119162018734.png)

磁盘按不同的方式可分为若干类型：

- **每个磁道一个磁**头，磁头不需要移动，称为固定头磁盘
- 磁头**需要移动寻找磁道**，称为活动头磁盘
- 磁盘永久**固定在磁盘驱动器内**的，称为固定盘磁盘
- 磁盘**可移动和替换的**，称为可换盘磁盘

注意：一般柱面、盘面、扇区、簇都是从 0 编号，一般柱面有多少个磁道就是有多少个盘面

### 磁盘的管理

#### 磁盘初始化

一个新的磁盘只是一个**含有磁性记录材料的空白盘**，初始化分三步：低级格式化、分区、逻辑格式化

**低级格式化，物理分区**：划分扇区，检测坏扇区，并用备用扇区替换坏扇区（对 OS 透明），以便磁盘控制器操作：

- 低级格式化为磁盘的每个扇区采用特别的数据结构：通常由**头部、数据区域和尾部**组成
- 头部和尾部包含了一些**磁盘控制器所使用的信息**，如扇区校验码；数据区用于**存放文件数据**

为了使用磁盘存储文件，操作系统还需要将自己的数据结构记录在磁盘上：

1. 将磁盘分为由**一个或多个柱面组成的分区**，即我们熟悉的 C 盘、D 盘等形式的分区
2. 对物理分区进行**逻辑格式化，创建文件系统**：操作系统将初始的文件系统数据结构存储到磁盘上，这些数据结构包括**空闲和已分配的空间**及**一个初始为空的目录**

操作系统**将多个相邻的扇区组合在一起**，形成一簇（Linux 叫块），来提高效率

**一簇只能存放一个文件的内容**，文件所占用的空间只能是簇的整数倍（起码占 1 簇）

思考：要安装操作系统，起码要有文件系统，所以步骤是<u>物理格式化、分区、逻辑格式化、操作系统的安装</u>

#### 引导块

计算机启动时需要运行一个初始化程序（自举程序），它**初始化 CPU、寄存器、设备控制器和内存**等，接着**启动操作系统**

自举程序需要找到磁盘上的操作系统内核，装入内存，并转到起始地址，从而开始操作系统的运行

在 ROM 中**保留很小的自举装入程序**，将**完整功能的自举程序保存在磁盘的启动块上**，启动块（引导控制块）**位于磁盘的固定位置**；若磁盘<u>没有操作系统，则这块的内容为空</u>，通常为分区的<u>第一块</u>，UFS 中称为引导块，NTFS 中称为分区引导扇区

拥有启动分区的磁盘称为**启动磁盘或系统磁盘**

#### 坏块

由于磁盘有移动部件且容错能力弱，因此容易导致一个或多个扇区损坏，部分磁盘甚至从出厂时就有坏扇区

根据所使用的磁盘和控制器，对这些块有以下处理方式：

1. 对于简单磁盘：如电子集成驱动器 IDE，**坏扇区可由 OS 处理**

   如 MS-DOS 的 Format 命令执行逻辑格式化时便会扫描磁盘以检查坏扇区

   坏扇区在 FAT 表上会标明，因此程序不会使用

2. 对于复杂的磁盘：如小型计算机系统接口 SCSI，则**由其控制器处理**

   其控制器维护一个磁盘坏块链表，在低级格式化时就已初始化，并在磁盘的整个使用过程中不断更新

   低级格式化将一些块保留作为备用，**对操作系统透明**，控制器可**用备用块来逻辑地替代坏块**，这种方案称为**扇区备用**

对坏块的处理实质上就是用某种机制，使系统不去使用坏块，坏块**属于硬件故障**，操作系统是不能修复坏块的

### 磁盘操作时间

一次磁盘读写操作的时间由**寻道时间、旋转延迟时间、传输时间**决定

1. 寻找时间 $T_S$：活动头磁盘在读写信息前，将磁头**移动到指定磁道所需要的时间**

   这个时间包括**跨越 n 条磁道的时间，和启动磁臂的时间 s**，即 $T_s=m×n+s$

   m 是与磁盘驱动器速度有关的常数，约为 `0.2ms`，磁臂的启动时间约为 `2ms`

2. 旋转延迟时间 $T_r$：磁头**定位到某一磁道的扇区所需要的时间**

   设磁盘的旋转速度为 r，则 $T_r=\dfrac 1{2r}$，平均时间所以要除以 2

3. 传输时间 $T_t$：**从磁盘读出或向磁盘写入数据所经历的时间**

   取决于每次所**读/写的字节数 b 和磁盘的旋转速度**，$T_t=\dfrac{b}{rN}$ 

   r 为磁盘每秒的转数，N 为一个磁道上的字节数

寻道时间**与磁盘调度算法相关**（OS 只能优化寻道时间）；旋转延迟时间和传输时间都**与磁盘旋转速度线性相关**

总平均存取时间 $T_a$ 可以表示为 $T_a=T_s+\dfrac{1}{2r}+\dfrac{b}{rN}$，在实际的中**调度算法直接决定寻找时间，从而决定总的存取时间**

### 磁盘调度算法

用户访问文件时，操作系统经过一系列的检验访问权限和寻址过程后，控制磁盘把相应的数据信息读出或修改

当有多个请求同时到达时，操作系统就要**决定先为哪个请求服务**，这就是**磁盘调度算法要解决的问题**

#### 先来先服务 FCFS 算法

FCFS 算法**根据进程请求访问磁盘的先后顺序进行调度**，这是一种最简单的调度算法

优点：**具有公平性**，若只有少量进程需要访问，且大部分**访问的磁道比较集中，则有望达到较好的性能**

缺点：**大量进程竞争使用磁盘时**，则这种算法在性能上往往接近于随机调度（**性能很差**，一般不用）

例子：磁盘请求队列中的请求顺序分别为 55, 58, 39, 18, 90, 160, 150, 38, 184，磁头的初始位置是磁道 100

采用 FCFS 算法时磁头共移动了 (45 + 3 + 19 + 21 + 72 + 70 + 10 + 112 + 146) = 498 个磁道，平均寻找长度 = 498 / 9 = 55.3

<img src="..\images\image-20211119163620866.png" alt="image-20211119163620866" style="zoom:150%;" />

#### 最短寻找时间优先 SSTF 算法

SSTF **选择与当前磁头所在磁道距离最近的磁道**，以便使**每次的寻找时间最短**，但**不能保证平均寻找时间最小**

能提供**比 FCFS 算法更好的性能**，但这种算法**会产生饥饿现象**，即一直处理近的请求而忽略远的请求

使用 FCFS 的参数：采用 SSTF 算法时磁头共移动了 248 个磁道，平均寻找长度 = 248 / 9 = 27.5

<img src="..\images\image-20211119163708975.png" alt="image-20211119163708975" style="zoom:150%;" />

不能保证寻找时间最短是指：磁头在 100，有 90, 105, 150 到达，按 90, 105, 150 才是时间最小的

#### 扫描 SCAN 算法

SCAN **在磁头当前移动方向上选择与当前磁道距离最近的请求**，由于磁头移动与电梯相似，又称**电梯调度算法**

SCAN 算法**对最近扫描过的区域不公平**，因此它在访问局部性方面不如 FCFS 算法和 SSTF 算法好

采用 SCAN 算法时，要知道磁头的当前位置和**磁头的移动方向**，但解决了 SSTF 的饥饿现象，且性能比 FCFS 快

使用 FCFS 的参数：磁头朝磁道号增大的方向移动，采用 SCAN 磁头共移动了282 个磁道，平均寻道长度 = 282 / 9 = 31.33

<img src="..\images\image-20211119163742356.png" alt="image-20211119163742356" style="zoom:150%;" />

#### 循环扫描 C-SCAN 算法

在 SCAN 的基础上**规定磁头单向移动来提供服务**，回返时直接**快速移动至起始端而不服务任何请求**

使用改进型的 C-SCAN 算法来**避免偏向于处理那些接近最里或最外的磁道的访问请求**（避免不公平）

使用 FCFS 的参数：磁头沿磁道号增大的顺序移动，采用 C-SCAN 磁头共移动 390 个磁道，平均寻道长度 = 390 / 9 = 43.33

<img src="..\images\image-20211119163814198.png" alt="image-20211119163814198" style="zoom:150%;" />

#### LOOK 调度算法

 LOOK 调度：在 SCAN 的基础上磁头移动**只需要到达最远端的一个请求即可返回**，不需要到达磁盘端点

<img src="..\images\image-20211119163831528.png" alt="image-20211119163831528" style="zoom:150%;" />

C-LOOK 调度：和 LOOK 差不多，但它是在 C-SCAN 的基础上实现的

LOOK 和 C-LOOK 通过**在移动前会查看此方向是否有请求**实现的

<img src="..\images\image-20211119163855031.png" alt="image-20211119163855031" style="zoom:150%;" />

注意，若无特别说明，也可**以默认 SCAN 算法和 C-SCAN 算法为 LOOK 和 C-LOOK 调度**

#### 磁盘调度算法比较

- FCFS 算法太过简单，性能较差，仅**在请求队列长度接近于 1 时才较为理想**
- SSTF 算法较为通用和自然
- SCAN 算法和 C-SCAN 算法在磁盘**负载较大时比较占优势**

<img src="..\images\image-20211119163926216.png" alt="image-20211119163926216" style="zoom:150%;" />

### 减少延迟时间

对**盘面扇区进行交替编号**，**不同盘面错位命名**，假设每个盘面有 8 个扇区，磁盘片组共 8 个盘面，可如此编号：

<img src="..\images\image-20211119164035919.png" alt="image-20211119164035919" style="zoom:150%;" />

磁盘是连续自转设备，磁头读/写一个物理块后，需要**经过短暂的处理时间才能开始读/写下一块**

这种编号的好处是，读完了 0 号扇区后，**处理数据时磁头刚好在 4 号扇区**，处理完了后就转到了 1 号扇区

若编号连续，读完 0 号后，转到 1 号扇区头部时在处理数据，处理完后就错过了，需要再转一圈

不同盘面的扇区错位类似；这种编号**只会减少连续读时的延迟时间，不能减少随机读的时间**

磁盘寻块时间分为**寻道时间、延迟时间、传输时间**

- 寻道时间和延迟时间这种找的时间都可以通过一定的方法削减
- 传输时间是磁盘本身性质所决定的，**不能通过一定的措施减少**

注意：题目中盘面扇区交替编号和处理时间没有出现，当这节内容是空气就好了，也可以当作现代的磁盘没这种毛病

额外：间隔因子，交错因子：硬盘磁道上相邻的两个逻辑扇区之间的物理扇区的数量

# 输入输出管理

## I/O 管理概述

### I/O 设备

#### 设备的分类

##### 按使用类型分类

1. 人机交互类外部设备：用于**与计算机用户之间交互的设备**，如键盘等

   这类设备的数据交换速度相对较慢，通常是**以字节为单位进行数据交换**的

2. 存储设备：用于**存储程序和数据的设备**，如磁盘等

   这类设备用于数据交换，速度较快，通常**以块为单位进行数据交换**

3. 网络通信设备：用于**与远程设备通信的设备**，如各种网络接口、调制解调器等

   其**速度介于前两类设备之间**，网络通信设备在使用和管理上与前两类设备也有很大不同

##### 按传输速率分类

1. 低速设备：传输速率为**每秒几字节到数百字节**，如键盘、鼠标等
2. 中速设备：传输速率为**每秒数千字节至数万字节**，如行式打印机、激光打印机等
3. 高速设备：传输速率为**每秒数百千字节至千兆字节**，如磁带机、磁盘机、光盘机等

##### 按信息交换的单位分类

1. 块设备：由于信息的存取总是以数据块为单位的，如磁盘等

   属于有结构设备，**传输速率较高、可寻址**，即对它可随机地读/写任一块

2. 字符设备：其传输的基本单位是字符，如键盘等

   属于无结构类型，**传输速率低、不可寻址**，并且在输入/输出时常采用**中断驱动方式**

##### 按设备的共享属性分类

1. 独占设备：**一段时间内只允许一个进程访问**，属于临界资源，**可能导致死锁**，如打印机

2. 共享设备：**一段时间内允许多个进程访问，但每个时刻只能一个进程访问**

   **不会导致死锁，必须是可寻址、可随机访问的设备**，如磁盘

3. 虚拟设备：将一台独占设备虚拟为若干台逻辑设备，**物理上是独占设备，但逻辑上是共享设备**，如 SPOOLing 技术

#### I/O 控制器

I/O 接口（设备控制器）位于 CPU 与设备之间，它要与 CPU 及设备通信，还要按 CPU 的命令去控制设备工作

![image-20211121212940417](..\images\image-20211121212940417.png)

设备控制器的工作方式：

1. OS 向控制器的寄存器**写命令字**
2. 控制器收到一条命令后，**完成具体的 I/O 操作**
3. 命令执行完毕后，控制器**发出一个中断信号**
4. OS 检查执行结果，从状态寄存器中读取设备的状态

设备控制器的主要功能如下：

1. 接收和识别 CPU 或通道发来的命令
2. 实现数据交换，包括**设备和控制器之间的数据传输**以及**控制器和主存之间的数据传输**
3. **发现和记录设备及自身的状态信息**，供 CPU 处理使用
4. **设备地址识别**
5. 数据缓冲
6. 差错控制

为实现上述功能，设备控制器包含以下组成部分：

1. 设备控制器与 CPU 的接口：该接口有**数据线、地址线、控制线**

   数据线：修改或读取数据寄存器和控制/状态寄存器的内容

2. 设备控制器与设备的接口：

   设备控制器连接设备需要相应数量的接口，**一个接口连接一台设备**

   每个接口中都存在**数据、控制和状态**三种类型的信号

3. I/O 控制逻辑：用于**实现对设备的控制**

   它**通过一组控制线与 CPU 交互**，对从 CPU 收到的 I/O 命令进行译码

思考：由于设备控制器链接多个设备，有多个设备同时使用的情况，所以数据寄存器和控制/状态寄存器应有多个

#### I/O 端口

I/O 端口：设备控制器中**可被 CPU 直接访问的寄存器**，主要有：

- 数据寄存器：实现 CPU 和外设之间的**数据缓冲**
- 状态寄存器：获取执行结果和设备的**状态信息**，以让 CPU 知道是否准备好
- 控制寄存器：由 CPU 写入，以便**启动命令**或更改设备模式

![image-20220728205110027](..\images\image-20220728205110027.png)

实现 CPU 与 I/O 端口进行通信，有两种方法：

1. 独立编址：**每个端口分配一个 I/O 端口号**，形成 I/O 端口空间，只有**操作系统使用特殊的 I/O 指令才能访问端口**
2. 统一编址，内存映射 I/O：**每个端口被分配唯一的内存地址**，通常靠近地址空间的顶端

### I/O 控制方式

#### 程序直接控制方式

对 I/O 设备发出命令后就**一直检查外设的状态**，直到确定该字已经在 I/O 控制器的数据寄存器中（**每次读一个字**）

![image-20211121202511286](..\images\image-20211121202511286.png)

由于 CPU 的高速性和 I/O 设备的低速性，使得 **CPU 浪费时间在等待上**，造成了 CPU 资源的极大浪费

优点：简单且易于实现；缺点：CPU 和 I/O 设备只能串行工作，CPU 利用率相当低

#### 中断驱动方式

对 I/O 设备发出命令后 CPU 就去做其他事情，当 **I/O 设备完后使用中断通知 CPU**，CPU 处理中断（每次读一个字）

![image-20211121202548700](..\images\image-20211121202548700.png)

优点：比程序直接控制方式 CPU 占用率更低；缺点：**传送数据仍需要 CPU**，消耗较多的 CPU 时间

#### DMA 方式

DMA 方式**在 I/O 设备和内存之间开辟直接的数据交换通路**，彻底解放 CPU

DMA 方式的特点如下：

1. **基本单位是数据块**
2. 所传送的数据，是从设备直接送入内存的，或者相反
3. 整块数据的传送是在 DMA 控制器的控制下完成的
4. 仅在**传送一个或多个数据块的开始和结束时，才需 CPU 干预**

![image-20211121192900425](..\images\image-20211121192900425.png)

要在主机与控制器之间实现成块数据的直接交换，则需在 DMA 控制器中设置：

1. 命令/状态寄存器 CR：接受 CPU 发来的 **I/O 命令或有关控制信息**，或**设备的状态**
2. 内存地址寄存器 MAR：输入时把设备的数据读入内存；输出时把内存的数据写入设备
3. 数据寄存器 DR：用于暂存从设备到内存或从内存到设备的数据
4. 数据计数器 DC：存放本次要传送的字（节）数

需要传送数据时 DMA **向 CPU 发送请求**，响应后开始传送数据，整个数据块传送完成后，**向 CPU 发送中断信号**

![image-20211121202620710](..\images\image-20211121202620710.png)

DMA 控制方式与中断驱动方式的主要区别：

1. 中断驱动方式：每字传输都要中断 CPU；DMA 控制方式：传送完一批数据后才需要中断 CPU
2. 中断驱动方式：中断处理时由 CPU 传输数据；DMA 控制方式：在 DMA 控制器的控制下传输数据

#### 通道控制方式

I/O 通道是指**专门负责输入/输出的处理机**，是 DMA 方式的发展，它可以**进一步减少 CPU 的干预**，基本单位是**一组数据块**

当 CPU 要完成一组相关的读/写操作及有关控制时，向 I/O 通道**发送一条 I/O 指令**（通道程序的首地址和 I/O 设备号），通道接到该指令后，**执行通道程序传送数据**，数据传送结束时**向 CPU 发中断请求**

I/O 通道与一般处理机的区别是：通道**指令的类型单一**，没有自己的内存，通道所执行的**通道程序是放在内存中**

I/O 通道与 DMA 方式的区别是：

- DMA 方式**需要 CPU 来控制传输的数据块大小、传输的内存位置**；通道方式中这些信息是**由通道控制的**
- 每个 DMA 控制器**对应一台设备**与内存传递数据；一个通道可以**控制多台设备**与内存的数据交换

思考：CPU 要进行 I/O 时可能在内存写好通道程序，然后发送命令给 I/O 通道运行这些程序，运行完后发送中断

选择题：通道的类型分为：

| 通道类型     | 特点                                     | 适用于                    |
| ------------ | ---------------------------------------- | ------------------------- |
| 字节多路通道 | 以字节为单位，一段时间内为多个设备服务   | 大量的低速、中速 I/O 设备 |
| 数组选择通道 | 以数据块为单位，一段时间内为一个设备服务 | 少量的高速 I/O 设备       |
| 数组多路通道 | 以数据块为单位，一段时间内为多个设备服务 | 大量的高速 I/O 设备       |

### I/O 软件层次结构

I/O 软件涉及的面非常广，**即与硬件有着密切的联系，又与用户直接交互**，它与进程管理、存储器管理、文件管理等都有联系

在 I/O 软件中普遍采用了层次式结构，每层都利用其下层提供的服务，完成输入/输出功能中的某些子功能，向高层提供服务

只要层次间的接口不变，对某一层次中的软件的修改都不会引起其下层或高层代码的变更，**仅最低层才涉及硬件的具体特性**

![image-20211121212900285](..\images\image-20211121212900285.png)

**中间三层属于 OS 内核**，称为 I/O 系统或 I/O 核心子系统

整个 I/O 系统可以视为具有 4 个层次的系统结构，各层次及其功能如下：

#### 用户层 I/O 软件

**实现与用户交互的接口**，对下层的系统调用进行封装，给用户提供更为简单的接口

如与用户程序链接在一起的库函数，和完全运行于内核之外的一些程序，但大部分 I/O 软件都在 OS 内核

用户层软件**必须通过一组系统调用来获取操作系统服务**

#### 设备独立性软件

为了**实现设备独立性**，必须再在驱动程序之上设置一层设备独立性软件

设备独立性也称设备无关性，使**应用程序独立于具体使用的物理设备**，通过引入了逻辑设备和物理设备来实现

- 在应用程序中，使用逻辑设备名来请求使用**某类设备**
- 在系统实际执行时，必须**将<u>逻辑设备名</u>映射成物理设备名使用**

使用逻辑设备名的好处是：

1. **增加设备分配的灵活性**
2. **易于实现 I/O 重定向**，即用于 I/O 操作的设备可以更换，而不必改变应用程序

设备独立性软件的主要功能可分为以下两个方面：

1. **执行所有设备的公有操作**：
   
   - 对设备的分配与回收
   
   - 将逻辑设备名映射为物理设备名，由**[逻辑设备表](#逻辑设备名到物理设备名的映射)**实现
   
     其表项由**逻辑设备名、物理设备名（绝对号）、驱动程序入口地址**组成
   
   - 对设备进行保护，禁止用户直接访问设备
   
   - 缓冲管理
   
   - 差错控制
   
   - 提供缓冲区，屏蔽设备之间信息交换单位大小和传输速率的差异
   
2. 向用户层（或文件层）**提供统一接口**：即**系统调用**，无论何种设备，它们向用户所提供的接口应是相同的

#### 设备驱动程序

**与硬件直接相关**，负责**具体实现系统对设备发出的操作指令**，驱动 I/O 设备工作的驱动程序

**每类设备配置一个设备驱动程序**，它是 I/O 进程与设备控制器之间的通信程序，常以进程形式存在

设备驱动程序向上层用户程序**提供一组标准接口**，设备具体的**差别被设备驱动程序所封装**，从而隐藏设备控制器之间的差异

把上层的命令转换为具体要求后，发送给设备控制器，控制 I/O 设备工作；设备控制器发来的信号也传送给上层软件

注意：设备驱动程序发送命令给设备控制器，具体的 I/O 操作由设备控制器来控制 I/O 设备完成

#### 中断处理程序

<u>保存被中断进程的 CPU 环境，转入相应的中断处理程序进行处理，处理完并恢复被中断进程的现场后，返回到被中断进程</u>

中断处理层的主要任务有：进行进程上下文的切换，对处理中断信号源进行测试，读取设备状态和修改进程状态等

由于中断处理与硬件紧密相关，对用户而言，应尽量加以屏蔽，因此应放在操作系统的底层

#### 硬件设备

I/O 设备通常包括**一个机械部件和一个电子部件**：

- 电子部件，设备控制器（适配器），通常是一块插入主板扩充槽的印刷电路板
- 机械部件：设备本身

思考：用户想要读某设备时，调用用户层的 read 命令，由设备独立性软件分配设备，由设备驱动程序解析成硬件使用的指令，由中断处理程序中断当前进程，让硬件运行读命令

### 应用程序 I/O 接口

#### 字符设备接口

数据的存取和传输是**以字符为单位**的设备，如键盘，基本特征是传输速率较低、**不可寻址**，常采用中断驱动方式

提供 get 和 put 接口：根据其顺序存取性，为字符设备建立字符缓冲区，通过 get 获取字符，通过 put 输出字符到缓冲区

in-control 指令：字符设备间的差异巨大，故在接口中提供一种通用的 in-control 指令来方便特定使用（有巨多参数）

字符设备都属于**独占设备**，为此接口中还需要提供**打开和关闭操作**，以实现互斥共享

#### 块设备接口

数据的存取和传输是**以数据块为单位**的设备，如磁盘，基本特征是传输速率较高、**可寻址**，常采用 DMA 方式

把所有扇区依次编号，而不需要使用磁道号和扇区号来表示，把二维结构变为一种线性序列

块设备提供**打开、读、写和关闭**等接口，该接口将上述命令映射为设备能识别的较低层的具体操作

内存映射接口通过内存的字节数组来访问磁盘，而不提供读/写磁盘操作，它返回一个虚拟内存地址，访问时才进行调页

#### 网络设备接口

网络 I/O 接口为**网络套接字接口**，通过此系统调用，可以实现用户的上网功能

网络套接字有选择协议、绑定端口、连接远程主机、发送接受数据等接口

#### 阻塞/非阻塞 I/O

操作系统的 I/O 接口还涉及两种模式：阻塞和非阻塞

- 阻塞 I/O：当用户进程调用 I/O 操作时，进程就被阻塞，需要**等待 I/O 操作完成，进程才被唤醒继续执行**
- 非阻塞 I/O：用户进程调用 I/O 操作时，不阻塞该进程，该 I/O 调用**直接返回一个状态值**

大多数操作系统提供的 I/O 接口都是采用阻塞 I/O

## I/O 核心子系统

### I/O 子系统概述

由于 I/O 设备种类繁多，功能和传输速率差异巨大，因此需要多种方法来进行设备控制

这些方法共同组成了操作系统内核的 I/O 子系统，它**将内核的其他方面从繁重的 I/O 设备管理中解放出来**

I/O 核心子系统提供的服务主要有 I/O 调度、缓冲与高速缓存、设备分配与回收、假脱机、设备保护和差错处理等

### I/O 调度概念

I/O 调度就是**确定一个好的顺序来执行这些 I/O 请求**，从而改善系统整体性能，使进程之间公平地共享设备访问

操作系统**为每个设备维护一个请求队列**，调度就是从中选择一个请求来运行，如磁盘调度算法

### 高速缓存与缓冲区

#### 磁盘高速缓存 Disk Cache

磁盘高速缓存技术指**利用内存中的存储空间来暂存从磁盘中读出的一系列盘块中的信息**，对内存访问更快

磁盘高速缓存逻辑上属于磁盘，物理上则是驻留在内存中的盘块

高速缓存在内存中分为两种形式：

1. **在内存中开辟一个单独的存储空间**作为磁盘高速缓存，大小固定
2. 把**未利用的内存空间作为一个缓冲池**，供请求分页系统和磁盘 I/O 时共享

额外：以下操作可以提高磁盘 I/O 性能

1. 预读是从磁盘读数据额外预读数据
2. 滞后写是等多一点数据再写
3. 虚拟盘是指用内存空间去仿真磁盘

#### 缓冲区 Buffer

在设备管理子系统中，引入缓冲区的目的主要如下：

1. **缓和 CPU 与 I/O 设备间速度不匹配的矛盾**
2. **减少对 CPU 的中断频率**，放宽对 CPU 中断响应时间的限制
3. **解决基本数据单元大小不匹配的问题**
4. **提高 CPU 和 I/O 设备之间的并行性**

其实现方法如下：

1. 采用**硬件缓冲器**，但由于成本太高，只用于关键部位
2. 采用**缓冲区**，位于内存区域

**缓冲区有以下特点：**

- 当缓冲区的数据非空时，只能从缓冲区把数据传出
- 当缓冲区为空时，可以往缓冲区冲入数据
- 必须把缓冲区充满后，才能从缓冲区把数据传出

选择题：单缓冲、双缓冲、循环缓冲属于**专用缓冲**；缓冲池是系统的共用资源，**可共享**

选择题：缓冲区管理着重要考虑的问题是**实现进程访问缓冲区的同步**

根据系统设置缓冲器的个数，缓冲技术可以分为如下几种：

##### 单缓冲

在设备和处理机之间**设置一个缓冲区**，被交换数据先写入缓冲区，然后被需要数据的设备或处理机取走

假设设备输入一块数据到缓冲区的时间为 T，缓冲区中传送到用户区的时间为 M，数据处理的时间为 C

计算处理一块数据所需的时间：**假设一种初始状态，计算下一次到达相同状态时所需的时间**

设初始状态为：工作区是满的，缓冲区是空的，一般认为缓冲区的大小和工作区的大小相等：

- 假设 T > C：在 T 时间后写入缓冲区和处理数据都完成，M 时间传送到用户区后，回到初始状态，用时 M + T
- 假设 T < C：在 C 时间后写入缓冲区和处理数据都完成，M 时间传送到用户区后，回到初始状态，用时 M + C

所以**单缓冲区处理每块数据的用时为 max(C, T) + M**

注意：缓冲区中传送到用户区和数据处理都是 CPU 在做，所以不能并行，但都可以和设备输入数据并行

![image-20211122213548458](..\images\image-20211122213548458.png)

##### 双缓冲

I/O 设备输入数据时先装填到缓冲区 1，在缓冲区 1 填满后才开始装填缓冲区 2，同时可以从缓冲区 1 中取出数据

双缓冲机制**提高了处理机和输入设备的并行操作的程度**

设初始状态为：工作区是空的，一个缓冲区是满的，另一个缓冲区是空的；不妨假设 1 满 2 空

- 假设 T > C + M：当 T 时间后回到初始状态
- 假设 T < C + M：当 C + M 时间后回到初始状态（每次进行一个数据块的处理必定需要 C + M 的时间）

**双缓冲区处理一块数据的用时为 max(C + M, T)**

![image-20211122213644612](..\images\image-20211122213644612.png)

若 M + C < T，则可使块设备连续输入；若 C + M > T，则可使 CPU 不必等待设备输入

##### 单双缓冲对比

对于字符设备，若采用行输入方式：

- 双缓冲：用户在输入第一行后，<u>在 CPU 执行第一行中的命令的同时，用户可继续向第二缓冲区输入下一行数据</u>
- 单缓冲：<u>必须等待一行数据被提取完毕才可输入下一行的数据</u>

两台机器之间通信：

- 单缓冲：它们在任意时刻都只能实现单方向的数据传输，而绝**不允许双方同时向对方发送数据**
- 双缓冲：一个用作发送缓冲区，另一个用作接收缓冲区，**实现双向数据传输**

![image-20211122213851387](..\images\image-20211122213851387.png)

##### 循环缓冲

包含**多个大小相等的缓冲区**，这些缓冲区**以循环链表的方式链接在一起**，形成一个环形

循环缓冲用于输入/输出时，还需要有两个指针 in 和 out：

- 输入：从 in 拿到第一个空缓冲区，从设备接收数据到缓冲区中，放满后 in 指向下一个
- 输出：从 out 取第一个满缓冲区，从此缓冲区中提取数据，取空后 out 指向下一个

##### 缓冲池

由**多个系统公用的缓冲区组成**，缓冲区按其使用状况可以形成三个队列：

**空缓冲队列**、装满输入数据的缓冲队列（**输入队列**）和装满输出数据的缓冲队列（**输出队列**）

还应具有 4 种缓冲区：

1. 用于收容输入数据的工作缓冲区
2. 用于提取输入数据的工作缓冲区
3. 用于收容输出数据的工作缓冲区
4. 用于提取输出数据的工作缓冲区

**进程与缓冲区的交互**：

- 输入进程输入数据：从空缓冲队列队首取一个空缓冲区，作为 1，输入数据后挂在输入队列队尾
- 计算进程接受数据：从输入队列队首取一个缓冲区，作为 2，提取数据使用完后挂在空缓冲队列
- 计算进程输出数据：从空缓冲队列队首取一个空缓冲区，作为 3，输入数据后挂在输出队列队尾
- 输出进程接受数据：从输出队列队首取一个缓冲区，作为 4，提取数据使用完后挂在空缓冲队列

![image-20211122214009700](..\images\image-20211122214009700.png)

#### 高速缓存与缓冲区的对比

<img src="..\images\image-20211122214108952.png" alt="image-20211122214108952" style="zoom:150%;" />

### 设备分配与回收

#### 设备分配概述

设备分配是指**根据用户的 I/O 请求分配所需的设备**

分配的总原则：①**充分发挥设备的使用效率**，尽可能地让设备忙碌；②**避免造成进程死锁**

从设备的特性来看，有以下使用设备的方式：

1. 独占式使用设备：**申请设备时，若设备空闲，则将其独占**，直到该设备被释放才允许其他进程申请使用
2. 分时式共享使用设备：当设备没有独占使用的要求时，可以**通过分时共享使用提高利用率**
3. 以 SPOOLing 方式使用外部设备：实现了虚拟设备功能，可以**将设备同时分配给多个进程**，实质上就是对 I/O 操作进行批处理，是**以空间换时间的技术**

#### 设备分配的数据结构

设备分配依据的主要数据结构有<u>设备控制表 DCT、控制器控制表 COCT、通道控制表 CHCT、系统设备表 SDT</u>

由于在多道程序系统中，进程数多于资源数，会引起资源的竞争，因此要有一套合理的分配原则

主要考虑的因素：I/O 设备的固有属性、I/O 设备的分配算法、I/O 设备分配的安全性、I/O 设备的独立性

思考：一个通道对应多个设备控制器，一个设备控制器对应多个设备

##### 设备控制表

**一个设备控制表就表征一个设备**，而这个控制表中的表项就是设备的各个属性

![image-20211122214442221](..\images\image-20211122214442221.png)

- 设备标识符：**物理设备名**，系统中的每个设备的物理设备名唯一
- 指向控制器表的指针：每个设备由一个控制器控制，该指针可找到相应控制器的信息
- 重复执行次数或时间：当重复执行多次 I/O 操作后仍不成功，才认为此次 I/O 失败
- 设备队列的队首指针：**指向正在等待该设备的进程队列**，由进程 PCB 组成队列

##### 控制器控制表

![image-20211123194240617](..\images\image-20211123194240617.png)

- 控制器标识符：各个控制器的唯一 ID
- 与控制器连接的通道表指针：每个控制器由一个通道控制，该指针可找到相应通道的信息
- 控制器队列的队首/尾指针：**指向正在等待该控制器的进程队列**，由进程 PCB 组成队列

##### 通道控制表

通道方式显然要比其他几种方式更加优越，因此**现代操作系统的 I/O 控制采用的都是通道控制**

![image-20211123194348027](..\images\image-20211123194348027.png)

- 通道标识符：各个通道的唯一 ID
- 与通道连接的控制器表首址：可通过该指针找到**该通道管理的所有控制器**相关信息
- 通道队列的队首/尾指针：**指向正在等待该通道的进程队列**，由进程 PCB 组成队列

##### 系统设备表

系统设备表 SDT：**整个系统只有一张 SDT**，它记录已连接到系统中的所有物理设备的情况，**每个物理设备占一个表目**

![image-20211123194414242](..\images\image-20211123194414242.png)

- 设备类：记录设备的类型，逻辑设备名就是这个
- 设备标识符：物理设备名

#### 设备的分配步骤

1. 根据进程请求的逻辑设备名查找 SDT，**用户编程时提供的逻辑设备名是设备类型**

2. 查找 SDT，找到**指定类型的、并且空闲的设备**，将其分配给该进程，操作系统**在[逻辑设备表 LUT](#逻辑设备名到物理设备名的映射) 中新增一个表项**

   若没有空闲的设备，则将进程 PCB 挂到该类设备的等待队列上

3. 根据 DCT 找到 COCT，若**控制器忙碌则将进程 PCB 挂到控制器等待队列中**，不忙碌则将控制器分配给进程

4. 根据 COCT 找到 CHCT，若**通道忙碌则将进程 PCB 挂到通道等待队列中**，不忙碌则将通道分配给进程

   若设备控制器连接了多个通道，则在通道忙时检查下一个通道的状态

要成功分配一个设备必须要：设备可用、控制器可用、通道可用

#### 设备分配的策略

1. 设备分配原则：设备分配应**根据设备特性、用户要求、系统配置情况**

   分配的总原则是：充分发挥设备的使用效率；避免造成进程死锁；**将用户程序和具体设备隔离开**

2. 设备分配方式：

   - 静态分配：主要**用于对独占设备的分配**

     在用户作业开始执行前，由系统**一次性分配该作业所要求的全部设备、控制器**，直到该作业被撤销

     静态分配方式不会出现死锁，但**设备的使用效率低**，不符合分配的总原则

   - 动态分配：在**进程执行过程中根据执行需要进行**

     当进程需要设备时，由系统给进程分配所需要的设备、I/O 控制器，**一旦用完，便立即释放**

     动态分配方式**有利于提高设备的利用率**，但若分配算法使用不当，则**有可能造成进程死锁**

3. 设备分配算法：

   常用的**动态设备分配算法**有**先请求先分配、优先级高者优先**等

   独占设备：既可以采用动态分配方式，又可以采用静态分配方式，但往往**采用静态分配方式**

   共享设备：可被多个进程所共享，一般**采用动态分配方式**

#### 设备分配的安全性

设备分配的安全性是指**设备分配中应防止发生进程死锁**

1. 安全分配方式：每当进程发出 I/O 请求后便进入阻塞态，直到 **I/O 操作完成时才被唤醒**

   因为被阻塞到 I/O 完成，所以它运行时不占资源，阻塞时占一个资源，不会死锁（破坏了保持并请求）

   优点：**设备分配安全**；缺点：CPU 和 I/O 设备**是串行工作**的

2. 不安全分配方式：进程在发出 I/O 请求后**继续运行**，可以继续发 I/O 请求

   仅当进程所请求的设备已**被另一进程占用时，才进入阻塞态**

   优点：可同时占多个设备，以**迅速推进进程**；缺点：这种设备分配有**可能产生死锁**

#### 逻辑设备名到物理设备名的映射

设备独立性：**应用程序独立于具体使用的物理设备**，用于提高设备分配的灵活性和设备的利用率，方便实现 I/O 重定向

逻辑设备表 LUT：用于**将逻辑设备名映射为物理设备名**，以实现设备独立性

LUT 表项包括**逻辑设备名、物理设备名、设备驱动程序入口地址**：

- 当进程**用逻辑设备名来请求分配设备**时，系统为它**分配相应的物理设备**，并在 LUT 中建立一个表项
- 以后进程再利用逻辑设备名请求 I/O 操作时，系统通过**查找 LUT 来寻找相应的物理设备和驱动程序**

在系统中可采取两种方式建立逻辑设备表：

1. **整个系统中只设置一张 LUT**：这样不允许有相同的逻辑设备名，主要**适用于单用户系统**
2. **每个用户设置一张 LUT**：当用户登录时，OS 为用户建立一个进程和一张 LUT，并**把该表放入进程的 PCB**

### SPOOLing 技术

脱机输入/输出技术：**缓和 CPU 的高速性与 I/O 设备低速性之间的矛盾**，提高**独占设备的利用率**

- 处理器只与高速的磁盘交换数据，而不与低速 I/O 设备交换
- 利用专门的外围控制机，让低速 I/O 设备与高速磁盘进行输入输出

SPOOLing 又称**假脱机输入/输出**操作，是操作系统中采用的一项**将独占设备改造成共享设备**的技术，下面是它的组成：

![image-20211122214853891](..\images\image-20211122214853891.png)

选择题：SPOOLing 系统由<u>预输入程序、井管理程序、缓输出程序</u>组成

#### 输入井和输出井

输入井和输出井是指**在磁盘上**开辟出的两个存储区域：

- 输入井模拟脱机输入时的磁盘，用于**收容 I/O 设备输入的数据**
- 输出井模拟脱机输出时的磁盘，用于**收容用户程序的输出数据**

一个进程的输入或输出数据保存为一个文件，所有进程的数据输入或输出文件链接成一个输入（或输出）队列

思考：输入井和输出井与用户程序直接连接，发送数据时写到输出井；接受数据时从输入井拿

#### 输入缓冲区和输出缓冲区

输入缓冲区和输出缓冲区是**在内存中**开辟的两个缓冲区：

- 输入缓冲区：用于**暂存由输入设备送来的数据**，以后再传送到输入井
- 输出缓冲区：用于**暂存从输出井送来的数据**，以后再传送到输出设备

思考：这部分对用户程序透明，由于 I/O 设备是与内存交互的，所以数据要经过内存

#### 输入进程和输出进程

输入进程和输出进程就是**模拟脱机输入和脱机输出时的外围控制机**：

- 输入进程：将数据从 I/O 设备通过输入缓冲区再送到输入井，**用户需要数据时直接从输入井拿**

- 输出进程：**用户需要发送数据时放入输出井**，对应的 I/O 设备空闲时，从输出井拿出数据经过输出缓冲区送到 I/O 设备

---

共享打印机是使用 SPOOLing 技术的一个实例，这项技术已被<u>广泛地用于多用户系统和局域网络</u>

当用户进程请求打印输出时，SPOOLing 系统同意为它打印输出并为它做两件事：

1. 输出进程在输出井中为之**申请一个空闲磁盘块区**，并**将要打印的数据送入其中**
2. 输出进程申请一张空白的用户请求打印表，写入用户打印要求，**挂到请求打印队列上**

SPOOLing 系统的主要特点有：

1. **提高了 I/O 的速度**，将对低速 I/O 设备操作变为对磁盘缓冲区中数据的存取
2. **将独占设备改造为共享设备**，但实际上并没有为任何进程分配设备
3. **实现了虚拟设备功能**，每个进程都认为自己独占了一个设备

思考：提高了 I/O 速度是对于用户程序而言的，它只需要对磁盘进行 I/O 相比于 I/O 设备来说快了很多

注意：用户对井的操作是通过 SPOOLing 软件来进行的，而不是直接访问井

### 设备驱动程序接口

每个设备驱动程序与操作系统之间都有着**相同或相近的接口**，不然每出现一个新设备，都要修改操作系统

对于**每种设备类型**，操作系统都要**定义一组驱动程序必须支持的函数**，如磁盘为读、写、格式化等

驱动程序中通常包含一张表格，指向驱动程序实现接口的函数，装载驱动程序时，操作系统记录这个函数指针表的地址

与设备无关的软件还要**将符号化的设备名映射到适当的驱动程序上**

在 UNIX 中，设备名 `/dev/disk0` 确定特殊文件的 i 结点，包含主设备号（定位驱动程序）和次设备号（确定具体设备）

在 UNIX 和 Windows 中，设备是作为命名对象出现在文件系统中的，因此**针对文件的常规保护规则也适用于 I/O 设备**

