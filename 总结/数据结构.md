# 数据结构

* [第一章 绪论](#绪论)
* [第二章 线性表](#线性表)
* [第三章 栈、队列和数组](#栈、队列和数组)
* [第四章 串](#串)
* [第五章 树与二叉树](#树与二叉树)
* [第六章 图](#图)
* [第七章 查找](#查找)
* [第八章 排序](#排序)

# 绪论

## 数据结构的基本概念

### 基本概念和术语

1. 数据：数据是**信息的载体**，是所有能输入到计算机中并<u>被计算机程序识别和处理的符号的集合</u>

2. 数据元素：数据元素是数据的**基本单位**，通常作为**一个整体**进行考虑和处理，一个数据元素可由若干数据项组成

3. 数据项：数据项是构成数据元素**不可分割的最小单位**，如一条学生记录是数据元素，里面的姓名等是数据项

4. 数据对象：数据对象是具有**相同性质的数据元素的集合**，如整数数据对象是集合 $N = {0,\pm1,\cdots}$

5. 数据类型：数据类型是一个值的集合和定义在此集合上的一组操作的总称

   如 int 类型，它的集合是 $[-2^{16},2^{16}-1]$，它的操作是：加、减、乘、除、模等

   1. 原子类型：其值**不可再分**的数据类型

   2. 结构类型：其值**可以再分解**为若干成分的数据类型，如一个结构体里面包含若干数据类型，还有若干操作

   3. 抽象数据类型：抽象数据组织及与之相关的操作，如栈就是抽象数据类型

      定义抽象数据类型，就是定义数据的**逻辑结构 + 数据的运算**，当真正用计算机实现抽象数据类型时，才需要涉及数据的存储结构

6. 数据结构：数据结构是相互之间存在一种或多种特定**关系**的数据元素的集合

   数据结构包括三方面的内容：逻辑结构、存储结构、数据的运算

   数据的逻辑结构和存储结构是不可分的两个方面，算法设计取决于逻辑结构，算法实现取决于存储结构

注意：数据结构是强调数**据元素之间的关系以及之间的运算**；数据对象是强调数据元素的有**同一性质**

选择题：完整的数据结构的定义只需要逻辑结构和数据运算，而实现才需要存储结构

### 数据结构三要素

#### 数据的逻辑结构

逻辑结构是指数据元素之间的逻辑关系，即从逻辑关系上描述数据

数据的逻辑结构分为**线性结构**和**非线性结构**

线性结构：线性表、栈和队列、串、数组

非线性结构；集合、树形结构、图状结构

- 集合：数据元素间仅有**同属一个集合**的关系
- 线性结构：数据元素间只存在**一对一**关系
- 树形结构：数据元素间存在**一对多**关系
- 图状结构：数据元素间存在**多对多**关系

#### 数据的存储结构

存储结构是指数据结构在计算机中的表示，也称物理结构

1. 顺序存储：**逻辑上相邻**的元素存储在**物理位置上也相邻**的存储单元中，下面三个是非顺序存储
2. 链式存储：借助**元素存储地址的指针**令逻辑相邻的元素在物理上不必相邻
3. 索引存储：在存储元素信息的同时，还建立附加的**索引表**，用索引表记录数据存放的位置
4. 散列存储：根据**元素的关键字**直接计算出该**元素的存储地址**，又称哈希存储

#### 数据的运算

施加在数据上的运算包括运算的定义和实现

运算的定义是针对逻辑结构的，指出运算的功能

运算的实现是针对存储结构的，指出运算的具体操作步骤

## 算法与算法评价

### 算法的基本概念

算法是**对特定问题求解步骤的一种描述**

一个算法具有下列 **5 个重要特性**：

1. 有穷性：一个算法必须在有穷步后结束，**运行时间是有穷的**
2. 确定性：算法中每条指令必须有确切的含义，**同样输入会有同样输出**
3. 可行性：算法的操作有可以**通过已实现的基本运算来实现**
4. 输入：一个算法有零或多个输入
5. 输出：一个算法有零或多个输出

一个好的算法应当考虑**达到以下目标**：

1. 正确性：算法应当正确解决问题
2. 可读性：算法应具有良好的可读性，以帮助人们理解
3. 健壮性：能够处理非法数据，不会产生莫名其妙的输出
4. 效率与低存储量要求：效率指算法的执行时间，存储量需求指算法执行过程所需的最大存储空间

### 算法效率的度量

#### 时间复杂度

一个语句的**频度**是指该语句在算法中被**重复执行的次数**

时间复杂度 T(n) 是指算法中所有语句的频度之和，它是算法规模 n 的函数

经常采用同数量级频度的 f(n) 来分析算法的时间复杂度，T(n) = O(f(n))

其中 O 的定义是存在常数 C 和 $n_0$ 当 $n\geq n_0$ 时，满足 $0\leq T(n) \leq Cf(n)$

当不同情况的时候，时间复杂度也会不一样：

1. 最坏时间复杂度：指在最坏情况下，算法的时间复杂度
2. 平均时间复杂度：指所有可能输入实例在等概率出现的情况下，算法的期望运行时间
3. 最好时间复杂度：指在最好情况下，算法的时间复杂度

**一般总是考虑在最坏情况下的时间复杂度**

分析程序时间复杂度的两条准则：

1. 加法准则：$T(n)=T_1(n)+T_2(n)=O(f(n))+O(g(n))=O(max(f(n),g(n)))$
2. 乘法准则：$T(n)=T_1(n)\times T_2(n)=O(f(n))\times O(g(n))=O(f(n)\times g(n))$

**常见的渐进复杂度为：**

$O(1)<O(\log_2n)<O(n)<O(n\log_2n)<O(n^2)<O(n^3)<O(2^n)<O(n!)<O(n^n)$

#### 空间复杂度

算法的空间复杂度 S(n) 定义为该**算法所消耗的存储空间**，它是问题规模 n 的函数，S(n) = O(g(n))

辅助空间是指对数据进行操作的工作单元和存储一些为实现计算所需信息的空间

算法**原地工作**是指算法所需的辅助空间为常量，即 O(1)

## 思维拓展

斐波那契数列的时间复杂度 $F(n)=\left\{\begin{matrix}1,&n=0,1\\F(n-1)+F(n-1),&n>1 \end{matrix}\right.$

对于递归而言，斐波那契数列形成树形结构的函数调用，所以时间复杂度是 $O(2^n)$

对于非递归而言，使用数组存储上一个值，所以迭代就可以，时间复杂度 O(n)

# 线性表

## 线性表的定义和基本操作

### 线性表的定义

线性表是具有**相同数据类型** n 个数据元素的**有限序列**，其中 n 为表长，当 n = 0 时线性表是一个空表

以 L 命名线性表，其表示为 $L=(a_1,a_2,\cdots,a_n)$，$a_1$ 叫表头元素，$a_n$ 叫表尾元素

除第一个元素外，每个元素都有一个直接前驱；除最后一个元素外，其他元素都有一个直接后继

线性表有以下特点：

1. 表中元素的**个数有限**
2. 表中元素具有**逻辑上的顺序性**，表中元素有先后次序
3. 表中元素都是**数据元素**，每个元素都是单个元素
4. 表中元素的**数据类型相同**，即元素的大小相同
5. 表中元素具有抽象性，即仅讨论元素间的逻辑关系，而不考虑内容

注意：线性表是逻辑关系，表示元素间的逻辑关系；顺序表和链表是存储关系，表示元素的物理关系

### 线性表的基本操作

```c
InitList(L);  // 初始化表
Length(L);  // 求表长
LocateElem(L, e);  // 按值查找位置
GetElem(L, i);  // 按位置查找值
ListInsert(&L, i, e);  // 插入操作
ListDelete(&L, i, &e);  // 删除操作, e 是返回删除元素
PrintList(L);  // 输出操作，按前后顺序输出线性表的所有值
Empty(L);  // 判空操作
DestroyList(&L);  // 销毁操作，回收线性表的内存
```

## 线性表的顺序表示

### 顺序表的定义

顺序表是用一组地址连续的存储单元依次存储线性表中的数据元素，使得两个元素在**逻辑和物理上都相邻**

线性表中的任一数据元素都可以**随机存储**，线性表的顺序存储结构是一种**随机存储结构**

**注意：线性表中元素的位序是从 1 开始的，而数组中元素的下标是从 0 开始的**

静态分配时，一旦空间占满再加入新数据就会**溢出**导致程序崩毁，存储类型描述为：

```c
#define MaxSize 50
typedef struct {
    ElemType data[MaxSize];
    int length;
} SqList;
```

动态分配时，一旦数据空间占满，就另外**开辟一块更大的存储空间**，以替换原来的空间，存储类型描述为：

```c++
#define InitSize 100
typedef struct {
    ElemType *data;
    int MaxSize, length;
} SeqList;

L.data = (ElemType*)malloc(sizeof(ElemType) * InitSize);  // C 的内存分配
L.data = new ElemType[InitSize];  // C++ 的内存分配
```

**顺序表的特点：**

1. 顺序表最主要的特点是随机访问，给了首地址和元素序号可在 O(1) 内找到元素
2. 顺序表的存储密度高，每个结点只存储数据元素
3. 顺序表逻辑及上相邻的元素物理上也相邻，所以插入和删除操作需要移动大量元素

### 顺序表上基本操作的实现

#### 插入操作

```c
bool ListInsert(SqList &L, int i, ElemType e) {
    if (i < 1 || i > L.length + 1)  // 验证 i 是否越界
        return false;
    if (L.length >= Maxsize)  // 存储空间是否还有空位
        return false;
    for (int j = L.length; j >= i; j--)  // 将第 i 个元素后移
        L.data[j] = L.data[j - 1];
    L.data[i - 1] = e;  // 把 e 插入位置 i
    L.length++;  // 长度加一
    return true;
}
```

最好情况：表尾插入，元素后移不执行，时间复杂度为 O(1)

最坏情况：表头插入，元素后移执行 n 次，时间复杂度为 O(n)

平均情况：每个位置移动的次数加起来除以位置的个数，$\dfrac{1}{n+1}\displaystyle\sum^{n+1}_{i=1}(n-i+1)=\dfrac{n}{2}$，时间复杂度为 O(n)

#### 删除操作

```c
bool ListDelete(SqList &L, int i, ElemType &e){
    if (i < 1 || i > L.length)  // 验证 i 是否越界
        return false;
    e = L.data[i - 1];  // 将要删除的元素赋值给 e
    for (int j = i; j < L.length; j++)  // 将第 i 位置后的元素前移
        L.data[j - 1] = L.data[j];
    L.length--;  // 长度减一
    return true;
}
```

最好情况：删除表尾元素，无需移动元素，时间复杂度为 O(1)

最坏情况：删除表头元素，需移动表头外的元素，时间复杂度为 O(n)

平均情况：计算法和插入时一样，时间复杂度为 O(n)

#### 按值查找

```c
int LocateElem(SqList L, ElemType e){
    int i;
    for (i = 0; i < L.length; i++)
        if (L.data[i] == e)
            return i + 1;  // 返回其位序 i + 1
    return 0;  // 查找失败
}
```

最好情况：查找元素在表头，仅比较一次，时间复杂度为 O(1)

最坏情况：查找元素在表尾，需要比较 n 次，时间复杂度为 O(n)

平均情况：计算法和插入时一样，时间复杂度为 O(n)

### 综合应用题

#### 删除表内所有为 x 的元素

问题：对长度为 n 的顺序表 L，编写一个时间复杂度为 O(n)、空间复杂度为 O(1) 的算法，该算法删除线性表中所有值为 x 的数据元素

```c
void deleteElem(SqList &L, ElemType x){
    int k = 0;
    for (int i = 0; i < L.length; i++)
        if (L.data[i] != x)
            L.data[k++] = L.data[i];
    L.length = k;
}
```

#### 数组中的两个顺序表位置互换

思想：先整个数组逆置，这时 $L=(b_n,\cdots,b_1,a_n,\cdots,a_1)$ 再将 A 和 B 内部分别逆置就有 $L=(b_1,\cdots,b_n,a_1,\cdots,a_n)$

```c
void Reverse(int []array, int left, int right){
    int mid = (right - left) / 2;
    int tmp;
    for (int i = 0; i <= mid; i++){
        tmp = array[left + i];
        array[left + i] = array[right - i];
        array[right - i] = tmp;
    }
}

void Exchange(int []array, int m, int n){
    int len = m + n;
    Reverse(array, 0, len - 1);
    Reverse(array, 0, n - 1);
    Reverse(array, n, len - 1);
}
```

时间复杂度 O(n)，空间复杂度 O(1)

方法 2：使用 a 和 b 的后半部分交换，就有 $L=(b_{m-n+1},\cdots,b_m,b_1\cdots,b_{m-n},a_1,\cdots,a_n)$，就变成 $(b_2,b_1,a)$，反复换几次就可以，最后 $b_1$ 和 $b_2$ 长度相等直接交换就行，这里可以思考直接使用最大公约数的解法

#### 两个长度相同数组的联合中位数

问题：有两个长度一样的升序数组，求它们合并后的中位数，是中间两个数中的较小值

思想：设 a 和 b 是 A 和 B 的中位数

当 a < b 时，a 的左半部分已经无缘中位数，舍去，因为 ab 和并后这部分的点不可能在中间；b 的右半部分也一样

当 b > a 时，舍去 b 的左半和 a 的右半

当 b = a 时，显然中位数相等，那么这就是全部的中位数

当舍去直到自己时，中位数就是 a 和 b 间的最小值

注意：这种算法只适合两个长度相同的数组

```c
int MiddleSearch(int A[], int B[], int n) {
    int s1 = 0, d1 = n - 1, m1, s2 = 0, d2 = n - 1, m2;
    // s1 == d1 舍去到只剩下自己
    while(s1 != d1 || s2 != d2) {
        m1 = (s1 + d1) / 2;
        m2 = (s2 + d2) / 2;
        if (A[m1] == B[m2])  // 当两个中位数一样时，即使全部的中位数
            return A[m1];
        if (A[m1] < B[m2]) {
            // 元素的个数为奇数
            if ((s1 + d1) % 2 == 0) {
                // 奇数的话需要保留中点
                s1 = m1;
                d2 = m2;
            } else {
                // 偶数的话把整个部分都舍去了
                s1 = m1 + 1;  // 舍去左边，因为中点在左边，所以加一
                d2 = m2;  // 舍去右边不包括中点
            }
        } else {
            if ((s2 + d2) % 2 == 0) {
                d1 = m1;
                s2 = m2;
            } else {
                d1 = m1;
                s2 = m2 + 1;
            }
        }
    }
    return A[s1] < B[s2] ? A[s1] : B[s2];
}
```

时间复杂度 $O(\log_2n)$，空间复杂度 O(1)

#### 序列的主元素

问题：当一个元素在序列中出现的次数超过一半就把他叫做序列的主元素，求序列是否存在主元素

思想：利用超过一半才叫主元素的特点，使用计数 Count

扫描序列，将第一个数保存到 Elem 中，若下一个数仍是 Elem 计数加一，否则减一；当计数减到零时，将下一个数保存到 Elem 中

完成后再次扫描序列，统计记录的数的个数

```c
int Majority(int A[], int n){
    int i, count = 1, c = A[0];
    for (i = 1; i < n; i++){
        if (A[i] == c) count++;  // 增加该元素的计数
        else if (count > 0) count--;  // 有计数时减少计数
        else {  // 没有时更换计数元素
            count = 1;
            c = A[i];
        }
    }
    if (count > 0)
        for (i = count = 0; i < n; i++)  // 统计元素出现的次数
            if (A[i] == c)
                count++;
    if (count > n / 2) return c;
    else reutrn -1;
}
```

时间复杂度 O(n)，空间复杂度 O(1)

#### 最小未出现正整数

问题：设计在时间上尽可能高效的算法，找出数组中未出现的最小正整数

给定一个含 n ≥ 1 个整数的数组 A

思想：做一个长度为 n 的辅助数组 B，A[i] ≤ n 令 B[A[i]] = 1，最后迭代 B 寻找第一个为 0 的位置

#### 三元组的最短距离

问题：定义三元组的距离 D = |a - b| + |b - c| + |c - a|

给定 3 个非空整数集合，按**升序**分别存储在 3 个数组中

需要计算并输出所有可能的三元组中的最小距离

------

思想：假设一条 x 轴，有三个点 a, b, c 假设 $a\leq b\leq c$ 那么它们距离其实就是 $2|c - a|$ 那么只要缩小它们的距离就好了

不妨让 a 增加看一下是否变得更短了，因为 c，b 增加只会变更长或者不变

因此我们设置整数存储最短距离 D_m，然后计算距离，比最短距离短就修改最短距离

然后让最小的值的那个数组索引加一，相当于让 a 增加，在次计算距离直到全部迭代

```c
int abs(int a){
    return a >= 0 ? a : -a;
}

bool min(int a, int b, int c){
    if (a <= b && a <= c) return true;
    return false;
}

int FindMinofTrip(int A[], int n, int B[], int m, int C[], int p) {
    int minD = 0x7fffffff, D;
    int i = 0, j = 0, k = 0;
    while (i < n && j < m && k < p && minD > 0){
        D = abs(A[i] - B[j]) + abs(B[j] - C[k]) + abs(C[k] - A[i]);
        if (D < minD) minD = D;
        if (min(A[i], B[j], C[k])) i++;
        else if (min(B[j], A[i], C[k])) j++;
        else k++;
    }
    return minD;
}
```

时间复杂度 O(n)，空间复杂度 O(1)

## 线性表的链式表示

链式存储线性表时，不要求逻辑上相邻的元素在物理位置上也相邻，它通过链建立数据元素之间的关系

插入和删除操作**不需要移动元素**，**只需修改指针**，但也**失去顺序表可随机存储**的优点

选择题：链式存储结构比顺序存储结构能**更方便地表示各种逻辑结构**，不像顺序存储必须要用物理相邻来表示逻辑结构

### 单链表

#### 单链表的定义

线性表的链式存储又称单链表，对于每个链表结点，除了存储自身数据外，还**需存储指向其后继的指针**

单链表的结点结构如下，其中 data 为**数据域**，存放数据；next 为**指针域**，存放后继结点的指针：

```c
typedef struct LNode{
    ElemType data;  // 数据域
    struct LNode *next;  // 指针域
}LNode, *LinkList;
```

单链表可以解决顺序表需要大量连续存储的缺点，但多加了指针域也会浪费空间

而且单链表不能直接找到表中特定的点，需要**从头遍历依次查找**

头指针和头结点：头指针是指向第一个结点的指针，为了**操作方便**会带有头结点，即拿一个空结点做头；同样是表空操作，如果**只有头指针** head == NULL，如果**带了头结点** head->next == NULL

引入头结点后，可以带来两个优点（**操作方便**）：

1. 有头结点后第一个位置上的操作和在表的其他位置的操作一致，无需特殊处理
2. 无论表是否为空，头指针都指向非空结点，空表与非空表处理统一

#### 单链表上基本操作的实现

##### 采用头插法建立单链表

头插法就是从空表开始，把每一个结点都插入表头

```c
LinkList ListHeadInsert(LinkList &L){
    LNode *s;
    int x;
    L = (LinkList)malloc(sizeof(LNode));  // 创建头结点
    L -> next = NULL;
    scanf("%d", &x);
    while (x != 9999) {
        s = (LNode *)malloc(sizeof(LNode));  // 创建新结点
        s -> data = x;
        s -> next = L -> next;  // 把旧结点链入新结点
        L -> next = s;  // 设置新结点为表头
        scanf("%d", &x);
    }
    return L;
}
```

采用头插法建立单链表时，**读取数据的顺序**与生成的链表中的元素的顺序是**相反**的，时间复杂度是 O(n)

##### 采用尾插法建立单链表

尾插法是把每一个结点都插入表尾，因此需要一个表尾指针，时间复杂度是 O(n)

```c
LinkList ListTailInsert(LinkList &L){
	int x;
	L = (LinkList)malloc(sizeof(LNode));
	LNode *s, *r = L;
	scanf("%d", &x);
	while(x != 9999){
		s = (LNode*)malloc(sizeof(LNode));
		s -> data = x;
		r -> next = s;  // 把元素插入表尾
		r = s;  // 指向新的表尾
		scanf("%d", &x);
	}
	r -> next = NULL;
	return L;
} 
```

##### 按序号查找结点值

从第一个结点出发，按照指针域依次迭代，直到找到第 i 个结点，时间复杂度是 O(n)

```c
LNode *GetElem(LinkList L, int i){
	int j = 1;
	LNode *p = L -> next;
	if(i == 0)
		return L;
	if(i < 1)
		return NULL;
    // 迭代查找位置为 i 的结点，但 i 超长就只能返回 NULL
	while(p && j < i){
		p = p -> next;
		j++;
	}
	return p;
}
```

##### 按值查找表结点

从第一个结点出发，依次比较数据域的值 ，若值相等返回结点指针，没有返回 NULL，时间复杂度是 O(n)

```c
LNode *LocateElem(LinkList L, ElemType e){
	LNode *p = L -> next;
	while(p != NULL && p -> data != e)  // 查找数据域为 e 的结点
		p = p -> next;
	return p;  // 找到返回指针，否则返回 NULL
}
```

##### 插入结点操作

插入结点首先要找到前一个结点，然后判断结点是否合法，最后再插入，时间复杂度 O(n)

```c
bool ListInsert(LinkList L, int i, ElemType e){
	LinkList p = GetElem(L, i - 1);  // 拿到前一个结点
	if(NULL == p) {  // 检验合法性
		return false;
	}
    // 插入
	LinkList s = (LNode*)malloc(sizeof(LNode));
	s -> data = e;
	s -> next = p -> next;
	p -> next = s;
	return true;
}
```

若有 *p 要把 *s 插入 *p 的前面，这时我们可以把 *s 插入 *p 的后面，然后互换数据

```c
// 把 s 插入 p 后面
s -> next = p -> next;
p -> next = s;
// 交换数据
temp = p -> data;
p -> data = s -> data;
s -> data = temp;
```

##### 删除结点操作

删除结点，首先拿到它的前驱，然后检查结点的合法性，然后删除，时间复杂度是 O(n)

```c
bool ListDelete(LinkList L, int i){
	LinkList p = GetElem(L, i - 1);  // 拿到前驱
	if(NULL == p) {  // 验证合法性
		return false;
	}
    // 删除数据
	LinkList q;
	q = p -> next;
    if (q == NULL) return false;
	p -> next = q -> next;
    free(q);
	return true;
}
```

若有 *p 且要把 *p 删除，我们可以把 *p 的数据域等于它的下个结点，然后把下个结点删除

```c
// 这里的 q != NULL 时才能使用
q = p -> next;
p -> data = q -> data;  // 等于下个结点的数据域
p -> next = q -> next;  // 删除下个结点
free(q);
```

##### 求表长操作

求表长是计算单链表中数据结点的个数，需要从第一个开始向下遍历，每遍历一个计数加一

当访问到空结点的时候计数就是表的长度，时间复杂度是 O(n)

### 双链表

双链表结点有**两个指针 prior 和 next**，分别**指向前驱和后继**，类型的描述如下：

```c
typedef struct DNode{
	ElemType data;  // 数据域
	struct DNode *prior, *next;  // 前指针和后指针
}DNode, *DLinkList;
```

由于添加了前驱指针所以访问前一个结点是时间复杂度变为 O(1)

仅添加了一个前驱指针，因此只在插入和删除上与单链表有较大的区别

#### 双链表的插入操作

在双链表插入中，不仅要调整与后继结点的关系，还要调整与前驱结点的关系

```c
bool DListFrontInsert(DLinkList DL,int i,ElemType e) {
	DLinkList p = GetElem(DL, i - 1);  // 获取前驱值
	if(NULL == p)  // 验证前驱合法性
		return false;
	DLinkList s = (DNode*)malloc(sizeof(DNode));
	s -> data = e;
	s -> next = p -> next;  // 调整和后继的关系
    if (p -> next != NULL)
		p -> next -> prior = s;
	s -> prior = p;  // 调整和前驱的关系
	p -> next = s;
	return true;
}
```

#### 双链表的删除操作

双链表删除和单链表差不多，要注意调整后继的指针要指向前驱

```c
bool DListDelete(DLinkList DL, int i) {
	DLinkList p = GetElem(DL, i - 1);  // 拿到前驱
	if(NULL == p)  // 验证合法性
		return false;
	DLinkList q;
    // 删除结点
	q = p -> next;
	if(q == NULL) return false;
	p -> next = q -> next;
	if(q -> next != NULL)  // 比单链表多的一步
		q -> next -> prior = p;
	free(q);
	return true;
}
```

### 循环链表

#### 循环单链表

![image-20220504145515175](..\images\image-20220504145515175.png)

循环单链表和单链表的区别：表中**最后一个结点的指针指向头结点**，从而形成一个环

循环单链表的判空条件是**头结点的指针是否等于头指针**

循环单链表通常不设头指针而设尾指针（方便表头表尾操作），因为 r -> next 就是头指针

循环链表可以从任一结点开始遍历整个链表，它的插入和删除操作和单链表基本一样

注意：即使有尾指针，**删除尾结点时间复杂度一样是 O(n)**，因为要拿到尾结点的前驱

#### 循环双链表

循环双链表与循环单链表不同的是，除了尾结点的 next 要指向头结点，它**头结点的 prior 还要指向表尾**

当循环双链表为空表时，其**头结点的 prior 和 next 都等于头指针**

### 静态链表

静态链表借助数组来描述线性表的链式存储结构，结点也有**数据域和指针域**

但静态链表的结点的指针域**存放的是数组的下标**，是相对地址，又称游标

因为是由数组实现的，所以和顺序表一样也要**预先分配一块连续的内存空间**

```c
#define MaxSize 50
typedef struct {
    ElemType data;  // 存储的数据
    int next;  // 下一个元素的数组下标
} SLinkList[MaxSize];
```

静态链表**以 next == -1 作为结束标志**，它的插入删除和动态链表一样**只需要修改指针**，但总的来说没动态链表方便

在一些不支持指针的高级语言中，这是一种链表的巧妙的设计方法

### 顺序表和链表的比较

1. 存取（读写）方式：顺序表可以**顺序存取和随机存取**，但链表只能**顺序存取**
2. 逻辑结构和物理结构：
   1. 顺序存储时，逻辑相邻的元素对应**物理存储位置也相邻**
   2. 链式存储时，逻辑相邻的元素，**物理存储位置不一定相邻**，逻辑关系是通过**指针链接表示**
3. 查找、插入、删除操作：
   1. 按值查找时，**无序**两者都需要 O(n)；**有序时**顺序表仅需要 $O(log_2n)$
   2. 按序号查找时，顺序表可**随机访问 O(1)**，链表要**迭代 O(n)**
   3. 插入和删除时，顺序表平均**要移动半个表的元素**，而链表**仅修改相关指针**，但需要先找到前驱，复杂度都是 O(n)
4. 空间分配：
   1. 顺序存储在**静态分配时**，存储满了就会溢出，因此需要**预先分配足够的存储空间**；**动态分配时**，需要**移动大量元素**，会导致操作效率低，没有足够的连续空间时还会分配失败
   2. 链式存储就只需要在**使用时分配**，操作灵活、高效

### 取舍顺序表和链表

1. 基于存储的考虑：**难以估计线性表长度或规模时**，使用链表；但链表存储密度低，**能估计规模时用顺序表**
2. 基于运算的考虑：需要**大量按序号访问操作**时，使用顺序表；需要**大量插入删除**时，使用链表
3. 基于环境的考虑：所有语言都有数组，但不是所有语言都有指针，相对来讲顺序表更好实现

通常较稳定的线性表选择顺序存储，频繁插入、删除操作时选择链式存储

### 综合应用题

#### 递归删除链表中值为 x 的结点

思想：

当 L 为 NULL 时，迭代完链表退出

当 L 的数据域等于 x 把 L 删了，递归下一个结点

当 L 的数据域不等于 x 时直接递归下一个结点

```c
void Delete(LinkList &L, ElemType e){
    LNode *p;
    if (L == NULL) return;
    if (L -> data == e) {
        p = L;
        L = L -> next;  // 注意这个 L 的类型是引用类型，会修改原链表的指针域
        free(p);
        Delete(L, e);
    } else Delete(L -> next, e);
}
```

#### 链表是否有环

问题：判断一个链表是否有环，如果有，找出环的入口并返回，否则返回 NULL

思想：

设快慢两个指针 fast、slow，fast 每次走两步，slow 每次走一步，当它们碰头了就表示有环

接下来就是求环的入口了，设头结点到环入口距离为 a，环长为 r

当 slow 走到环入口时，fast 在环中的位置是 a % r，fast 与 slow 的距离是 r - a % r

slow 从入口走 r - a % r 步会碰面，那么它们碰面时的在环中的位置是 r - a % r

考虑到 (a + r - a % r) % r = 0，所以在碰面的地方再走 a 就到达入口了

因此可设置两个指针，一个指向 head 一个指相遇点，同时移动，相交就是入口点

```c
LNode *FindLoopStart(LNode *head) {
    LNode *fast = head, *slow = head;  // 设置快慢两指针
    while(fast != NULL && fast -> next != NULL) {
        slow = slow -> next;
        fast = fast -> next -> next;
        if (slow == fast) break;  // 相遇
    }
    if (fast == NULL || fast -> next == NULL) 
        return NULL;  // 没有环
    LNode *p1 = head, *p2 = slow;  // 分别指向开始点和相遇点
    while (p1 != p2) {
        p1 = p1 -> next;
        p2 = p2 -> next;
    }
    return p1;  // 返回入口点
}
```

#### 会做的考研题

##### 求链表倒数第 k 结点

问题：带头结点的单链表，查找倒数第 k 个位置上的结点

思想：设置 p、k 两个变量，p 指针沿链表移动，当 p 移动到第 k 个结点时，q 开始和 p 同步移动，当 p 移动到最后一个结点时，q 就是倒数第 k 个结点

##### 两个单链表的共同结点

问题：采用带头结点的单链表保存单词，当两个单词有共同后缀时可共享后缀存储空间，求共同后缀的起始位置

思想：如果两个链表有公共结点，那么透视图就应该是 Y 形的，公共结点后面的结点都是重合的

我们可以求出两个链表的长度，并取出它们的差，让较长的那个跳过一些结点留下和较短的一样长的结点

然后两个一起迭代，直到两个结点一样进行返回，就像下面

loading -> ading -> ing

being    -> being -> ing

##### 去绝对值相等的重复元素

问题：用单链表保存 m 个整数，且 $|data|\leq n$ 数据域的数据的绝对值小于 n，现需要删除绝对值相等的数据，仅保留第一次出现的结点，要求时间复杂度尽可能高效

思想：使用辅助数组记录链表中以出现的数值，从而只需对链表进行一趟扫描

辅助数组 q 大小为 n + 1，初始值为 0，依次扫描链表中各点并检查 q[|data|] 的值，为 0 就置 1 并保留该结点，为 1 就删去

##### 重新排列链表

问题：有链表 $L=(a_1,\cdots,a_n)$ 现要排列成 $L^{'}=(a_1,a_n,a_2,a_{n-1},\cdots)$，要求空间复杂度 O(1)

思想：将后半部分逆置（头插法），然后从两端单链表依次取一个结点，按要求重排

取中间结点可以取两个指针，一个一次走一步，一个一次走两步

## 思想拓展

一个长度为 N 的整形数组 A[1...N]，给定整数 X，请设计一个时间复杂度不超过 $O(n\log_2n)$ 的算法，查找出这个数组中所有两两之和等于 X 的整数对

实现这个有两种方法：

1. 使用时间复杂度为 $O(n\log_2n)$ 排序成有序数组，然后分别从数据的小端 i = 1 和大端 j = N 开始查找，若 A[i] + A[j] < X，i++；若 A[i] + A[j] > X，j--；如果相等就输出并 i++, j--；当 i > j 时停止，总复杂度 $O(n\log_2n)$
2. 使用 HashSet，迭代数组若 `set.contains(X - A[i])` 则输出，否则将 A[i] 放入 HashSet 中，时间复杂度是 O(n)

```java
// 第一种方法
public static void expectSumBySort(int[] arr, int expectSum)
{
    if(arr == null || arr.length == 0)
        return;
    Arrays.sort(arr);
    int left = 0, right = arr.length - 1;

    while(left < right)
    {
        if(arr[left] + arr[right] > expectSum)
            right--;
        else if(arr[left] + arr[right] < expectSum)
            left++;
        else//equal
        {
            System.out.println(arr[left] + " + " + arr[right] + " = " + expectSum); 
            left++;
            right--;
        }
    }
}

// 第二种方法
public static void expectSumBySet(int[] arr, int expectSum)
{
    if(arr == null || arr.length == 0)
        return;
    HashSet<Integer> intSets = new HashSet<Integer>(arr.length);

    int suplement;
    for (int i : arr)
    {
        suplement = expectSum - i;
        if(!intSets.contains(suplement)){
            intSets.add(i);
        }else{
            System.out.println(i + " + " + suplement + " = " + expectSum);
        }
    }
}
```

#  栈、队列和数组

## 栈

### 栈的基本概念

#### 栈的定义

栈是只允许**在一端进行插入或删除操作**的线性表，即栈是一种操作受限的线性表

**栈顶**是线性表**允许进行插入**的那一端；**栈底**是固定的**不允许进行插入**的另一端；**空栈**是**不含任何元素**的空表

由于栈只能在栈顶进行插入和删除操作，所以栈的操作可以明显的概括为**后进先出**

**栈满还存为上溢，栈空再取即下溢**。上溢和下溢都修改了**栈之外的内存**，因此有可能导致程序崩溃

n 个不同元素进栈，出栈元素**不同排列的个数**为 $\dfrac{1}{n+1}C^{n}_{2n}=\dfrac{1}{n+1}\dfrac{(2n)!}{n!\cdot n!}$，这是卡特兰数

#### 出栈排列个数思考

把 n 个元素的出栈个数的记为 f(n)，显然有 f(1) = 1、f(2) = 2

第一个元素在出栈时可能会在位置 1、位置 2......一直到位置 n

如 `abcd` 出栈的话会是 `abcd`, `bacd`, `cbad`, `dcba` 其中 a 的位置分别是 1, 2, 3, 4

1. 假设第一个元素在位置 1，那么就和后面 n - 1 个元素的排序，即 f(n - 1)

2. 假设第一个元素在位置 2，那么有前面 1 个元素的排列和后面 n - 2 的元素排列，排列个数为 f(1) * f(n - 2)

3. 那么第一个元素在位置 i，那么有前面 i - 1 个元素的排列和后面  n - i 个元素的排列，排列个数为 f(i - 1) * f(n - i)

   如 a 在第三位，那么 a 压入栈后最多只能再入两个元素，即有两个元素自由搭配，a 出栈后有 n - 3 个元素自由搭配

4. 把上面的都加起来就是 $f(n)=f(n-1)+f(1)*f(n-2)+\cdots+f(i-1)*f(n-i)+\cdots+f(n-1)$

5. 令 f(0) = 1，就有 $f(n)=\displaystyle\sum^n_{i=1}f(i-1)*f(n-i)$

#### 栈的基本操作

```c
InitStack(&S);  // 初始化空栈
StackEmpty(S);  // 判断一个栈是否为空
Push(&S, x);  // 入栈
Pop(&S, &x);  // 出栈
GetTop(S, &x);  // 读取栈顶元素
DestroyStack(&s);  // 销毁栈
```

在解答算法题时，若题干未做出限制，则可直接使用这些基本的操作函数

### 栈的顺序存储结构

#### 顺序栈的实现

采用顺序存储的栈称为顺序栈，它利用**数组**存放栈的数据元素，并附上一个**指针**指示当前栈顶元素的位置

```c
#define MaxSize 50
typedef struct DNode{
    ElemType data[MaxSize];  // 存放栈中元素
    int top;  // 栈顶指针
}SqStack;
```

栈顶指针：`S.top`，初始时设置 `S.top = -1`

栈顶元素：`S.data[S.top]`

进栈操作：栈不满时，栈顶指针先加 1，再送值到栈顶元素

出栈操作：栈非空时，先取栈顶元素值，再将栈顶指针减 1

栈空条件：`S.top == -1`

栈满条件：`S.top == MaxSize - 1`

栈长：`S.top + 1`

#### 顺序栈的基本操作

##### 初始化

```c
void InitStack(SqStack &S){
	S.top = -1;
}
```

##### 栈判空

```c
bool StackEmpty(SqStack &S){
    // 为什么不 return S.top == -1;
	if(S.top == -1)
		return true;
	else
		return false;
}
```

##### 进栈

```c
bool Push(SqStack &S, ElemType x){
	if(S.top == MaxSize - 1)  // 栈满
		return false;
	S.data[++S.top] = x;  // 指针加 1 再入栈
	return true;
}
```

##### 出栈

```c
bool Pop(SqStack &S, ElemType &x){
	if(-1 == S.top)  // 栈空
		return false;
	x = S.data[S.top--];  // 先出栈，指针再减 1
	return true;
}
```

##### 读取栈顶元素

```c
bool GetTop(SqStack &S, ElemType &x){
	if(-1 == S.top)  // 栈空
		return false;
	x = S.data[S.top];  // 记录栈顶元素
	return true;
}
```

注意：若栈初始化为 `S.top = 0` 那么入栈就变成了 `S.data[S.top++] = x` 出栈就变成了 `x = S.data[--S.top]`

#### 共享栈

利用栈的位置相对不变的特性，可让**两个顺序栈共享一个一维数组空间**

将两个栈的栈底分别设置在**共享空间的两端**，两个栈顶**向共享空间的中间延伸**

![src=http___images2017.cnblogs.com_blog_858860_201708_858860-20170828180651437-1593004191.png&refer=http___images2017.cnblogs](..\images\src=http___images2017.cnblogs.com_blog_858860_201708_858860-20170828180651437-1593004191.png&refer=http___images2017.cnblogs.jpg)

该图片是 `top1` 初始为 0，`top2` 初始为 `MaxSize - 1` 的共享栈，与下面不同

`top1 == -1` 时 1 号栈为空，`top2 == MaxSize` 时 2 号栈为空；当**两个栈顶指针相邻**（`top2 - top1 = 1`）时，栈满

当 1 号栈进栈时先**加 1 再赋值**，2 号栈进栈时先**减 1 再赋值**；**出栈时相反**

共享栈是为了**更有效地利用存储空间**，两个栈地空间相互调节，只有在**整个存储空间被占满时才发生上溢**

原本一个栈用得多一个栈用的少，两个分配同样的内存，用的多的容易上溢，现在共享栈自己用完了会用另外一个栈的空间，没那么容易上溢

### 栈的链式存储结构

采用链式存储的栈称为链栈，链栈的优点是便于**多个栈共享空间**和**提高其效率**，且**不存在栈满上溢的情况**（这里的共享空间是指更方便多个栈共享内存空间）

链栈通常使用**单链表**来实现，并规定所有操作都是在**单链表的表头进行的**，通常链栈**没有头结点**

```c
typedef struct Linknode {
    ElemType data;  // 数据域
    struct Linknode *next;  // 指针域
} *LiStack;
```

链栈的操作和链表相似，只是入栈和出栈的操作都在链表的**表头进行**

## 队列

### 队列的基本概念

#### 队列的定义

队列也是一种**操作受限**的**线性表**，只允许在表的**一端进行插入**，而在表的**另一端进行删除**

向队列插入元素称为**入队或进队**；删除元素称为**出队或离队**，其操作的特性是**先进先出**

#### 队列常见的基本操作

```c
InitQueue(&Q);  // 初始化队列
QueueEmpty(Q);  // 判队列是否为空
EnQueue(&Q, x);  // 入队
DeQueue(&Q, &x);  // 出队
GetHead(Q, &x);  // 读取头元素
```

### 队列的顺序存储结构

#### 队列的顺序存储

队列的顺序是指**分配一块连续的存储单元**存放队列中的元素，并附有**队头指针**和**队尾指针**

```c
#define MaxSize 50
typedef int ElemType;
typedef struct {
	ElemType data[MaxSize];  // 存放队列元素
	int front, rear;  // 对头指针和队尾指针
} SqQueue;
```

初始条件：`Q.front = Q.rear = 0`，**声名是：front 指向队头元素，rear 指向队尾元素的后一位**

队空条件：`Q.front == Q.rear`

进队操作：队不满时，先送值到队尾元素，再将队尾指针加 1

出队操作：队不空时，先取队头元素，再将队头指针加 1

顺序队列缺点：没用重复利用使用过的空间，造成空间上的浪费

#### 循环队列

环形队列即把存储队列元素的表**从逻辑上视为一个环**，当队首指针 `Q.front = MaxSize - 1` 后，**再前进就变成 0**，这就利用到了之前顺序队列所没用利用的空间

初始时：`Q.front = Q.rear = 0`

队首指针进 1：`Q.front = (Q.front + 1) % MaxSize`

队尾指针进 1：`Q.rear = (Q.rear + 1) % MaxSize`

队列长度：`(Q.rear + MaxSize - Q.front) % MaxSize`

出队入队时：指针都按顺时针方向进 1

为了防止队空队满判断都是 `Q.front == Q.rear`，有三种方法：

1. **牺牲一个单元**来区分队空和堆满，以<u>队头指针在队尾指针的下一位置作为队满的标志</u>，这是一种**较为普遍的做法**，**队满条件**为 `(Q.rear + 1) % MaxSize == Q.front`
2. 类型中**增加表示元素个数的数据成员**，这时**队空条件**为 `Q.size == 0`；**队满条件**为 `Q.size == MaxSize`
3. 类型中**增加标志 tag 成员**。**队空条件**为 `Q.front == Q.rear && tag == 0`；**队满条件**为 `Q.front == Q.rear && tag == 1`

#### 循环队列的操作

##### 初始化

```c
void InitQueue(SqQueue &Q) {
	Q.rear = Q.front = 0;
}
```

##### 判队空

```c
bool isEmpty(SqQueue &Q) {
	if(Q.rear == Q.front)
		return true;
	else	
		return false;
} 
```

##### 入队

```c
bool EnQueue(SqQueue &Q, ElemType x) {
	if((Q.rear + 1) % MaxSize == Q.front)  // 队满
		return false;
	Q.data[Q.rear] = x;
	Q.rear = (Q.rear + 1) % MaxSize;  // 表尾向前进 1
	return true;
}
```

##### 出队

```c
bool DeQueue(SqQueue &Q, ElemType &x){
	if(Q.rear == Q.front)  // 队空
		return false;
	x = Q.data[Q.front];
	Q.front = (Q.front + 1) % MaxSize;  // 表头向前进 1
	return true;
}
```

### 队列的链式存储结构

#### 队列的链式存储

队列的**链式表示**称为链队列，实际上就是一个带**队头指针**和**队尾指针**的单链表

<u>头指针指队头结点，尾指针指队尾结点</u>，队列的链式存储结构为：

```c
typedef struct LinkNode {  // 链式队列结点
	ElemType data;
	struct LinkNode *next;
} LinkNode;

typedef struct {
	LinkNode *front, *rear;  // 队头和队尾指针
} LinkQueue;
```

当 `Q.front == NULL && Q.rear == NULL` 时，**链式队列为空**

出队时，若**队列不为空**，从**队头弹出一个元素**；入队时，直接**把新元素插入队尾**

由于不带头结点的链式队列在操作上往往比较麻烦，因此**通常会把链接队列设计成带头结点的单链表**

单链表表示的链式队列适合**数据元素变动比较大**的情形，且不存在队列满且产生**溢出问题**

当程序中要使用**多个队列**，与多个栈的情形一样，最好**使用链式队列**，这样就不会出现存储分配不合理和溢出

#### 链式队列的基本操作

##### 初始化

```c
void InitQueue(LinkQueue &Q){
    // 这里是带头结点单链表实现的链式队列
	Q.front = Q.rear = (LinkNode*)malloc(sizeof(LinkNode));
	Q.front -> next = NULL; 
}
```

##### 判队空

```c
bool IsEmpty(LinkQueue &Q){
	if(Q.front == Q.rear)
		return true;
	else
		return false;
}
```

##### 入队

```c
void EnQueue(LinkQueue &Q, ElemType x){
	LinkNode *s = (LinkNode *)malloc(sizeof(LinkNode));
	s -> data = x;
	s -> next = NULL;
	Q.rear -> next = s;  // 插入到队尾
	Q.rear = s;
}
```

##### 出队

```c
bool DeQueue(LinkQueue &Q, ElemType &x){
	if(Q.front == Q.rear) return false;
	LinkNode *p = Q.front -> next;  // 弹出一个头结点
	x = p -> data;
	Q.front -> next = p -> next;
	if (Q.rear == p)  // 弹出后队列为空，设置一下 Q.rear 位置
		Q.rear = Q.front;
	free(p);
	return true;
}
```

### 双端队列

双端队列是指允许**两端都可以进行入队和出队操作的队列**，其元素的**逻辑结构**仍是**线性结构**，将队列的两端分别称为**前端**和**后端**，两端都可以**入队**和**出队**

![u=3737484954,683032264&fm=26&fmt=auto&gp=0](..\images\u=3737484954,683032264&fm=26&fmt=auto&gp=0.webp)

在两端队列进队时，前端进的元素会在后端进的元素**前面**，后端进的元素会在前端进的元素**后面**；出队时**先出的元素排在后出的元素的前面**

例如：前端入 a 队中是 a，后端入 b 队中是 ab，前端入 c 队中是 cab；后端出队队中 ca 队外 b，后端再出队中 c 队外 `ba`，前端出队队外 `bac`

输出受限的双端队列：允许**在一端进行插入和删除**，但在**另一端只允许插入**的双端队列

输入受限的双端队列：允许**在一端进行插入和删除**，但在**另一端只允许删除**的双端队列

<img src="..\images\u=2992605034,2358148482&fm=26&fmt=auto&gp=0.webp" alt="u=2992605034,2358148482&fm=26&fmt=auto&gp=0" style="zoom:200%;" />

例子：如果有 1，2，3，4 四个数字，要令他输出 2，4，1，3 那么双向队列操作为：

1. 左入，内部 1，外部
2. 左入，内部 21，外部
3. 左出，内部 1，外部 2
4. 右入，内部 13，外部 2
5. 左入，内部 413，外部 2
6. 左出，内部 13，外部 24
7. 左出，内部 3，外部 241
8. 右出，内部，外部 2413

### 元素复用且空间可增的队列

请设计一个队列，要求满足（会做）：

1. 初始时队列为空
2. 入队时，允许增加队列占用空间
3. 出队后，出队元素所占用的空间可重复使用，即整个队列所占用的空间只增不减
4. 入队操作和出队操作的时间复杂度始终保持为 O(1)

---

设计出的队列：循环单链表，最好带头结点

因为队列是循环的，所以弹出元素不需要释放掉，等下次入队时重复利用，当队满时入队也可以分配结点链上去

队空条件：`front == rear`；队满条件：`front == rear -> next`

```c
// 入队
if (front == rear -> next)
    在 rear 后面插入一个新空结点;
入队元素保存到 rear 所在结点中;
rear = rear -> next;

// 出队
if (front == rear)
    则出队失败，return false;
取 front 所指结点中的元素 e;
front = front -> next;
return e;
```

## 栈和队列的应用

### 栈在括号匹配中的应用

假设表达式中允许包括两种括号：圆括号和方括号，其嵌套的顺序任意即 (\[\]\(\)) 或 [\([]\[]\)] 等均为正确格式，[(]) 或 ([()) 等均为不正确的格式，先需要设计一个算法来检验表达式是否是正确格式

分析如下：

检测所有括号是否匹配，就是检查每一个局部的括号是否匹配

只要我们匹配好每一个局部的括号，并把匹配好的括号去掉，继续向外匹配，那么就可以了

那么我们只需要用一个空间放左括号，然后拿它与右括号匹配，匹配上了就可以了

而左括号很明显是最后看见的最先匹配，所以要用到栈，后进先出

算法思想：

1. 初始化设置一个栈
2. 如果是左括号压入栈，如果是右括号就和栈顶的括号匹配，匹配成功出栈继续，失败退出

### 栈在表达式求值中的应用

中序表达式 `A + B * (C - D) - E / F` 所对应的后缀表达式为 `ABCD-*+EF/-`，后缀表达式**没有括号**，它已经考虑了运算符的优先级，后缀表达式的**运算符在操作数后面**

通过后缀表示计算表达式值得过程为：

扫描表达式得每一项，根据它的类型做如下操作

1. 若是操作数，那么压入栈
2. 若是操作符 \<op> 则连续从栈弹出两个操作数 Y 和 X，做运算 X \<op> Y，并将运算结果压入栈中
3. 当表达式扫描完时，栈顶存放的就是最终结果

#### 中缀转后缀的过程

| 操作符     | #    | (    | *, / | +, - | )    |
| ---------- | ---- | ---- | ---- | ---- | ---- |
| `isp` 栈内 | 0    | 1    | 5    | 3    | 6    |
| `icp` 栈外 | 0    | 6    | 4    | 2    | 1    |

其中 `isp` 是栈内优先数，`icp` 是栈外优先数，在表达式后面加上符号 '#' 表示表达式结束

扫描中缀表达式的没一项做以下操作：

1. 先把 '#' 入栈然后继续下面操作
2. 如果是操作数直接输出
3. 如果是操作符 op 分下面三种情况
   1. `isp(栈顶) < icp(op)` 把 op 进栈，下一个
   2. `isp(栈顶) == icp(op)` 把栈顶出栈，废弃 op，下一个
   3. `isp(栈顶) > icp(op)`，把栈顶出栈输出，重新判断 op
4. 读取到结束标识 '#' 结束

简单来说，操作数直接输出，对于操作符：

**高级压低级，低级弹高级，同级要弹出，左括号直压，都压左括号，左右括号对应**：+ = - < * = /

例子：`a / b + (c * d - e * f) / g`

1. 栈内：/，栈外：ab
2. 栈内：+，栈外：ab/ 低级弹高级
3. 栈内：+(，栈外：ab/ 左括号直压
4. 栈内：+(*，栈外：`ab/cd` 都压左括号
5. 栈内：+(-*，栈外：`ab/cd*ef` 高级压低级
6. 栈内：+，栈外：`ab/cd*ef*-` 左右括号对应
7. 栈内：，栈外：`ab/cd*ef*-g/+`

#### 手工转缀（括号法）

示例表达式 `a / b + (c * d - e * f) / g`

1. 按照运算符优先级队所有的运算单位加括号，`((a / b) + (((c * d) - (e * f)) / g))`
2. 如果把每个操作符提到自己的括号前面就是前缀表达式：`+(/(ab)/(-(*(cd)*(ef))g))`=`+/ab/-*cd*efg`
3. 如果把每个操作符提到自己的括号后面就是后缀表达式：`((ab)/(((cd)*(ef)*)-g)/)+`=`ab/cd*ef*-g/+`

### 栈在递归中的应用

若在一个函数、过程或数据结构的定义中又**应用了它自身**，则这个函数、过程或数据结构称为是**递归定义的**

递归策略只需要少量的代码就可以描述出解题过程所需要的多次重复运算，大大**减少了程序的代码量**，但通常情况下，递归的**效率不是很高**

注意递归模型不能是死循环，必须满足两个条件：

* 递归表达式（**递归体**）
* 边界条件（**递归出口**）

递归过程中，系统会使**用栈**来存储返回点、局部变量、传参等，递归次数过多会造成**栈溢出**

有序递归过程中可能会包含很多**重复的运算**，这是其效率不高的原因

将递归算法转换为非递归算法，**通常**（不是一定）需要**借助栈来实现**

注意：有些递归函数用栈来实现，不是实现其递归过程，仅仅只是用栈实现这一算法而已，如把栈当数组用

### 队列在层次遍历中的应用

在信息处理中有一大类问题需要**逐层**或**逐行处理**，需要等到**当前层或当前行处理完成**才会处理下一层或下一行

这时需要**使用队列保存下一步处理的顺序**，例如层次遍历二叉树过程：

1. 根结点入队
2. 队空即遍历完成，则结束遍历，否则进行第三步
3. 队列中第一个结点出队，若有左儿子，则左儿子入队；右儿子也一样，返回第二部

### 队列在计算机系统中的应用

队列在计算机系统中的应用非常广泛，下面仅从两个方面来简述队列在计算机系统中的作用：

* 解决主机与外部设备之间速度不匹配的问题（假脱机技术）

  主机输出数据的速度比打印机快很多，直接把数据全塞给打印机是不行的

  使用我们会在打印机设置一个**数据缓存区**，而这个缓存区是队列确保<u>输入和输出的数据位置一样</u>

  主机把数据写入这个缓冲区，写满就暂停做其他时，等打印机消化完数据再通知主机继续发送

* CPU 资源竞争问题（时间片轮询）

  在带多终端的计算机系统上，有多个用户需要 CPU 运行主机的程序，它们向操作系统提出占用 CPU 的请求

  操作系统按照每个请求的时间排成一个队列，然后弹出队列运行相应的时间后再塞回队列，直到程序运行完

  这样既能满足每个用户的请求，又使 CPU 能够正常运行

## 数组和特殊矩阵

### 数组的定义

数组是由 n 个**相同类型**的数据元素构成的有限序列，每个数据元素称为一个数组元素，元素在 n 个线性关系中的**序号**称为该元素的**下标**，下标的**取值范围**称为数组的**维界**

**数组是线性表的推广**，一维数组可视为一个线性表；二位数组是视为元素是定长线性表的线性表

数组一旦被定义，其维数和维界就**不再改变**，除结构的初始化和销毁外，数组只会有**存取元素和修改元素**的操作

### 数组的存储结构

一个数组在内存中占用一段**连续的空间**，以一维数组 A[0...n - 1] 为例，存储结构关系为 $LOC(a_i)=LOC(a_0)+i\times L(0\leq i<n)$，其中 L 是每个数组元素所占的存储单元

对于多维数组，有两种映射方法：**按行优先和按列优先**，以二维数组为例：

* 按行优先：先行后列，先存储**行号较小的元素**，再**存储列较小的元素**，设行标和列标范围为 $[0,h_1]$ 和 $[0,h_2]$

  则它的存储结构关系式为 $LOC(a_{i,j})=LOC(a_{0,0})+[i\times(h_2+1)+j]\times L$

  ![image-20210914192829080](..\images\image-20210914192829080.png)

* 按列优先：先列后行，先存储**列号较小的元素**，再**存储行较小的元素**，设行标和列标范围为 $[0,h_1]$ 和 $[0,h_2]$

  则它的存储结构关系式为 $LOC(a_{i,j})=LOC(a_{0,0})+[j\times(h_1+1)+i]\times L$

  ![image-20210914192918205](..\images\image-20210914192918205.png)

主要计算思想：**本元素前面有 i 个元素，那么本元素的偏移为 i × 元素大小**，这把二维数组看成一维了

### 矩阵的压缩存储

压缩存储：指**多个值相同的元素只分配一个存储空间**，**对零元素不分配存储空间**

特殊矩阵：指具有**许多相同矩阵元素或零元素**，并且这些矩阵元素分布有**一定的规律性**，通常有：对称矩阵、上（下）三角矩阵、对角矩阵等

特殊矩阵的压缩方法：找出特殊矩阵的分布规律，把那些规律性分布、值相同的**多个矩阵元素**压缩**存储到一个存储空间**

做题方法：

1. 查看**矩阵的类型**，数组下标的开始位置（b[0...n-1] 从 0 开始，b[1...n] 从 1 开始）
2. 查看是**按行优先还是按列优先**，查看题目给定的位置**分析位置**
3. 如果是抽象的 i, j 可以直接**代特定的数进去**，如果是特定的数**计算前面有多少个元素**（或套公式）

- 假设行和列都是从 1 开始，仅算第 j 列的话，对于上三角该元素前面有 **j - i 个元素**，对于下三角前面有 **j - 1 元素**

#### 对称矩阵

对称矩阵是指对于任意一个矩阵内元素 $a_{i,j}$ 都有 $a_{i,j}=a_{j,i}$，其中元素可以分成 3 个部分，上三角区、主对角线、下三角区

对于 n 阶对称矩阵，上三角的元素和下三角的元素相同，如果使用二维数据存储会浪费空间，所有应该采用一维数组存储，舍弃上三角的元素，**仅存储下三角的元素和主对角线元素**

![image-20210914195830707](..\images\image-20210914195830707.png)

一维数组的大小应该是除主对角元素个数的一半再加上主对角元素的个数 $\dfrac{n^2-n}2+n=n(n+1)/2$

在一维数组中，元素 $a_{i,j}(i\geq j)$ 前面元素的个数为：

1. 第 1 行：1 个元素
2. 第 i - 1 行：i - 1 个元素
3. 第 i 行：j - 1 个元素

所以元素 $a_{i,j}$ 在一维数组中的下标 $k = 1 + ... + (i - 1) + j - 1 = i(i - 1) / 2 + j - 1$（数组从 0 开始时）

注意：若数组从 0 开始，前面有多少个元素，数组下标就是几，如我前面有 2 个元素，我在数组中的下标为 2

而对称矩阵元素是对称的，对于 $a_{i,j}(i<j)$ 就是计算 $a_{j,i}$ 的位置

那么就得出**元素下标之间的对应关系**：$k=\left\{\begin{matrix}\dfrac{i(i-1)}{2}+j-1,&i\geq j（下三角区和主对角线元素）\\\dfrac{j(j-1)}{2}+i-1,&i<j（上三角区元素）\end{matrix}\right.$

注意：**如果数组下标从 1 开始的话，运算出来的结果要加 1**

注意：这里使用的是**行优先**来计算，如果是**列优先**的话可以**对称过来**当作行优先计算

#### 三角矩阵

<img src="..\images\image-20210914201508777.png" alt="image-20210914201508777" style="zoom:200%;" />

##### 下三角矩阵

下三角矩阵中，**上三角区域**的所有元素均为**同一常量**，使用**一个位置**来存储就好了，设置在**数组最后**

因此我们只需要存储下**三角元素**和**主对角元素**以及**额外常量**，大小为 $n(n+1)/2+1$

当 i < j 时，取上三角元素，就访问数组的最后一个元素 $n(n+1)/2$ 拿到常量就好了

当 $i\geq j$ 时，取下三角元素，这里的计算思路和对称矩阵的一样，结果是 $i(i-1)/2+j-1$

##### 上三角矩阵

上三角矩阵中，**下三角区域**的所有元素均为**同一常量**，也是使用数组最后的元素来存储，数组大小和上三角矩阵一样

与下三角不同这里第 1 行是有 n 个元素的，所以不能套用对称矩阵的公式

在一维数组中，元素 $a_{i,j}(i\leq j)$ 前面元素的个数为：

1. 第 1 行：n 个元素
2. 第 i - 1 行：n - i + 2 个元素
3. 第 i 行：j - i 个元素

所以元素 $a_{i,j}$ 在一维数组中的下标 $k=n+(n-1)+\cdots+(n-i+2)+j-i=(i-1)(2n-i+2)/2+(j-i)$

那么就得出**元素下标之间的对应关系**：$k=\left\{\begin{matrix}\dfrac{(i-1)(2n-i+2)}{2}+(j-i),&i\leq j（上三角区和主对角线元素）\\\dfrac{n(n+1)}{2},&i>j（下三角区元素）\end{matrix}\right.$

注意：**如果数组下标从 1 开始的话，运算出来的结果要加 1**

注意：这里使用的是**行优先**来计算。<u>上三角的列优先和下三角的行优先类似</u>；<u>下三角的列优先与上三角行优先类似</u>

#### 三对角矩阵

三对角矩阵也称带状矩阵，对于 n 阶矩阵的任意元素 $a_{i,j}$ 当 |i - j| > 1时，有 $a_{i,j}=0$

三对角矩阵的所有**非零元素**都集中在以主对角线为中心的 3 条对角线区域，**其余区域元素都为零**

![image-20210914202417969](..\images\image-20210914202417969.png)

对三角矩阵采用压缩存储，按行优先方式存储放在一维数组中，数组长度为 `3(n - 2) + 4 = 3n - 2`

元素在一维数组的下标计算为：第一行的个数 + 前面三个元素的行数 + 当前行前面的元素

即元素 $a_{i,j}$ 的下标 $k=2+3(i-2)+(j-i+1)=2i+j-3$

注意：**如果数组下标从 1 开始的话，运算出来的结果要加 1**

注意：这里使用的是**行优先**来计算。不过列优先和行优先差不多

### 稀疏矩阵

矩阵中非零的元素的个数对于矩阵元素的个数来说非常少，如 $100 \times 100$ 的矩阵只有不到 100 的非零元素

如果采用常规法来存储就很浪费空间了，所以将非零元素及其相应的行和列构成一个三元组（**行标、列标、值**）

![image-20210914203617205](..\images\image-20210914203617205.png)

稀疏矩阵的**三元组**既可以采用**数组存储**，也可以采用**十字链表法**存储

# 串

## 串的定义和实现*

### 串的定义

串是**由零个或多个字符组成的有限序列**，记为 $S='a_{1}a_2\cdots a_n'(n\geq0)$ 其中 S 是**串名**，单引号里面的字符序列是串的值，串中字符的个数 n 称为**串的长度**，n = 0 时的串称为**空串**（用 `Ø` 表示）

串中任意多个连续的字符组成的子序列称为该串的**子串**，包含子串的串称为**主串**

某个字符在**串中的序号**称为该字符在**串中的位置**，子串在主串中的位置以子串的**第一个字符在主串中的位置**来表示

当两个串的**长度相等**且**对应位置的字符都相等**时，称这两个串是**相等**的

串的逻辑结构和线性表极为相似，区别在于**串的数据对象限定为字符集**。基本操作上**线性表操作单个元素**，而**串操作子串**

### 串的存储结构

#### 定长顺序存储表示

使用一组**地址连续的存储单元**存储串值的字符序列，这里**使用定长数组来为字符串分配位置**

```c
#define MAXLEN 255
typedef struct {
	char ch[MAXLEN];  // 每个分量存储一个字符
    int length;  // 串的实际长度
} SString;
```

串的实际长度只能小于等于 `MAXLEN`，**超过预定义长度的串值会被舍去**，称为截断

长度由两种表示方法：

1. 使用一个额外的变量 `len` 来存储串的长度
2. 在串值后面加一个不计入串长的结束标记字符 "\0"

#### 堆分配存储表示

堆分配存储仍以一组**地址连续的存储单元**存储串值得字符序列，但这组存储单元是**动态分配**的

```c
typedef struct {
    char *ch;  // 指向串的基地址
    int length;  // 串的长度
} HString;
```

在 C 语言中，使用 `malloc()` 和 `free()` 函数来实现存储单元的动态管理

#### 块链存储表示

块链存储类似于**线性表的链式存储结构**，只不过现在**存储的是串值**

在具体实现时，每个结点既可以存放一个字符，也可以存放多个字符

每个结点称为**块**，整个链表称为**块链结构**

下面是结点大小为 4 的链表和结点大小为 1 的链表，为 4 的链表最后一个结点不满时通常用 "#" 补上

![image-20210915190230399](..\images\image-20210915190230399.png)

### 串的基本操作

```c
StrAssign(&T, chars);  // 赋值操作
StrCopy(&T, S);  // 复制操作，S 复制到 T
StrEmpty(S);  // 判空操作
StrCompare(S, T);  // 比较操作，S > T 返回 > 0；S = T 返回 0；S < T 返回 < 0
StrLength(S);  // 求串长
SubString(&Sub, S, pos, len);  // 求子串
Concat(&T, S1, S2);  // 串连接
Index(S, T);  // 定位操作
ClearString(&S);  // 清空操作
DestroyString(&S);  // 销毁串
```

上诉操作中，**串赋值、串比较、求串长、串连接、求子串**五种操作构成串类型的**最小操作子集**，即这些操作**不可能利用其他串操作**来实现

其他串操作除串清空和串销毁外，均可在该最小操作子集上实现

## 串的模式匹配

### 简单的模式匹配算法

子串的定位操作通常称为串的模式匹配，它求的是子串（常称模式串）在主串上的位置

这里给出顺序存储结构的暴力匹配方法：

```c
int Index(SString S, SString T){
    int i = 1, j = 1;
    while(i <= S.length && j <= T.length) {
        if (S.ch[i] == T.ch[j]) {  // 相等比配后面的字符
            ++i;
            ++j;
        } else {  // 主串移动到匹配开始的后一个，模式串回到第一位
            i = i - j + 2;
            j = 1;
        }
    }
    if (j > T.length) return i - T.length;  // 匹配成功
    else return 0;
}
```

该方式是逐位比较，如果比较不通过那么主串就从比较起点的下一个重新于模式串比较

简单模式匹配算法的最坏时间复杂度为 `O(mn)`，其中 n 和 m 分别是主串和模式串的长度

### 改进匹配算法：KMP 算法

如果以匹配相等的前缀序列中有**某个后缀正好是模式的前缀**，那么就可以将模式向**后滑动到于这些相等字符对齐的位置**，主串 i 指针**无须回溯**，并从该位置继续比较，如：

1234123412341235 -> 1234123412341235

12341235                 ->         12341235

在 5 那里匹配失败，无需回溯主串，只需把模式串右滑 4 位就好了

#### 字符串的前缀、后缀和部分匹配

**前缀**：指除最后一个字符以外，字符串的所有头部子串

**后缀**：指除了第一个字符外，字符串的所有尾部子串

**部分匹配值**：指字符串的前缀和后缀的最长相等前后缀长度

下面以 `'abab'` 为例：

1. `'a'` 没有前后缀，最长相等前后缀为 0
2. `'ab'` 前缀为 {a}，后缀为 {b}，它们交集为空集，最长相等前后缀为 0
3. `'aba'`  前缀为 `{a,ab}`，后缀为 `{ba,a}`，交集为 {a}，最长相等前后缀为 1
4. `'abab'` 前缀为 `{a,ab,aba}`，后缀为 `{bab,ab,b}`，交集为 {ab}，最长相等前后缀为 2

所以字符串 `'abab'` 的部分匹配值为 0012，将它写成数组形式，就得到**部分匹配表**（Partial Match, PM）

而**子串需要向后移动的位数：移动位数 = 已匹配的字符数 - 对应的部分匹配值**

#### KMP 算法的原理是什么

为什么会有 "移动位数 = 已匹配的字符数 - 对应的部分匹配值" 这个公式呢？下面是我的解释

- 因为部分匹配值是最大相等前后缀，我们需要将模式串**移动到前缀匹配的位置**，所以需要少移动最大部分匹配值的长度，也就是把它减掉

对算法进行改进：

对于：移动位数 = 已匹配的字符数 - 对应的部分匹配值

写成：Move = (j - 1) - PM[j - 1]，其中 j 是匹配失败的位置，已匹配的字符数是 j - 1

如果我们将 PM 表右移一位，就变成 Move = (j - 1) - next[j]，而 `'abab'` 的表就从 0012 变成 -1001，可以注意到：

1. 第一个元素使用 -1 填充，因为第一个元素匹配失败会向右移动一位
2. 最后一个元素被消去了，因为<u>最后一个元素没有下一个元素，所以它的部分匹配值就没人使用</u>

而 j - Move 就是移动后的模式串开始比较位置：j - Move = j - ((j - 1) - next[j]) = next[j] + 1

为了更加整洁会直接将 PM 整体加 1，所以 `'abab'` PM 就会写成 0112，就得到公式 j = next[j]，注意下标从 1 开始

- 1 表示没有相同前后缀，匹配失效时，回到第一位来比；0 表示第一个失效，就向右移一位

next[j] 的含义是：<u>在子串的第 j 个字符与主串发生失配时，则跳到子串的 next[j] 位置重新与主串当前位置进行比较</u>

next[j] 也就是 [1...j-1] 最大相等前后缀的长度 + 1（原本 next[j - 1] 表示 [1...j - 1] 但后来右移了一位）

#### next 数组的计算

next[j] 是 [1...j-1] 最大相等前后缀的长度 + 1

而某个位置最大相等前后缀可以写成 $max\{k|1<k<j 且 'p_1\cdots p_{k-1}'='p_{j-k+1}\cdots p_{j-1}'\}$

给定 next[1] = 0，以及最大前后缀为空时要写成 next[j] = 1

就有 $next[j]=\left\{ \begin{matrix} 0,&j=1\\max\{k|1<k<j 且 'p_1\cdots p_{k-1}'='p_{j-k+1}\cdots p_{j-1}'\},&当集合不空时\\1,&其他情况 \end{matrix} \right.$

现在就是 $max\{k|1<k<j 且 'p_1\cdots p_{k-1}'='p_{j-k+1}\cdots p_{j-1}'\}$ 的求法：

使用数学归纳法，假设 next[j] = k 满足上面的条件（$'p_1\cdots p_{k-1}'='p_{j-k+1}\cdots p_{j-1}'$），那么对于 next[j + 1] = ? 有两种可能：

1. 若 $p_k=p_j$ 表明 $'p_1\cdots p_{k}'='p_{j-k+1}\cdots p_{j}'$，由于 next[j] = k 是最大前后缀，所以这里也是最大前后缀

   所以 next[j + 1] = k + 1 即 next[j + 1] = next[j] + 1

2. 若 $p_k\not=p_j$，表示 $'p_1\cdots p_{k}'\not='p_{j-k}\cdots p_{j-1}'$ 则需要寻找第二大前后缀

   设 q 是第二大前后缀，则它需要满足 $max\{k|1<q<k 且 'p_1\cdots p_{q-1}'='p_{k-q+1}\cdots p_{j-1}'\}$

   next[k] 是 $'p_1\cdots p_{k-1}'$ 里面的最大后缀，又因为 $'p_1\cdots p_{k-1}'='p_{j-k+1}\cdots p_{j-1}'$ 若 q = next[k] 就有 $'p_1\cdots p_{q-1}'='p_{j-q+1}\cdots p_{j-1}'$

   根据上面的推理，第二大前后缀就是 q = next[k]，那么就比较 $p_q$ 和 $p_j$ 如果等于就 next[j] = q + 1，不等就找第三大前后缀

   q = next[k]，而第三大就是 next[next[k]] 套娃下去直到找到，或者最大前后缀是空集就置 1
   
   如：`'abcabdabcab`**c**`abd'` 在这个粗体 c 这里它是先和 6 对比的然后再与 3 对比，next[12 + 1] = next[3] + 1 = 4

#### 代码实现

```c
void getNext(String T, int next[]) {  // 求 next 值
    int i = 1, j = 0;  // 这里的 j 其实就是 next[k]
    next[1] = 0;  // 从 1 开始
    while (i < T.length) {
        if (j == 0 || T.ch[i] == T.ch[j]) {
            ++i; ++j;
            next[i] = j;  // 若 pi = pj，则 next[j + 1] = next[j] + 1
        }
        else j = next[j];  // 否则令 j = next[j]，也就是 next[next[k]]
    }
}

int IndexKNP(String S, String T, int next[]) {
    int i = 1, j = 1;
    while (i <= S.length && j <= T.length) {
        if (j == 0 || S.ch[i] == T.ch[j]) {
            ++i; ++j;  // 继续比较后继字符
        }
        else
            j = next[j];  // 模式串向右移动
    }
    if (j > T.length)
        return i - T.length;  // 匹配成功
    else
        return 0;
}
```

尽管普通模式匹配的时间复杂度是 **`O(mn)`**，KMP 算法的时间复杂度是 **`O(m + n)`**，但<u>一般情况下普通模式匹配的实际执行时间近似为 `O(m+n)`</u>，因此至今仍被采用

KMP 算法仅在主串与子串**有很多部分匹配**时才显得比普通算法快得多，其**主要优点是主串不回溯**

### KMP 算法的进一步优化

前面定义的 next 数组在某些情况下尚有缺陷，可以进一步优化，如模式 `'aaaab'` 在和主串 `'aaabaaaab'` 进行匹配，过程不谈

问题在于如果当前失匹的字符与回溯后的字符相等，即 $p_j=p_{next[j]}$ 根据 $p_j\not= s_j$ 必然有 $p_{next[j]}\not= s_j$ 还要继续回溯，为了防止多余的回溯，所以在设置 next 时先判断 $p_j$ 与 $p_{next[j]}$ 是否相等

即当出现 $p_j=p_{next[j]}$ 时，要令它等于最初的 $p_j$ 值所对应的部分再匹配，**代码是 `next[j]` 等于 `next[next[j]]` 的递归形式**

```c
void getNextval(String T, int nextval[]) {
    int i = 1, j = 0;
    nextval[1] = 0;
    while (i < T.length) {
        if (j == 0 || T.ch[i] == T.ch[j]) {
            ++i; ++j;
            // 就改动了这里，令 pj=pnextj 时 next[j] = next[next[j]]
            if (T.ch[i] != T.ch[j]) nextval[i] = j;
            else nextval[i] = nextval[j];
        }
        else
            j = nextval[j];
    }
}
```

**注意：优化后的 KMP 数组改名为 `nextval`，如果数组名叫 next 是未优化的 KMP**

### 手算 KMP 的 `nextval` 数组

注意：在实际 KMP 算法中，<u>如果串位序从 1 开始则 next 元素加 1 开头为 01，从 0 开始不需要加 1 开头为 -10</u>

---

需要先计算 next 数组（按照"next 数组的计算"的思路来手算就好了）

求 next[j] **就把 j 遮住，找 1...j-1 的最大前后缀**

如 `'ababc'`，next[1]=0 求 next[2] 时把 2 及后面的遮住剩下 'a' 没有相同前后缀，next[2] = 1

求 next[3] 把 3 及后面的遮住剩下 `'ab'` 也没有共同前后缀，next[3] = 1

同样的 next[4] 是 `'aba'` 共同前后缀是 'a' 长度是 1 故 next[4] = 2

next[5] 是 `'abab'`，`'ab'` next[5] = 3

---

置 `nextval[1] = 0;i = 2`

遍历字符串，比较 **S[i] 和 S[next[i]]**

相等 `nextval[i]=nextval[next[i]]`

不相等 `nextval[i]=next[i]`

![image-20210915231724259](..\images\image-20210915231724259.png)

# 树与二叉树

## 树的基本概念

### 树的定义

树是 n（$n\geq0$）个结点的有限集。当 n = 0 时，称为空树，在任意一棵非空树中应满足：

1. 有且仅有**一个特定的称为根的结点**
2. 当 n > 1 时，其余结点可分为 m（m > 0）个互不相交的有限集 $T_1,\cdots,T_m$，其中**每个集合本身又是一棵树**，并称为**根的子树**

树的定义是**递归**的，在**树的定义中又用到了其自身**，树作为一种**逻辑结构**，同时也是一种**分层结构**，有以下特定：

1. 树的**根结点没有前驱**，**除根结点外**的所有结点有且**只有一个前驱**
2. 树中所有结点可以有**零个或多个后继**

**树适合表示具有层次结构的数据**，树中**除根结点外**的某个结点最多只和**上一层**的一个结点有**直接关系**

**根结点没有直接上层结点**，因此<u>在 n 个结点的树中有 n - 1 条边</u>，而树中每个结点与其**下一层**的零个或多个结点有**直接关系**

### 基本术语

![image-20210916160654157](..\images\image-20210916160654157.png)

1. 根 A 到结点 K 的唯一路径上的任意结点，称为结点 K 的**祖先**；相对 K 就是它们的**子孙**，如 B 是 K 的祖先，K 是 B 的子孙
2. 祖先中最接近 K 的结点 E 称为 K 的**双亲**，而 K 称为 E 的**孩子**，根结点是唯一没有双亲的结点
3. 有相同双亲的结点称为**兄弟**，如结点 K 和结点 L 有相同的双亲，即 K 和 L 为兄弟
4. 树中**一个结点的孩子个数**称为该**结点的度**，**树中结点的最大度数**称为**树的度**，如 B 的度 2，树的度 3
5. 度大于 0 的结点称为**分支结点**或**非终端结点**；度为 0 的结点称为**叶子结点**或**终端结点**，每个结点的分支数就是该结点的度
6. 结点的**层次**从树根开始定义，**根结点为第 1 层**，它的子结点为 2 层，它的子结点的子结点在 3 层，以此类推
7. 结点的**深度**是从**根结点开始**自顶向下逐层累加的；结点的**高度**是从**叶结点开始**自低向上逐层累加的
8. 双亲在**同一层的结点**，也就是在同一层的结点，**互为堂兄弟**，如 G 与 E、F、H、I、J 互为堂兄弟
9. **树的高度或深度**是树中结点**最大的层数**，如图中树的高度或深度为 4
10. **有序树**是指树中结点的各子树**从左到右是有次序的**，**不能互换**，若可互换就称为**无序树**
11. 树中两个结点之间的**路径**是由这两个结点之间所经过的**结点序列**构成的，而**路径长度**是路径上经过的**边的个数**
12. **树的路径长度**是从树根到每个结点的路径长度的**总和**，相同结点个数下，**完全二叉树**就是这种**路径长度最短的二叉树**
13. **森林**是 m（$m\geq0$）棵**互不相交**的**树的集合**，把树的根结点删去就成了森林，给森林加个根结点就成了树

注意：树的分支是有向的，即从双亲指向孩子，所以**树中路径是从上向下**的，**同一双亲的两个孩子之间不存在路径**

### 树的性质

1. **树中的结点数等于所有结点的度数之和加 1**，因为结点的度数和等于边数和，而结点数等于边数加 1

2. 度为 m 的树中第 i 层上至多有 $m^{i-1}$ 个结点（$i\geq 1$）

3. 高度为 h 的 m 叉树**至多有 $(m^h-1)/(m-1)$ 个结点**，根据 $1+m+m^2+\cdots+m^{h-1}=(m^h-1)/(m-1)$

4. 具有 n 个结点的 m 叉树的**最小高度**为 $\lceil\log_m(n(m-1)+1)\rceil$

   $1+m+\cdots+m^{h-2}<n\leq1+m+\cdots+m^{h-1}$

   $(m^{h-1}-1)/(m-1)<n\leq (m^h-1)/(m-1)$

   $m^{h-1}<n(m-1)+1\leq m^h$

   拆开分别求解就有：$h<\log_m[n(m-1)+1]+1$，$h\geq \log_m[n(m-1)+1]$

   由于 h 只能是正整数，故 $h=\lceil\log_m(n(m-1)+1)\rceil$

5. 具有 n 个结点，度为 m 的树，它的高度至多是 n - m + 1

6. 度为 n 高度为 h 的树，至少有 h + n - 1 个结点

三大公式：**设 $n_i$ 为 度为 i 的结点数：**

1. 总结点数 = $n_0+\cdots+n_m$
2. 总分支（边）数 = $1n_1+\cdots+mn_m$
3. 总结点数 = 总分支数 + 1

## 二叉树的概念

### 二叉树的定义及其主要特征

#### 二叉树的定义

二叉树是另一种树形结构，其特点是**每个结点至多只有两棵子树**，并且二叉树的**子树有左右之分**，其次序不能任意颠倒

二叉树也**以递归的形式定义**，二叉树是 n（$n\geq 0$）点的有限集合：

1. 当 n = 0 时，为**空二叉树**
2. 当 n > 0 时，由一个**根结点**和两个互不相交的**左子树和右子树**组成，左子树和右子树分别是一棵二叉树

二叉树有 **5 种基本形态**：空二叉树、只有根结点、只有左子树、左右子树都有、只有右子树

二叉树与度为 2 的有序树的区别：

1. 度为 2 的树至少有 3 个结点，而**二叉树可以为空**
2. 若度为 2 的树某个**结点只有一个孩子**，则这个**孩子无需区分左右次序**，而**二叉树必须区分**

#### 几个特殊的二叉树

##### 满二叉树

**一棵高度为 h，且含有 $2^h-1$ 个结点的二叉树称为满二叉树**

即树中<u>每层都含有最多的结点</u>，且<u>叶子结点都集中在最下一层</u>，并且<u>除叶子结点外每个结点的度均为 2</u>

对满二叉树按层序编号：从根结点 1 起，自上而下，自左向右，这样每个结点都对应一个编号

对于编号为 i 的结点，若有双亲则为 $\lfloor i/2\rfloor$；若有左孩子则为 `2i`；若有有孩子则为 `2i + 1`

![image-20210916202647863](..\images\image-20210916202647863.png)

##### 完全二叉树

高度为 h 有 n 个结点的二叉树，当且仅当**其每个结点都与高度为 h 的满二叉树种编号为 1 ~ n 的结点一一对应**时，称为**完全二叉树**

![image-20210916202710346](..\images\image-20210916202710346.png)

高度为 h、有 n 个结点的完全二叉树具有以下特点：

1. 若 $i\leq\lfloor n/2\rfloor$，则结点 i 为**分支结点**，否则为**叶子结点**
2. **叶子结点**只可能在**层次最大的两层**上出现，对于**最大层次中的叶子结点**，都一次排序在**该层最左边位置**上
3. 若有**度为 1 的结点**，则**只可能有一个**，且该结点**只有左孩子**而无右孩子
4. 按层序编号后，一旦出现某结点为**叶子结点或只有左孩子**，则**编号大于它**的结点**均为叶子结点**
5. 若 n 为奇数，则每个分支结点都有左孩子和右孩子；若 **n 为偶数**，**最大的分支结点只有左孩子**，其余的左右都有

##### 二叉排序树

1. <u>左子树上所有子结点的关键字均小于根结点的关键字</u>
2. <u>右子树上的所有结点的关键字均大于根结点的关键字</u>
3. <u>左子树和右子树右各是一棵二叉排序树</u>

##### 平衡二叉树

平衡二叉树是一棵二叉排序树

树上任意结点的**左子树和右子树的深度差不超过 1**

#### 二叉树的性质

1. **非空二叉树上的叶子结点等于度为 2 的结点数加 1，即 $n_0=n_2+1$**

   结点总数：$n=n_0+n_1+n_2$，分支数：$B=n_1+2n_2$ 又 $n=B+1=n_1+2n_2+1$

   合并就解出方程 $n_0+n_1+n_2=n_1+2n_2+1\Longrightarrow n_0=n_2+1$

2. 非空二叉树上第 k 层上至多有 $2^{k-1}$ 个结点（$k\geq1$）

3. 高度为 h 的二叉树至多有 $2^h-1$ 个结点（$h\geq1$）

4. 对完全二叉树按从上到下、从左到右的顺序依次编号 1,2,...,n 则有以下关系：

   1. 当 i > 1 时，结点 i 的双亲编号为 $\lfloor i/2\rfloor$；当 i 为偶数时，是左孩子；为奇数时，是右孩子
   2. 当 $2i\leq n$ 时，结点 i 的左孩子编号为 `2i`，否则无左孩子
   3. 当 $2i+1\leq n$ 时，结点 i 的右孩子编号为 `2i + 1`，否则无右孩子
   4. **结点 i 所在层次或深度为 $\lfloor\log_2i\rfloor+1$** 或 $\lceil\log_2(i+1)\rceil$

5. **具有 n 个（n > 0）结点的完全二叉树的高度为 $\lceil\log_2(n+1)\rceil$ 或 $\lfloor\log_2n\rfloor+1$**

   根据 $1+2+\cdots+2^{h-2}<n\leq1+2+\cdots+2^{h-1}$ 推出 $h=\lceil\log_2(n+1)\rceil$
   
   根据 $1+2+\cdots+2^{h-2}+1\leq n< 1+2+\cdots+2^{h-1}+1$ 推出 $h=\lfloor\log_2n\rfloor+1$
   
   具体的推导方法与 [树的性质](#树的性质) 类似

### 二叉树的存储结构

#### 顺序存储结构

二叉树的顺序存储是指**用一组的地址连续的存储单元**依次自上而下、自左至右**存储完全二叉树上的结点元素**

将完全二叉树上**编号为 i 的结点**元素存储在一维数组**下标为 i - 1 的分量**中

根据二叉树的性质，**完全二叉树和满二叉树采用顺序存储比较合适**，它们可以**最大可能地节省存储空间**，又方便从数组中**查找结点**，以及**结点之间的关系**

对于**一般的二叉树**，为了让数组反应结点之间的关系，只能**添加空结点**，让它在数组中看似完全二叉树

但这样的话会出现浪费空间的情况，最坏情况下一个高度为 h 且只有 h 结点的单支树需要 $2^h-1$ 个存储单元

![image-20210916221701804](..\images\image-20210916221701804.png)

注意：**数组是从 0 开始**的，所以**不能直接使用性质 4**，需要一些变通

#### 链式存储结构

为了解决顺序存储的空间浪费问题，所以二叉树一般都采用**链式存储结构**，**用链表结点来存储二叉树中的每个结点**

二叉链表**至少**包含 3 个域：**数据域、左指针域、右指针域**

在实际的不同应用中，还可以增加某些指针域，如增加指向父结点的指针

二叉树的链式存储结构描述如下：

```c
typedef struct BiTNode {
    ElemType data;  // 数据域
    struct BiTNode *lchild, *rchild;  // 左右孩子指针
} BiTNode, *BiTree;
```

使用不同存储结构时，实现二叉树操作的算法也会不同，依次要根据实际应用场合来选择合适的存储结构

在含有 **n 个结点的二叉链表中**，含有 **n + 1 个空链域**；根节点有 2 个，之后每插入一个结点多一个

![image-20210916225214560](..\images\image-20210916225214560.png)

### 精选试题

1. 设二叉树有 `2n` 个结点，且 0 < m < n，则不可能存在 `2m` 个度为 1  的结点

   因为 $2n=n_0+n_1+n_2=n_1+2n_2+1$ 由于 `2n` 是偶数，$2n_2$ 是偶数 ，所以 $n_1$ 必定是奇数

2. 若一个完全二叉树的第 h 层有 k 个叶结点，则该完全二叉树的结点个数最多为 $2^{h}-1+(2^{h-1}-k)*2$

   当 h 和 h + 1 层有叶结点时结点数最大，逻辑是计算 1 ~ h 层的结点加上 h + 1 层的结点

   1 ~ h 层结点个数是 $2^h-1$ 而 h + 1 层结点个数是 $(2^{h-1}-k)*2$

3. 若一棵深度为 h 的完全二叉树的第 h 层有 k 个叶子结点，则该二叉树共有 $k+2^{h-2}-\lceil k/2\rceil$ 个叶子结点

   思路是第 h 层的叶子结点加上 h - 1 层的叶子结点

4. **若一棵完全二叉树有 i 个结点，则该二叉树中叶子结点的个数是 $i - \lfloor i / 2\rfloor$**

   思路是利用完全二叉树的特性，最后一个分支的序号是 $\lfloor i / 2\rfloor$

5. **一棵有 n 个叶子结点的完全二叉树，最多有 $h=\lceil \log_2n\rceil;2^h-(2^{h-1}-n)\cdot2$ 个结点**

   最底层少两个叶结点，整棵树就会少一个叶结点，用 1 ~ h 的结点数减去最低层少了的结点数
   
   但给一个叶子节点加一个左结点，树的叶子结点一样多，但完全二叉树只能加一次，所以可以加 1
   
   1 ~ h 的结点为 $2^h-1$ 缺失的结点数为 $(2^{h-1}-n)\cdot2$，相减加 1 得到 $2^h-(2^{h-1}-n)\cdot2$

**做题思路：**

* 可以利用 $n=n_0+n_1+n_2$，$n_0=n_2+1$，$n=n_1+2n_2+1$ 这三条公式
* 可以利用完全二叉树的性质，如高为 h，它的 h - 1 层的结点有 $2^{h-2}$，1 ~ h - 1 的结点有 $2^{h-1}-1$
* 可以直接在脑袋里面画出二叉树，用空间思维硬刚

## 二叉树的遍历和线索二叉树

### 二叉树的遍历

二叉树的遍历是指按某条搜索路径**访问树中每个结点**，，使得**每个结点均被访问一次**，而且**仅被访问一次**

按照**先遍历左子树再遍历右子树**的原则，常见的遍历次序有：**先序遍历、中序遍历、后续遍历**，其中序是指根结点何时访问

#### 先序遍历

先序遍历（`PreOrder`）的操作过程如下：

若二叉树为空，则什么都不做；否则（`NLR`）：

1. 访问根结点
2. 先序遍历左子树
3. 先序遍历右子树

对于的递归算法代码如下：

```c
void PreOrder(BiTree T){
    if(T == NULL) return ;
    visit(T);  // 访问根结点
    PreOrder(T -> lchild);  // 递归遍历左子树
    PreOrder(T -> rchild);  // 递归遍历右子树
}
```

#### 中序遍历

中序遍历（`InOrder`）操作和先序遍历差不多，只是把访问根结点调整到第二步，先左再自己再右（`LNR`）

```c
void InOrder(BiTree T){
    if(T == NULL) return ;
    InOrder(T -> lchild);
    visit(T);
    InOrder(T -> rchild);
}
```

#### 后序遍历

后序遍历（`PostOrder`）操作和先序遍历差不多，只是把访问根结点调整到第三步，先左右再自己（`LRN`）

```c
void PostOrder(BiTree T){
    if(T == NULL) return ;
    PostOrder(T -> lchild);
    PostOrder(T -> rchild);
    visit(T);
}
```

每个结点都访问一次且访问一次，故**时间复杂度是 O(n)**

递归遍历中，最坏情况下有 n 个结点的二叉树是深度为 n 的单支树，**空间复杂度为 O(n)**

当栈出一个结点 p 后，**栈内的元素是 p 的全部祖先**，从**栈低到栈顶加上 p 是根结点到 p 的路径**

很多算法设计中都可以利用这一思路求解，如**求根到某结点的路径**、**求两结点的最近公共祖先**等

------

**注意：考研很多题是基于这三个遍历模板延申出来的，要对它有很好的领会**

#### 递归算法和非递归算法的转换

##### 栈实现中序遍历

**使用栈实现中序遍历**，考虑到**中序遍历就是左中右遍历**（对每个结点都进行左中右），就可以得到下面思路：

1. 拿到该结点最左子树，因为中序遍历第一步是做左操作，左又做左操作，所以就拿最左结点
2. 因为是最左子树根据左中右原则，左没有了，自己就是中，先访问自己，然后把右子树做 1 操作
3. 到了这里左右子树都没有了，考虑到父结点是做左操作到自己的，这时应该轮到父结点做中操作了，访问父结点，然后父结点做右操作，对父结点的右子树做 1 操作

根据思路可以得到操作：

1. 如果当前结点不为空，把当前结点和一路左边结点压入栈；相当于第一步，使用栈是为了可以拿到父结点
2. 弹栈访问，并对结点的右子树执行操作 1；这里就相当于把上面思路的 2，3 步合在一起

原理讲完了下面是实现代码：

```c
void InOrder(BiTree T) {
    LiStack S;
    InitStack(S);
    BiTree p = T;
    while(p || !StackEmpty(S)) {
        if(p) {  // 第 1 步把左一路的压入栈
            Push(S, p);
            p = p -> lchild;
        }else {
            Pop(S, p);
            visit(p);  // 第 2 步访问自己，然后对右子树执行 1
            p = p -> rchild;
        }
    }
}
```

##### 栈实现前序遍历

使用栈实现前序遍历的思考和中序遍历差不多，区别在于**前序遍历的逻辑是中左右**

前序遍历的结点使用顺序和前序一样，就是访问的位置不一样，只需要调整一下就可以了

```c
void PreOrder(BiTree T){
    LiStack S;
    InitStack(S);
    BiTree p = T;
    while(p || !StackEmpty(S)){
        if(p){
            visit(p);  // 把访问调整为前序遍历的先访问
            Push(S, p);
            p = p -> lchild;
        }else{
            Pop(S, p);
            p = p -> rchild;
        }
    }
}
```

##### 栈实现后序遍历

使用栈实现后序遍历思考也差不多，**后序遍历的核心逻辑是左右中**，但操作变得不一样了：

1. 首先和中序一样，先拿到最左的结点
2. 然后直接对右子树做操作 1，因为左右中，现在进行右操作
3. 到了这里左右操作都做完了，现在就可以做中操作，对结点进行访问了

但在代码里面，<u>无法知道右操作是否有做，所以要做个判断</u>，判断不过就要乖乖做右操作：

* 如果没有右子树，就相当于光速做了右操作，就可以中操作了
* 如果上一个做中的结点是右子树结点，那么就是以前做了右操作，可以做中操作

```c
void PostOrder(BiTree T) {
    LiStack S;
    InitStack(S);
    BiTree p = T;
    BiTNode *r = NULL;
    while(p || !StackEmpty(S)) {
        if(p) {  // 做第一步操作，左边直入栈
            Push(S, p);
            p = p -> lchild;
        }else{
            GetTop(S, p);  // p 是 r 的父结点
            // 有两种情况，一个是左边上来的，一个是右边上来的
            // 左边上来就遍历右儿子，右边上来就出栈，向上遍历
            
            if(p -> rchild && p -> rchild != r){  // 从左边上来，还不能访问
                p = p -> rchild;
            }else {  // 从右边上来
                Pop(S, p);  // 出栈表示上去
                visit(p);
                r = p;  // 记录前驱，方便查看是哪里上来的
                p = NULL;  // 重置 p 指针省的第一步操作了
            }
        }
    }
}
```

#### 层次遍历

层次遍历是**指按树的层从左到右访问结点**，进行层次遍历要借助一个队列：

1. 初始化把根结点入队
2. 队列不空，从队列取出一个元素，并访问它
3. 有左子树把左子树入队
4. 有右子树把右子树入队，回第二步

```c
void LevelOrder(BiTree T) {
    LinkQueue Q;
    InitQueue(Q);
    BiTree p;
    EnQueue(Q, T);  // 第一步，根结点入队
    while(!QueueEmpty(Q)) {
        DeQueue(Q, p);  // 第二步，出列并访问
        visit(p);
        if(p -> lchild != NULL) {  // 第三步
            EnQueue(Q, p -> lchild);
        }
        if(p -> rchild != NULL) {  // 第四步
            EnQueue(Q, p -> rchild);
        }
    }
}
```

**注意：这些代码作为一个模板需要达到<u>熟练手写的程度</u>，这样才能将层次遍历模板应用于各种题目之中**

#### 由遍历序列构造二叉树

由二叉树的**先序序列**和**中序序列**可以**唯一地确定一棵二叉树**：

1. **先序序列的第一个是二叉树的根结点**；拿它去中序序列可以把中序序列分成两半，变成左子树的中序和右子树的中序
2. 然后在先序序列中找到对应的左子序列和右子序列
3. 在先序序列中，左子序列的第一位就是左子树的根部；右子序列的第一位就是右子序列的根部
4. 依次递归下去，就能找到唯一的二叉树了

例子：求先序序列（`ABCDEFGHI`）和中序序列（`BCAEDGHFI`）所确定的二叉树

![image-20210917202041035](..\images\image-20210917202041035.png)

同理，也可以求**后序序列和中序序列**的二叉树，**后序序列的最后一个结点就是根结点**

同理，也可以求**层序序列和中序序列**的二叉树，第一个为根结点，若中序左右子树都有，第二个是左子树根结点，以此类推

注意：只知道二叉树的**先序序列和后序序列**，是**无法确定唯一的二叉树**的

##### 选择题得到的理论

1. 如果**前序序列是后序序列的反转**设长度为 n，那么一共**可以构成 $2^{n-1}$ 棵二叉树**，因为它们**只会有一个叶结点**

2. 当两个结点的**前序序列为 `XY`**、**后序序列为 `YX`** 时，则 **X 为 Y 的祖先**，`XZY` 这时不能确定 X 和 Y 的关系

3. 先序序列为 1...n 的**不同二叉树的个数**是其**出栈元素不同排列的个数** $\dfrac{1}{n+1}C^{n}_{2n}$

  先序序列输出的是入栈的元素，而中序序列输出的是出栈的元素

  而先序和中序能确定一棵树，也就是有多少种中序就有多少棵树，也就是栈的出栈序列的个数

  如何保证先序序列和中序序列真的能构成一棵树？

  根据前序和后序思想，要进左子树必须先进其父结点，要进右子树必须前出其父结点，就有对于一个结点：

  - 当它在栈中时，往后入栈的元素都是它的左子树
  - 出栈之后，往后入栈的元素都是它的右子树

  所以出栈的前后只会影响左右性，不会对是否构成一棵树构成影响

##### 先中序列形成二叉树代码

思路：

1. 根据先序序列第一位确定树的根结点
2. 根据根结点在中序序列中划分出二叉树的左右子树包含那些结点
3. 根据左右子树结点在先序序列中的次序确定子树的根结点，即递归回步骤 1

```c
/**
 * A: 前序序列
 * B: 中序序列
 * l1: A 的第一个结点的下标
 * h1: A 的最后一个结点的下标
 * l2: B 的第一个结点的下标
 * h2: B 的最后一个结点的下标
 */
BiTree PreInCreat(ElemType A[], ElemType B[], int l1, int h1, int l2, int h2) {
    int i, llen, rlen;
    root = (BiTNode*)malloc(sizeof(BiTNode));  // 建立根结点
    root -> data = A[l1];
    for (i = l2; B[i] != root -> data;  i++);  // 在中序找出该结点的位置
    llen = i - l2;  // 左子树序列的长度
    rlen = h2 - i;  // 右子树序列的长度
    
    if (llen)  // 如果左子树序列不为空，递归建立；否则设左子树为空
        root -> lchild = PreInCreat(A, B, l1 + 1, l1 + llen, l2, l2 + llen - 1);
    else
        root -> lchild = NULL;
    
    if (rlen)
        root -> rchild = PreInCreat(A, B, h1 - rlen + 1, h1, h2 - rlen + 1, h2);
    else
        root -> rchild = NULL;
    
    return root;  // 返回局部二叉树的根结点
}
```

### 线索二叉树

#### 线索二叉树的基本概念

线索二叉树就是把二叉表的 n + 1 个**空指针利用起来**，分别**指向前驱和后继**

规定：若**无左子树**，令 **`lchild` 指向其前序结点**；若**无右子树**，令 **`rchild` 指向其后继结点**；此外还增加两个<u>标志域来表示指针域指向的是孩子还是前序或后继</u>

引用线索二叉树是为了**加快查找结点前驱和后继的速度**，线索二叉树是一种**物理结构**

```c
typedef struct ThreadNode{
    ElemType data;  // 数据域
    struct ThreadNode *lchild, *rchild;  // 左右孩子指针
    int ltag, rtag;  // 左右线索标志
}ThreadNode, *ThreadTree;
```

`ltag` 为 1 时指向**前驱**，为 0 时指向**左孩子**；`rtag` 为 1 时指向**后继**，为 0 时指向**右孩子**

以这种结点结构构成的二叉链表作为二叉树的存储结构叫做**线索链表**，其中**指向前驱和后继的指针叫做线索**，**加上线索的二叉树称为线索二叉树**

#### 中序线索二叉树的构造

**二叉树的线索化**是将二叉链表中的**空指针改为指向前驱或后继的线索**，通过遍历一次二叉树来实现

**中序线索二叉树的前驱**就是**中序遍历时结点的前驱**，前序、后序线索二叉树类似

附设 `pre` 指针指向前驱结点（刚刚访问的结点），指针 p 是正在访问的结点，在中序遍历中，调整它们的关系，代码如下：

```c
// 中序遍历线索化二叉树，
void InThread(ThreadTree &p, ThreadTree &pre){
    if(p != NULL){
        InThread(p -> lchild, pre);  // 线索化左边的二叉树
        if(p -> lchild == NULL){  // 当前结点左子树为空，指向前驱
            p -> lchild = pre;
            p -> ltag = 1;
        }
        if(pre != NULL && pre -> rchild == NULL){  // 前驱的右子树为空，指向后继
            pre -> rchild = p;
            pre -> rtag = 1;
        }
        pre = p;  // 更新前驱，注意这个是引用类型
        InThread(p -> rchild, pre);  // 线索化右边的二叉树
    }
}
 
// 建立中序线索化二叉树
void CreatInThread(ThreadTree T){
    ThreadTree pre = NULL;
    if(T != NULL){
        InThread(T, pre);  // 线索化
        pre -> rchild = NULL;  // 处理遍历的最后一个结点
        pre -> rtag = 1;
    }
}
```

二叉树的线索链表上**添加一个头结点**，令其 **`lchild` 指向二叉树的根结点**，**`rchild` 指向中序遍历的最后一个结点**

令**中序遍历**的**第一个结点的 `lchild`** 和**最后一个结点的 `rchild`** 均**指向头结点**

这就好比为二叉树建立了一个双向线索链表，**方便**从前往后或从后往前**对线索二叉树进行遍历**

![image-20210917230116841](..\images\image-20210917230116841.png)

#### 中序线索二叉树的遍历

线索二叉树的结点中隐含了线索二叉树的前驱与后继的信息

遍历时只要**找到序列中的第一个结点**，然后**依次找结点的后继**，**直至后继为空**

当右标志为 1 时，**后继为右线索**；当右标志为 0 时，**后继为右子树的最左子树**

```c
// 找中序线索二叉树中中序序列下的第一个结点
ThreadNode *Firstnode(ThreadNode *p){
    while(p -> ltag == 0) p = p -> lchild; // 最左下结点（不一定是叶结点）
    return p;
}
 
// 找中序线索二叉树中结点 p 在中序序列下的后继
ThreadNode *Nextnode(ThreadNode *p){
    if(p -> rtag == 0) return Firstnode(p -> rchild);
    return p -> rchild;  // rtag == 1直接返回后继线索
}
 
// 遍历线索二叉树
void Inorder(ThreadNode *T){
    for(ThreadNode *p = Firstnode(T); p != NULL; p = Nextnode(p))
        visit(p);
}
```

#### 先序和后序线索二叉树

先序线索二叉树和后序线索二叉树的代码类似，只需变动**线索化的代码**与**线索化左右子树递归**的**位置**

```c
// 先序线索化
void PreThread(ThreadTree T, ThreadTree &pre){
    if(T!=NULL){
        ......;  // 线索化，与中序先序化一样
        if(T -> ltag != 1)  // 因为上面进行了线索化，所以需要判断一下
            PreThread(T -> lchild, pre);
        if(T -> rtag != 1)  // 避免回溯回来造成死循环，当父结点的后继是自己时，只有一个左结点时
            PreThread(T -> rchild, pre);
    }
}

// 后序线索化，与中序先序化一样
void PostThread(ThreadTree T, ThreadTree &pre){
    if(T != NULL){
        PostThread(T -> lchild, pre);
        PostThread(T -> rchild, pre);
        ......;  // 线索化
    }
}
```

先序线索二叉树中找后继结点：

* 如果有左孩子，则其就是后继
* 如果只有右孩子，则其就是后继
* 如果为叶结点，右索引指向的就是后继

后序线索二叉树中找后继结点：

* 如果是二叉树的根，则没有后继
* 如果是双亲的左孩子，且双亲有右孩子，后继为双亲的右孩子按后序遍历列出的第一个结点
* 如果是双亲的右孩子，或是左孩子且没有右孩子，后继为双亲

后序线索二叉树在找后继的时候**需要知道双亲**，所以在**遍历的时候仍需要栈支持**，或者**采用带标志域的三叉链**作为存储结构，<u>先序线索二叉树找其前驱时也不能直接找到</u>

```c
// 先序线索二叉树的后继
ThreadNode *Nextnode(ThreadNode* p){
    if(p -> ltag == 0) return p -> lchild;  // 有左孩子
    else if(p -> rtag == 0) return p -> rchild;  // 只有右孩子
    return p -> rchild;  // 叶结点返回线索
}


// 遍历先序线索二叉树
void Preorder(ThreadTree T){
    for(ThreadNode *p = T; p != NULL; p = Nextnode(p))
        visit(p);
}

// 后序线索二叉树的前序
ThreadNode *Prenode(ThreadNode* p){
    // 后序线索二叉树的前驱刚好就是先序线索二叉树的后继的反转
    if(p -> rtag == 0) return p -> rchild;
    else if(p -> ltag == 0) return p -> lchild;
    return p -> lchild;
}

// 逆向遍历线索二叉树
void RevPostorder(ThreadTree T){
    // 如果想要正向遍历可以使用栈来辅助
    for(ThreadNode *p = T; p != NULL; p = Prenode(p))
        visit(p);
}
```

### 综合应用题

#### 非递归求二叉树高度

问题：假设二叉树采用二叉链表存储，设计一个非递归算法求二叉树的高度

思路：

使用层次遍历，记录当前层的最后一个元素，当出列的是当前层的最后一个元素时，记录下一层的最后元素，层数加一

因为出列到当前层的最后一个元素时，下一层的所有元素已经入队了，这时记录的队尾就是下一层最后一个元素

```c
int Btdepth(BiTree T) {
    if (!T) return 0;
    int front = -1, rear = -1;
    int last = 0, level = 0;
    BiTree Q[MaxSize];
    Q[++rear] = T;  // 根入列
    BiTree p;
    while (front < rear) {
        p = Q[++front];  // 出队
        if (p->lchild)  // 左孩子入队
            Q[++rear] = p->lchild;
        if (p->rchild)  // 右孩子入队
            Q[++rear] = p->rchild;
        if (front == last) {  // 当出队的是当前层最后一个时
            level++;  // 层数加一
            last = rear;  // 指向下一层的最后一个
        }
    }
    return level;
}
```

#### 访问  x 的所有祖先

问题：在二叉树中查找值为 x 的结点，试编写算法打印值为 x 的结点的所有祖先，假设值为 x 的结点不多于一个

思路：使用带栈的后序遍历，当访问到值为 x 的结点时，栈中所有元素均为该结点的祖先

后序遍历是指，访问可以任何时候访问，但入栈要先左后右，出栈要在左右入栈之后

```c
typedef struct {
    BiTree t;
    int tag;  // 0 表示左孩子被访问；1 表示右孩子被访问
} stack;

void Search(BiTree bt, ElemType x) {
    stack s[];  // 假设栈足够大
    int top = 0;
    while (bt != NULL || top > 0) {
        // 访问该结点，访问在左之前，而出栈在右之后，中操作其实就是出栈操作
        while (bt != NULL && bt -> data != x) {  // 在入栈前访问结点 bt -> data != x
            s[++top].t = bt;
            s[top].tag = 0;
            bt = bt -> lchild;
        }
        if (bt != NULL && bt -> data == x) {  // 找到 x
            printf("所查结点的所有祖先结点的值为：\n");
            for (i = 1; i <= top; i++)
                printf("%d", s[i].t -> data);
            exit(1);
        }
        // 退栈，右结点都被访问了的结点已经遍历完了，退到右结点没被访问的结点
        // 感觉可以把判断操作放在出栈之后，而不是在入栈的时候直接判断，可能是为了节省性能才先访问吧
        while (top != 0 && s[top].tag == 1)
            top--;
        // 来到这里 bt 已经是 NULL，且栈顶只有右结点未被访问
        if (top != 0) {
            s[top].tag = 1;  // 设置为访问它的右结点
            bt = s[top].t -> rchild;  // 开始访问右结点
        }
    }
}
```

感觉这种递归没有[栈实现后序遍历](#栈实现后序遍历)的代码好用，思维也没它清晰

#### 访问 p、q 的最近共同祖先

问题：设一棵二叉树的结点结构为 `(LLINK, INFO, RLINK)`，ROOT为指向该二叉树根结点的指针，p 和 q 分别指向该二叉树中任意两个结点的指针，试编写算法 `ANCESTOR(ROOT, p, q, r)`，找到 p 和 q 的最近公共祖先结点 r

思路：使用后序遍历加辅助栈，把第一个找到的结点的所有祖先放入辅助栈中，找到第二个时把辅助栈与当前栈比较

```c
typedef struct {
    BiTree t;
    int tag;  // 0 表示左孩子被访问；1 表示右孩子被访问
} stack;

BiTree Ancestor(BiTree ROOT, BiTNode *p, BiTNode *q) {
    stack s[], s1[];  // 假设栈足够大
    int top = 0, top1;
    BiTree bt = ROOT;
    bool find = false;
    while (bt != NULL || top > 0) {
        // 访问该结点，访问在左之前，而出栈在右之后，中操作其实就是出栈操作
        while (bt != NULL) {
            s[++top].t = bt;
            s[top].tag = 0;
            bt = bt -> lchild;
        }
        // 右结点都被访问了的结点已经遍历完了，出栈执行操作了
        while (top != 0 && s[top].tag == 1) {
            if (s[top].t == p || s[top].t == q)  // 是要找的两结点之一
                if (!find) {  // 找到第一个
                    for (int i = 1; i <= top; i++)  // 把栈拷贝到辅助中保存
                        s1[i] = s[i];
                    top1 = top;
                    find = true;
                } else {  // 找到第二个
                    for (int i = 2; i <= top; i++)  // 第一个不相等的结点的父结点就是最近的共同祖先
                        if (s1[i].t != s[i].t)
                            return s[i - 1].t;
                }
            top--;
        }
        // 来到这里 bt 已经是 NULL，且栈顶只有右结点未被访问
        if (top != 0) {
            s[top].tag = 1;  // 设置为访问它的右结点
            bt = s[top].t -> rchild;  // 开始访问右结点
        }
    }
}
```

我看见答案的时候很失望，居然是这种简单普遍的解法，代码也有点问题，修改了一下不一定能执行

我写了个递归的实现

```c
bool func(Tree *T, int p, int q, Tree &result) {
	if(T == NULL || result != NULL) return false;
	bool l, r;
	l = func(T->left, p, q, result);
	r = func(T->right, p, q, result);
    if(result != NULL) return false;
    
	if(l && r) {  // 左右子树分别找到，就是公共祖先
		reult = T;
		return false;
	}
    
	if(l || r) {
		if (T->data == q || T->data == p){  // 两结点间为祖孙关系
			result = T;
			return false;
		}
        return true;
	}
	
	if (T->data == q || T->data == p){  // 找到第一个
		return true;
	}
	
	return false;
}

Tree *Ancestor(Tree *T, int p, int q){
	Tree *reult = NULL;
	func(T, p, q, result);
	return result;
}
```

#### 树的最大宽度

题目：假设二叉树采用二叉链表存储结构，设计一个算法，求非空二叉树 b 的宽度（结点最多的那层的结点个数）

思路：使用队列层序遍历，队列中不仅带结点，还带结点所在的层数

根部层数为 1，入队时左子树的层数是自己层数加一，右子树也是一样

最后扫描队列求出各层的结点的总数，最大的层结点总数就是树的宽度了

#### 满二叉树的先序转后序

题目：设有一棵**满二叉树**，所有结点值均不同，已知其先序序列为 `pre`，设计一个算法求其后序序列 `post`

思考：对于先序和后序有一条规则，**先序的第一位等于后序的最后一位**，那么我们根据这条规则就可以想出：

1. 取出先序序列的第一个放入后序序列的最后一个
2. 除掉第一位的先序序列从中间拆开，左半是左子树，右半是右子树；左 1 就是左根，右 1 就是右根
3. 后序序列是左右中，现在反过来就是中右左了，第二步时中放完了，现在放右，对右子树根结点递归到 1
4. 根据中右左，右子树的信息放完了就该放左子树，从左子树开始，对左子树根结点递归到 1

```c
/**
 * pre: 前序序列
 * l1: pre 的第一个结点的下标
 * h1: pre 的最后一个结点的下标
 * post: 后序序列
 * l2: post 的第一个结点的下标
 * h2: post 的最后一个结点的下标
 */
void PreToPost(char pre[], int l1, int r1, char post[], int l2, int r2) {
    int mid;
    if (r1 >= l1) {
        post[r2] = pre[l1];  // 根
        mid = (r1 - l1) / 2;
        PreToPost(pre, l1 + 1, l1 + mid, post, l2, l2 + mid - 1);  // 左，前半段放左
        PreToPost(pre, l1 + mid + 1, r1, post, l2 + mid, r2 - 1);  // 右，后半段放右
    }
}
```

#### 中序结点找后序前驱

题目：写出在中序线索二叉树里查找指定结点在后序的前驱结点的算法

思路：结合中序和后序线索二叉树，思考各种情况，得到以下规律：

1. 若结点 p 有右孩子，则右孩子是其前驱
2. 若无右孩子但有左孩子，则左孩子是其前驱
3. 拿其中序左线索，为空就没有前驱
4. 中序左线索指向的祖先 f，它有左子树，则前驱就是 f 的左子树
5. 若 f 的左子树为空，就取其中序左线索，循环直到它左子树不为空，前驱就是左子树
6. 若循环时 f 的左子树为空了（没有线索了）就没有前驱

```c
BiThrTree InPostPre(BiThrTree t, BiThrTree p) {
    BiThrTree q;
    if (p -> rtag == 0)  // 第一步，有右返回右
        q = p -> rchild;
    else if (p - > ltag == 0)  // 第二部，无右有左返回左
        q =  p -> lchild;
    else if (p -> lchild == NULL)  // 第三步，无线索无前驱
        q = NULL;
    else {
        while (p -> ltag == 1 && p -> lchild != NULL)  // 循环直到有左子树
            p = p -> lchild;
        if (p -> ltag == 0)  // 有左子树，前驱是左子树
            q = p -> lchild;
        else  // 没有无前驱
            q = NULL;
    }
    return q;
}
```

## 树、森林

### 树的存储结构

#### 双亲表示法

采用一组**连续的空间**存储每个结点，并在每个结点中**记录其父结点的索引**，它的存储结构描述：

```c
#define MAX_TREE_SIZE 100

typedef struct {
    ElemType data;  // 数据元素
    int parent;  // 双亲的索引
} PTNode;

typedef struct {
    PTNode nodes[MAX_TREE_SIZE];  // 结点信息
    int n;  // 结点数
}
```

![image-20210919141347791](..\images\image-20210919141347791.png)

该存储结构利用了每个结点**只有一个双亲**的性质，可以很快得到结点的双亲，但**获取结点的孩子**需要**遍历整个结构**

注意：注意树和二叉树的最大的区别是，它的**儿子数量不是固定的**，所以才需要记录双亲的索引

#### 孩子表示法

将**每个结点的孩子都用单链表连接起来**形成一个线性结构，此时 n 个结点就有 n 个孩子链表

该存储结构寻找子女操作很简单，但是**寻找双亲**就要**迭代全部整个孩子链表**了

![image-20210919142223692](..\images\image-20210919142223692.png)

#### 孩子兄弟表示法

孩子兄弟表示法又称**二叉树表示法**，以二叉链表作为树的存储结构

其中**左指针**指向结点的**第一个孩子结点**，**右指针**指向该结点的**下一个兄弟结点**

```c
typedef struct CSNode {
    ElemType data;
    struct CSNode *firstchild, *nextsibling;
} CSNode, *CSTree;
```

该存储结构可以方便地实现**树转换为二叉树的操作**，易于**找结点的孩子**，但**找其双亲比较麻烦**

若为每个结点**增设一个 parent 域**指向其父结点，则查**找结点的父结点也很方便**

![image-20210919144047050](..\images\image-20210919144047050.png)

注意：在左孩子右兄弟中，堂兄弟不能也放进来

### 树、森林与二叉树的转换

给定一森林，可以找到**唯一的二叉树**与之对应；同样的给定一棵二叉树，可以找到**唯一的森林**与它对应

二叉树与森林从物理结构上看它们的二叉链表是相同的，但**解释不一样**

以下都是逻辑上的转换（考试画图，或选择题逻辑），因为在计算机内二叉树本就是森林的存储结构，不用转换

选择题：将树 F 转换为对应的二叉树 T，F 中**叶结点的个数**等于 T 中**左孩子指针为空的结点个数**；F 中的**非终端结点个数**等于 T 中**右孩子指针为空的结点个数减一**

1. 根据左孩子右兄弟，T 中左指针为空意味着森林的某个结点没有孩子，所以左指针空的个数是 F 中叶结点的个数

2. 根据左孩子右兄弟，T 中右指针为空意味着森林中某个结点没有右兄弟

   首先非终端结点肯定有孩子，那么它的孩子中肯定就会有一个没有右兄弟

   就有 T 中右指针为空的个数至少为 F 中非终端的个数

   其次对于根结点来说，除了它的孩子会没有右兄弟外它自己也没有右兄弟

   把根结点算上，就有 T 的右指针为空的个数就是 F 的非终端的个数加一

#### 树转换成二叉树

每个结点的**左指针指向它的第一个孩子**，**右指针指向它在树中的相邻右兄弟**，这是**左孩子右兄弟**

树转换成二叉树的画法：

1. 在兄弟结点之间加一连线
2. 仅保留指向第一个孩子的指针
3. 以树根为中心顺时针旋转 45°

#### 森林转换成二叉树

森林转换成二叉树与树类似，只要把**第二棵树看成第一棵树的右兄弟**，依次类推就好了

森林转换成二叉树的画法：

1. 将森林的每课树转换成相应的二叉树
2. 每棵树的根视为兄弟关系，在每棵树的根间加一条连线
3. 以第一棵树的根为中心顺时针旋转 45°

#### 二叉树转换成树、森林

- 若二叉树非空，二叉树的根及其左子树为第一棵树的二叉树形式
- 将根的右链断开，它的右子树视为一个森林来处理，如此反复，直到没有右子树
- 最后将每课二叉树依次转换成树，就得到原森林

### 树和森林的遍历

#### 树的遍历

- 先根遍历：若树非空，先访问根结点，再依次遍历根结点的每个子树，遍历时仍采用先根遍历

  其遍历序列与这棵树**相应二叉树的先序遍历相同**

- 后根遍历：若树非空，先依次遍历根结点的每个子树，再访问根结点，遍历时仍采用后根遍历

  其遍历序列与这棵树**相应的二叉树的中序遍历相同**

- 层次遍历：与二叉树的层次遍历一样，使用队列，先入根结点，出列一个结点时把其子树全部入列

  说点题外话，怎么实现，大致乱写一下：

  ```c
  Queue q;
  p = root;
  while(p) {  // 森林的全部树根都入队
      q.add(p);
      p = p.rchild;
  }
  while(!q.empty()) {
      p = q.remove();
      visit(p);
      p = p.lchild();
      while(p) {  // 全部儿子都入队
          q.add(p);
          p = p.rchild;
      }
  }
  ```

#### 森林的遍历

1. 先序遍历森林，若森林非空，就执行遍历：
   - 访问森林中第一棵树的根结点
   - 先序遍历第一棵树种根结点的子树森林（这两步相当于前根遍历，先自己，再遍历子结点）
   - 先序遍历除去第一棵树之后剩余的树构成的森林（对第二棵树，第三棵等递归使用前根遍历）
2. 中序遍历森林（也可以叫后序遍历），若森林非空，就执行遍历：
   - 中序遍历森林中第一棵树的根结点的子树森林
   - 访问第一棵树的根结点（这两步相当于后根遍历，先遍历子结点，再自己）
   - 中序遍历除去第一棵树之后剩余的树构成的森林（对第二棵树，第三棵等递归使用后根遍历）

**先序遍历**森林就相当于**先序遍历其相应的二叉树**；**中序遍历**森林就相当于**中序遍历其相应的二叉树**

<img src="..\images\image-20210919152628452.png" alt="image-20210919152628452" style="zoom:200%;" />

注意：**中序遍历**森林，**也可以叫中根遍历**因为对于其二叉树是中根遍历，**也可以叫后根遍历**因为对于树是后根遍历的

### 层次序列及度构成孩子兄弟链表

问题：已知一棵树的层次序列及每个结点的度，编写算法构成此树的二叉孩子兄弟链表

思路：由于有结点的度，我们可以拿到结点的子结点并链到结点上，只需要使用遍历记录子结点的位置和父结点的位置

```c
#define maxNodes 15

void createCSTreeDegree(CSTree &T, DataType e[], int degree[], int n) {
    CSTree *pointer = new CSTree[maxNodes];
    int i, j, d, k = 0;
    for (i = 0; i < n; i++) {  // 初始化数组
        pointer[i] = new CSNode;
        pointer[i] -> data = e[i];
        pointer[i] -> lchild = pointer[i] -> rsibling = NULL;
    }
    for (i = 0; i < n; i++) {  // 调整树的关系
        d = degree[i];  // 当前结点的度数
        if (d) {
            k++;
            pointer[i] -> lchild = pointer[k];
            for (j = 2; j <= d; j++) {  // 把该结点的子结点链入
                k++;
                pointer[k - 1] -> rsibling = pointer[k];
            }
        }
    }
    T = pointer[0];
    delete [] pointer;
}
```

书上采用的是辅助数组直接初始化，然后分别链上去，而我更想用队列，下面是我使用队列写的

```c
// 创建新的结点
CSNode *createCSNode(int data) {
	CSNode *r = new CSNode;
	r->data = data;
	r->rchild = r->lchild = NULL;
	return r;
}

void createCSTreeDegree(CSTree &T, int e[], int degree[]) {
	LinkQueue Q;
	int i = -1, j, k = 0, d;
	CSNode *p, *q;
	InitQueue(Q);
	T = createCSNode(e[0]);  // 创建根部结点
	EnQueue(Q, T);
	while (!IsEmpty(Q)) {
		DeQueue(Q, p);
		i++;
		if (d = degree[i]) {  // 如果有度就是有儿子，把儿子链入然后入队列
			k++;
			q = p->lchild = createCSNode(e[k]);
			EnQueue(Q, q);
			for (j = 2; j <= d; j++) {
				k++;
				q->rchild = createCSNode(e[k]);
				q = q->rchild;
				EnQueue(Q, q);
			}
		}
	}
}
```

## 树与二叉树的应用

### 并查集

![image-20220510182435831](..\images\image-20220510182435831.png)

并查集是一种**简单的集合表示**，它支持以下三种操作：

```c
Union(S, Root1, Root2);  // 把集合 S 的子集合 Root2 并入子集合 Root1，要求它们不能相交
Find(S, x);  // 查找集合 S 中单元素 x 所在的子集合，返回子集合名字
Initial(S);  // 将集合 S 中的每个元素都初始化为只有一个单元的集合
```

通常用**树（森林）的双亲表示**作为并查集的存储结构，**每个子集以一棵树表示**

通常以**数组的下标表示元素名**，用**根结点的下标代表子集合名**，**根结点的双亲结点为负数**

合并两个子集，只需将其中**一个子集合根结点的双亲指针指向另一个集合的根结点**

使用双亲指针数组作为并查集存储表示时，**集合元素编号从 0 到 size - 1**，其中 size 是最大元素的个数

```c
#defind SIZE 100
int UFSets[SIZE];  // 集合元素（双亲数组）

// 初始化并查集，所有初始化为 -1，即各自都是一棵树
void Initial(int s[]) {
    for (int i = 0; i < SIZE - 1; i++)
        s[i] = -1;
}

// 查找 S 中包含 x 的树的根结点，最坏时间复杂度为 O(n)
int Find(int S[], int x) {
    while (S[x] >= 0)
        x = S[x];
    return x;
}

// 合并两个不相交的子集，即求并集
// 代码写的有问题，合并时当在同一集合就会直接返回，且合并是根部合并
void Union(int S[], int Root1, int Root2) {
    // if(Find(s, root1) == Find(s, Root2)) return;
    // S[Find(S, Root2)] = Find(S, Root1);
    S[Root2] = Root1;
}
```

### 哈夫曼树和哈夫曼编码

#### 哈夫曼树的定义

在许多应用中，树中结点常常被赋予一个表示某种意义的数值，称为该结点的权

该**结点的带权路径长度**，是从**树的根到该结点的路径长度（经过的边数）与该结点上权值的乘积**

**树的带权路径长度**，记为 $WPL=\displaystyle\sum^n_{i=1}w_il_i$ 其中 $w_i$ 是第 i 个叶结点所带的权值，$l_i$ 是该叶结点到根结点的路径长度，即**所有叶结点的带权路径长度的和**

![image-20210920141556685](..\images\image-20210920141556685.png)

哈夫曼树是相同权重的叶结点中 `WPL` 最小的树，如上面 c 是一棵哈夫曼树，在三颗中 `WPL` 最小

#### 哈夫曼树的构造

给定 n 个权值分别为 $w_1,\cdots,w_n$ 的结点，**构造哈夫曼树的算法描述**如下：

1. 将这 n 个结点分别作为 n 棵仅含一个结点的二叉树，构成森林 F
2. 构造一个新结点，从 F 中取**两棵根结点权重最小的树**，**合并在一起**，**根结点的权重是这两个权重的和**
3. 从 F 中**删除刚刚选出的两棵树**，并**加入它们的合并树**
4. 重复 2、3 步骤，直至 F 中只剩下一棵树为止

从上述构造过程中可以看出哈夫曼树具有以下特点：

1. **每个初始结点最终都成为叶结点**，且**权值越小的结点到根结点的路径长度越大**
2. 构造过程中共新建了 n - 1 个结点，因此**哈夫曼树的结点总数为 `2n - 1`**，n 是叶结点的数量
3. 每次构造都选择 2 棵树作为新结点的孩子，因此**哈夫曼树中不存在度为 1 的结点**

<img src="..\images\src=http___pic2.zhimg.com_v2-5591c52619c16ddd52a882981fa716cd_b.gif&refer=http___pic2.zhimg.gif" alt="src=http___pic2.zhimg.com_v2-5591c52619c16ddd52a882981fa716cd_b.gif&refer=http___pic2.zhimg"  />

#### 哈夫曼编码

在数据通信中，对每个字符用**相等长度的二进制位表示**，则称为**固定长度编码**；若对不同字符用**不等长的二进制位表示**，则称为**可变长度编码**

可变长度编码的特点是，对**频率高的字符赋以短编码**，对**频率低的字符赋以较长一点的编码**，从而**缩短字符的平均编码长度**，起到压缩数据的作用

若**没有一个编码是另一个编码的前缀**，那么称这样的编码为**前缀编码**，如 {0, 00} 不是前缀码，{0, 10} 是前缀码

前缀编码的解码：因为没有一个编码是其他编码的前缀，解码时只**需识别每一个编码，将它翻译成原码**

哈夫曼编码的构造：

1. 将每个出现的字符作为哈夫曼树的结点，其权值为字符出现的频率
2. 拿这些字符结点构成一棵哈夫曼树
3. 将哈夫曼树的左边标记 0，右边标记 1
4. 每个字符的编码就是哈夫曼树的根到它所经过边的标记的集合

![image-20210920150005087](..\images\image-20210920150005087.png)

注意：**0 和 1 是左边还是右边没有明确规定**，且**左右结点的顺序是任意的**，所以**构造出的哈夫曼树不唯一**，但**每个哈夫曼树的 `WPL` 相同且为最优**

#### 最小代价合并多个有序表

问题：设有 6 个有序表 A，B，C，D，E，F，分别含有 10，35，40，50，60，200 个数据元素，各表中的元素按升序排序。要求通过 5 次两两合并，将 6 个表最终合并为 1 个升序表，并使最坏情况下比较的总次数达到最小

思路：先合并的表中元素在后序的每次合并中都会再次参与比较，因此求最小合并次数类似于求最小带权路径长度，所以就考虑使用哈夫曼树进行运算

求最坏情况下的比较次数，利用两个有序表合并的最坏情况需要比较 m + n - 1 次来求

## 注意

二叉树是极其重要的考点，关于二叉树的有关操作，出现了树的算法设计题

遍历时各种操作的基础，统考时会考查遍历过程对结点的各种操作

**需要重点掌握各种遍历方法的手写，如递归算法和利用栈或队列的非递归算法**

# 图

## 图的基本概念

### 图的定义

**图 G 由顶点集 V 和边集 E 组成**，记为 G=(V, E)，其中 **V(G)** 表示图 G 中**顶点的有限非空集**；**E(G)** 表示图 G 中**顶点之间的关系（边）集合**。

若 $V=\{v_1,\cdots,v_n\}$，则用 |V| 表示图 G 中顶点的个数，$E=\{(u,v)|u\in V,v\in V\}$ 用 |E| 表示图 G 中边的条数

注意：**图不可以是空图**，图中不能一个顶点也没有，图的**顶点集 V 一定非空**，但**边集 E 可以为空**

#### 有向图

若 E 是**有向边**（也称弧）的**有限集合**时，则图 G 为**有向图**

弧是顶点的**有序对**，记为 <v, w>，其中 v，w 是顶点，v 称为弧尾，w 称为弧头

<v, w> 称为从 v 到 w 的弧，也称 v 邻接到 w

#### 无向图

若 E 是**无向边**（简称边）的**有限集合**时，则图 G 为**无向图**

边是顶点的**无序对**，记为 (v, w) 或 (w, v)，可以说 w 和 v 互为邻接点

边 (v, w) 依附于 w 和 v，或称边 (v, w) 和 v，w 相关联

#### 简单图、多重图

如果图 G 是**简单图**，那么它满足：

1. **不存在重复边**
2. **不存在顶点到自身的边**

若图 G 中某**两个顶点之间的边数大于 1 条**，又**允许顶点通过一条边与自身关联**，则称图 G 为**多重图**

多重图和简单图的定义是相对的，**数据结构中仅讨论简单图**

#### 完全图（简单完全图）

对于**无向图**，|E| 的取值范围为 0 到 n(n-1)/2，**有 n(n-1)/2 条边**的无向图称为**完全图**，在完全图中**任意两个顶点之间都存在边**

对于**有向图**，|E| 的取值范围为 0 到 n(n-1)，**有 n(n-1) 条弧**的有向图称为**有向完全图**，在有向完全图中**任意两个顶点之间都存在方向相反的两条弧**

#### 子图

设有两个图 G = (V, E) 和 $G^\prime=(V^\prime,E^\prime)$，**若 $V^\prime$ 是 V 的子集，且 $E\prime$ 是 E 的子集**，则称 $G^\prime$ 是 G 的**子图**

若有满足 $V(G^\prime)=V(G)$ 的子图 $G^\prime$，即**顶点相同**，则称其为 G 的**生成子图**

一个图的连通分量、非连通分量，强连通分量、非强连通分量都是它的子图，只是取得部分不一样

注意：**并非 V 和 E 的任何子集都能构成 G 的子图**，因为 E 的子集中的某些边关联的顶点可能不在这个 V 的子集中

#### 连通、连通图和连通分量

在无向图中，若**顶点 v 到顶点 w 有路径存在**，则称 v 和 w 是**连通**的

若图 G 中**任意两个顶点都是连通的**，则称 G 为**连通图**，否则称为**非连通图**

无向图的每个**极大连通子图**称为**连通分量**，极大连通表示包含连通的**所有边**，与下面极小连通（树）对比理解

假设一个图有 n 个顶点，如果**边数小于 n - 1**，那么此图必定是**非连通图**；如果**边数大于 (n-1)(n-2)/2**，那么此图必定是**连通图**

#### 强连通图、强连通分量

在有向图中，如果有一对顶点 v 和 w，**从 v 到 w 和从 w 到 v 之间都有路径**，则称这两个顶点是**强连通**的

若图中**任何一对顶点都是强连通的**，则称此图为**强连通图**

有向图中的**极大强连通子图**称为有向图的**强连通分量**

假设一个有向图有 n 个顶点，如果是**强连通图**，那么**最少需要要 n 条边**，即形成一个环

#### 生成树、生成森林

连通图的生成树是**包含图中全部顶点的一个极小连通子图**，若图中顶点数为 n，则它的**生成树含有 n - 1 条边**

对生成树而言，若**砍去它的一条边**，则会变成**非连通图**；若**加上一条边**，则会**形成一条回路**

在**非连通图中**，**连通分量的生成树**构成了非连通图的**生成森林**，即每个连通分量都生成树

#### 顶点的度、入读和出度

无向图中，**顶点 v 的度**是指**依附于顶点 v 的边的条数**，记为 TD(v)

对于具有 n 个顶点、e 条边的无向图，$\displaystyle\sum^n_{i=1}TD(v_i)=2e$，即**无向图的全部顶点的度的和等于边数的两倍**，因为每条边和两个顶点相关联

有向图中，顶点 v 的度分为入度和出度，**入度**是**以顶点 v 为终点**的有向的数目，记为 ID(v)；而**出度**是**以顶点 v 为起点**的有向边的数目，记为 OD(v)

**顶点 v 的度等于其入度和出度之和**，即 TD(v) = ID(v) + OD(v)

对于具有 n 个顶点、e 条边的有向图，$\displaystyle\sum^n_{i=1}ID(v_i)=\displaystyle\sum^n_{i=1}OD(v_i)=e$，即**有向图的全部顶点的入度之和与出度之和相等且等于边数**，这是因为每条有向边都有一个起点和终点

#### 边的权和网

在一个图中，<u>每条边都可以标上具有某种含义的数值，该数值称为该边的权值</u>

这种边上**带有权值的图称为带权图**，也称**网**

#### 稠密图、稀疏图

**边数很少的图称为稀疏图**，**反之称为稠密图**

稀疏和稠密本身是模糊的概念，稀疏图和稠密图常常是相对而言的

一般当图 G 满足 $|E| < |V|\log|V|$ 时，可以将 G 视为稀疏图

#### 路径、路径长度和回路

**顶点 $v_p$ 到顶点 $v_q$ 之间的一条路径**是指顶点序列 $v_p,v_{i_1},\cdots,v_{i_m},v_q$，关联的**边**为路径的构成要素

**路径上边的数目**称为**路径长度**

**第一个顶点和最后一个顶点相同**的路径称为**回路或环**

若一个无向图有 n 个顶点，并且有大于 n - 1 条边，则此图一定有环

#### 简单路径、简单回路

在路径序列中，**顶点不重复出现的路径**称为**简单路径**

**除第一个顶点和最后一个顶点外**，**其余顶点不重复出现的回路**称为**简单回路**

#### 距离

**从顶点 u 出发到顶点 v 的最短路径**若存在，则此路径称为 **u 到 v 的距离**

若从 **u 到 v 根本不存在路径**，则即该**距离为无穷**（$\infty$）

#### 有向树

一个**顶点的入度为 0**、**其余顶点的入度均为 1** 的有向图，称为**有向树**

### 无环有向图重排*

问题：如何对无环有向图中的顶点号重新安排可使得该图的邻接矩阵中所有的 1 都集中到对角线<u>以上</u>

思考：无环图最多有 `n(n-1)/2` 条边，刚好是矩阵上三角矩阵元素的个数，所以这个是可以实现的

如果有 <i, j> 的话 <u>i 肯定是需要在 j 前面</u>的，因为 j 在 i 前面那么就有个 1 在下三角了

其次满足上面条件的情况下，<u>出度需要从大到小排</u>，放在出度多放在后面会占用下三角形

- 因为 $a_{ij}$ 表示边 \<i, j\>，出度多的话 j 的数量就多，上三角矩阵行越低 j 数量就越少，放后面显然不行

注意：可以采用拓扑排序并依次编号，这样一种更为简便的方法

## 图的存储及基本操作

### 邻接矩阵法

#### 邻接矩阵的定义

邻接矩阵存储，指用一个**一维数组存储图中顶点的信息**，用一个**二维数组存储图中边的信息**，**存储顶点之间邻接关系的二维数组**称为**邻接矩阵**。**结点数为 n 的图 G = (V, E) 的邻接矩阵 A 是 $n\times n$ 的**

对于非带权图有 $A[i][j]=\left\{ \begin{matrix} 1,&若 (v_i,v_j) 或<v_i,v_j> 是E(G)中的边\\0,&若 (v_i,v_j) 或<v_i,v_j>不是E(G)中的边 \end{matrix} \right.$

对于带权图有 $A[i][j]=\left\{ \begin{matrix} w_{ij},&若 (v_i,v_j) 或<v_i,v_j> 是E(G)中的边\\0或\infty,&若 (v_i,v_j) 或<v_i,v_j>不是E(G)中的边 \end{matrix} \right.$

![image-20210921154745086](..\images\image-20210921154745086.png)

图的**邻接矩阵存储结构定义**如下：

```c
#define MaxVertexNum 100 
typedef char VertexType;
typedef int EdgeType;
typedef struct {
    VertexType Vex[MaxVertexNum];  // 顶点表
    EdgeType EDge[MaxVertexNum][MaxVertexNum];  // 邻接矩阵，边表
    int vexnum,arcnum;  // 图中当前顶点数和弧数
} MGragh;
```

#### 邻接矩阵的特点

图的邻接矩阵存储表示法具有以下特点：

1. 无向图的邻接矩阵一定是一个**对称矩阵**且唯一，因此只需要**存储上或下三交矩阵**的元素即可
2. 对于无向图，邻接矩阵的**第 i 行**（或**第 i 列**）**非零元素的个数**正好是**第 i 个顶点的度** $TD(V_i)$
3. 对于有向图，邻接矩阵的**第 i 行**（或**第 i 列**）**非零元素的个数**正好是**第 i 个顶点**的**出度** $OD(V_i)$（或**入度** $ID(V_i)$）
4. 用邻接矩阵法存储图，易确定**图中任意两个顶点之间是否有边相连**。但要确定**图中有多少条边**，则必须**按行，按列对每个元素进行检测**，所花费的**时间代价很大**
5. **稠密图**适合用**邻接矩阵存储**表示
6. 设图 G 的邻接矩阵为 A，$A^n$ 的元素$A^n[i][j]$ 等于由**顶点 i 到顶点 j 的长度为 n 的路径的条数**

注意：

1. 在**简单应用**中，可以**直接用二维数组作为图的邻接矩阵**（顶点等信息均可忽略）
2. 当邻接矩阵中的元素**仅表示相应的边是否存在**时，`EdgeType` 可定义值为 **0 和 1 的枚举类型**
3. 无向图的邻接矩阵是**对称矩阵**，对规模特大的邻接矩阵**可采用压缩存储**
4. 邻接矩阵表示法的**空间复杂度为 $O(n^2)$**，其中 n 为图的顶点数 |V|

#### 路径条数的证明

命题：设图 G 的邻接矩阵为 A，$A^n$ 的元素$A^n[i][j]$ 等于由顶点 i 到顶点 j 的长度为 n 的路径的条数

证明（写的不太好，但意思理解了就行）：

首先 $A^n$ 表示矩阵的次方如 $A^2=A\cdot A$，矩阵的乘法是 $A=(a_{ij})$，$c_{ij}=\displaystyle\sum_{k=1}^sa_{ik}b_{kj}$

假设有矩阵 $A^n$ 其中它的元素 $a_{ij}$ 表示 i 经过 n 的路径长度达到 j 的路径的条数

使用 $A^n$ 的定义创造出 $A^p=(p_{ij}),A^q=(q_{ij})$

其中 $p_{ik}\cdot q_{kj}$ 表示 i 经过 p 步到 k 再经过 q 步到 j 的路径的条数

所有的 $p_{ik}\cdot q_{kj}$ 加起来 $\displaystyle\sum^n_{k=1}p_{ik}\cdot q_{kj}$ 这就变成了路径长度为 p + q 时 i 到 j 的路径数了

- i ~ k 是所有情况的路径，k ~ j 也是所有情况，所以 i ~ k ~ j 是第 p 步为 k 的所有情况，而 k 为 1 ~ n 所以是 i ~ j 的所有情况

根据矩阵乘法 $A^z=(z_{ij})=A^p\cdot A^q=\displaystyle\sum^n_{k=1}p_{ik}\cdot q_{kj}$ 故 $A^z$ 的元素 $A^z[i][j]$ 等于 i 到 j 的长度为 z = p + q 的路径的条数

### 邻接表法

#### 邻接表的定义

当一个图为**稀疏图**时，使用邻接矩阵表示法显然浪费了大量的存储空间，为了**避免浪费发明了邻接表**

邻接表是对图 G 中的**每个顶点 $V_i$ 建立一个单链表**，第 i 个**单链表中的结点**表示依**附于顶点 $V_i$ 的边**，在**有向图则是以顶点 $V_i$ 为尾的弧**，这个单链表就称为顶点 $V_i$ 的**边表**，在**有向图是出边表**

**边表的头指针**和**顶点的数据信息**采用**顺序存储**，称为**顶点表**，所以在邻接表中存在两种结点：**顶点表结点**和**边表结点**

![image-20210921155916101](..\images\image-20210921155916101.png)

顶点表结点由**顶点域**、**指向第一条邻接边的指针**构成，边表结点由**临接点域**、**指向下一条临界边的指针**域构成

![image-20210921160255953](..\images\image-20210921160255953.png)

图的邻接表存储结构定义如下：

```c
#define MaxVertexNum 100 
typedef char VertexType;

typedef struct ArcNode {  // 边表结点
	int adjvex;  // 该弧所指向的顶点的位置
	struct ArcNode *next;  // 指向下一条依附于该顶点的弧的指针
} ArcNode;

typedef struct VNode {  // 顶点表结点
	VertexType data;  // 顶点信息
	ArcNode *first;  // 指向依附于该顶点的弧的指针
} VNode, AdjList[MaxVertexNum];

typedef struct {
	AdjList vertices;  // 邻接表
	int vexnum, arcnum; // 图的顶点数和弧数
} ALGraph;
```

#### 邻接表的特点

图的邻接表具有以下特点：

1. 如果 G 为**无向图**，则所需的**存储空间为 `O(|V|+2|E|)`**；如果 G 为**有向图**，则所需的**存储空间为 `O(|V|+|E|)`**

2. 对于**稀疏图**，**采用邻接表表示**将极大的节省存储空间

3. 给定一顶点，在**邻接表**中，**读取它的邻接表就找到它的所有临边**；在**邻接矩阵**中，相同的操作则需要**扫描一行**

   确定**两个顶点间是否存在边**，在**邻接矩阵**里可以**立即查到**；在**邻接表**中要在相应结点**对应的边表中查找**另一结点

4. 在有向图的邻接表表示中，求一个给定**顶点的出度**只需计算其**邻接表中结点个数**即可；但求其**顶点的入度**，则需要**遍历全部的邻接表**

   因此也有人采用**逆邻接表的存储方式**来加速**求解给定顶点的入度**，与邻接表的存储方式是类似的

5. **图邻接表表示并不唯一**，这是因为在每个顶点对应的单链表中，各边结点的链接次序可以任意，取决于建立邻接表的算法以及边的输入次序

### 十字链表

十字链表是**有向图**的一种**链式存储结构**，在十字链表中，对应于有向图中的**每条弧有弧结点**，对应于**每个顶点有顶点结点**

![image-20210921162754052](..\images\image-20210921162754052.png)

弧结点中有 5 个域：

1. 尾域 tailvex：弧尾顶点在图中的位置
2. 头域 headvex：弧头顶点在图中的位置
3. 链域 hlink：指向弧头相同的下一条弧
4. 链域 tlink：指向弧尾相同的下一条弧
5. info 域指向该弧的相关信息

这样**弧头相同的弧**在**同一个链表上**，**弧尾相同的弧**也在**同一个链表上**

顶点域中有三个域：

1. data：存放顶点相关的数据信息，如顶点名称
2. firstin：以该顶点为弧头的第一个弧结点
3. firstout：以该顶点为弧尾的第一个弧结点

![image-20210921163458628](..\images\image-20210921163458628.png)

在十字链表中，容易找到 $V_i$ 为尾的弧和 $V_i$ 为头的弧，因而**容易求得顶点的出度和入度**

图的十字链表表示**不是唯一**的，但一个十字链表表示**确定一个图**（回忆：稀疏矩阵可以使用十字链表来存储）

### 邻接多重表

邻接多重表是**无向图**的一种链式存储方式，用于解决邻接表求**两顶点之间是否有边**、**删除边**等时**效率低问题**

与十字链表类似，在邻接多重表中，每条边用一个结点表示

![image-20210921164536570](..\images\image-20210921164536570.png)

1. mark 为标志域，可用以标记该条边是否被搜索过
2. ivex 和 jvex 为该边依附的两个顶点在图中的位置
3. ilink 指向下一条依附于顶点 ivex 的边
4. jlink 指向下一条依附于顶点 jvex 的边
5. info 为指向和边相关的各种信息的指针域

![image-20210921164902955](..\images\image-20210921164902955.png)

1. data 域存储该顶点的相关信息
2. firstedge 域指示第一条依附于该顶点的边

邻接多重表中，顶点表和邻接表的一样，但在邻接多重表中，**每条边同时连接在两个链表中**，令邻接多重表**同一条边只有一个结点**

![image-20210921165002757](..\images\image-20210921165002757.png)

### 图的基本操作

图的基本操作是**独立于图的存储结构**的，而对于不同的存储方式，操作算法的具体实现会有着不同的性能，在设计具体算法的实现时，应考虑采用何种存储方式的算法效率会更高

```c
Adjacent(G, x, y);  // 判断图是否有边 (x, y) 或 <x, y>
Neighbors(G, x);  // 列出图 G 中与顶点 x 邻接的边
InsertVertex(G, x);  // 在图 G 中插入顶点 x
DeleteVertex(G, x);  // 在图 G 中删除顶点 x
AddEdge(G, x, y);  // 若边不存在，则在 G 中添加边
RemoveEdge(G, x, y);  // 若边存在则删除边
FirstNeighbor(G, x);  // 求图 G 中顶点 x 的第一个邻接点，若有返回顶点号，没有返回 -1
NextNeighbor(G, x, y);  // y 是 x 的一个邻接点，返回 x 中 y 的下一个邻接点，没有返回 -1
Get_edge_value(G, x, y);  // 获取图 G 中边的权值
Set_edge_value(G, x, y, v);  // 设置图 G 中边的权值
......;  // 此外还有遍历算法等
```

## 图的遍历

图的遍历是指从图中的**某一顶点出发**，按照某种搜索方式沿着途中的边**对图中所有顶点访问一次且仅访问一次**

树是一种特殊的图，**树的遍历**也可以看做是一种**特殊的图的遍历**；<u>图的遍历操作是许多操作的基础</u>

图的遍历主要有两种算法：**广度优先搜索**和**深度优先搜索**

注意：基于**邻接矩阵**的遍历所得到的 **DFS 序列和 BFS 序列是唯一**的，基于**邻接表**的遍历所得到的 **DFS 序列和 BFS 序列是不唯一**的，因为图的邻接矩阵表示是唯一的，而图的邻接表表示是不唯一的

选择题：图的**广度优先生成树**的树高比**深度优先生成树**的树高**小或相等**。**广度优先**生成树是所有生成树中**树高最小**的

### 广度优先遍历

#### 广度优先的概念

广度优先搜索（Breadth-First-Search，BFS）类似于二叉树的**层序遍历**算法

它的基本思想是：广度优先搜索总是**按照距离由近到远**来**遍历图中每个顶点**

对于连通图的操作，如果非连通还要对每个连通分量都遍历：

1. 根结点入队
2. 出队结点，把它未访问过的邻接点都入队
3. 重复第二步，直到队列为空

类似的思想还将应用于 Dijkstra 单源最短路径算法和 prime 最小生成树算法

图的**广度优先搜索**过程与二叉树的**层序遍历**过程是**完全一致**的，说明图的广度优先是二叉树的层序遍历的扩展

广度优先搜索是一种**分层的查找过程**，为实现逐层的访问，算法必须**借助一个辅助队列**，记忆正在访问的顶点的下一层顶点

![a2c7c61edcadffeed85c10f53f1c988c](..\images\a2c7c61edcadffeed85c10f53f1c988c.gif)

```c
#define MaxVertexNum 100
void BFSTraverse(Graph G) {
    for (int i = 0; i < G.vexnum; i++)  // 初始化访问标志
        visited[i] = false;
    InitQueue(Q);
    for (int i = 0; i < G.vexnum; i++)  // 从 0 号顶点开始遍历
        if (!visited[i])  // 对没有访问过的进行一次广度优先
            BFS(G, i);
}

void BFS(Graph G, int v) {
    visit(v);  // 访问点
    visited[V] = true;  // 访问标志设置为以访问
    EnQueue(Q, v);  // 根结点入轨，开始迭代
    while (!isEmpty(Q)) {
        Dequeue(Q, v);
        // 对还没有被访问的顶点的邻接顶点进行访问
        for (w = FirstNeighbor(G, v); w >= 0; w = NextNeighbor(G, v, w))
            if (!visited[w]) {
                visit(w);
                visited[w] = true;
                EnQueue(Q, w);  // 对顶点入列，等待下次访问
            }
    }
}
```

#### BFS 复杂度分析

无论哪种存储方式，BFS 算法都需要借助一个辅助队列 Q，n 个顶点均需入队一次，在最坏的情况下，**空间复杂度为 $O(|V|)$**

当采用**邻接表存储方式**时，每个顶点均需要搜索一次（或者入队一次）故时间复杂度为 $O(|V|)$，在搜索任意一顶点的临接点时，每条边需要访问一次，故时间复杂度为 $O(|E|)$，算法的**总时间复杂度为 $O(|V|+|E|)$**

当采用**邻接矩阵存储方式**时，查找每个顶点的临接点所需的时间为$O(|V|)$，故算法的**时间复杂度为$O(|V|^2)$**

#### BFS 求解单源最短路径

如果图 G = (V, E) 为**非带权图**，定义从顶点 u 到顶点 v 的**最短路径** d(u, v) 为从 u 到 v 的任何**路径中最少的边数**；如果没有通路，则为 d(u, v) = $\infty$

利用<u>广度优先搜索总是按照距离由近到远来遍历图中每个顶点</u>的性质，求解满足上述定义的非带权路径的单源最短路径问题

```c
void BFS_MIN_Distance(Graph G, int u) {
    for(int i = 0; i < G.vexnum; i++)  // 初始化路径长度
        d[i] = INT_MAX;
    visited[u] = true;
    d[u] = 0;  // 设置根结点的距离为 0
    EnQueue(Q, u);
    while (!IsEmpty(Q)) {
        DeQueue(Q, u);
        for (w = FirstNeighbor(G, u); w >= 0; w = NextNeighbor(G, u, w)) {
            if (!visited[w]) {
                visited[w] = true;
                d[w] = d[u] + 1;  // 设置下一个结点的路径长度为当前路径长度 + 1
                EnQueue(Q, w);
            }
        }
    }
}
```

#### 广度优先生成树和森林

在**广度优先的过程中**，我们可以**得到一棵遍历树**，称为**广度优先生成树**

对**连通图**调用 BFS 才能产生广度优先生成**树**，**非连通图**的广度优先生成**森林**

把广度优先遍历时的未访问的邻接点变成自己的子树，或者把广度优先遍历时没使用的边全删去，森林类似

注意：**邻接矩阵**存储的**广度优先生成树是唯一**的，但**邻接表**存储的**广度优先生成树不是唯一**的，但存储结构固定时（若邻接表已经固定了，即给出了）生成树也固定；对于深度优先也一样

![image-20210921205817463](..\images\image-20210921205817463.png)

### 深度优先遍历

#### 深度优先的概念

深度优先搜索（Depth-First-Search，DFS）类似于树的**先序遍历**

正如其名称中所暗含的意思一样，这种搜索算法所遵循的策略是**尽可能“深”的搜索一个图**

对于连通图的操作，如果非连通还要对每个连通分量都遍历：

1. 访问自己，设置以访问标识
2. 对每个未访问过的邻接结点都进行深度优先搜索，即进行第一步

它的基本思想如下：从初始结点开始扩展，扩展顺序总是先扩展最新产生的结点

![e1e6a44251b69cd3b930f3071a71ffd8](..\images\e1e6a44251b69cd3b930f3071a71ffd8.gif)

```c
#define MAX_VERTEX_NUM 100
bool visited[MAX_VERTEX_NUM];
void DFSTraverse(Graph G) {
    for (v = 0; v < G.vexnum; i++)  // 初始化标志
        visited[v] = false;
    
    for (v = 0; v < G.vexnum; i++)  // 非连通图需要遍历每个连通分量
        if (!visited[v])
            DFS(G, v);
}
void DFS(Graph G, int v) {
    visit(v);
    visited[v] = true;
    for (w = FirstNeighbor(G, v); w >= 0; w = NextNeighor(G, v, w))  // 遍历未被访问的邻接点
        if (!visited[w])
            DFS(G, w);
}
```

非递归的代码，与上面的那副动图差不多：

```c
void DFS(MGraph &G, int v) {
    int w;
    InitStack(S);
    for (int i = 1; i < G.vexnum; i++) 
        visited[i] = false;
    visited[v] = true;
    Push(S, v);
    while (!IsEmpty(S)) {
        k = Pop(S);  // 出栈
        visit(k);  // 访问
        for (w = FirstNeighbor(G, k); w >= 0; w = NextNeighbor(G, k, w))  // 把它未访问的邻接点入栈
            if (!visited[w]){
                Push(S, w);
                visited[w] = true;
            }
    }
}
```

#### DFS 算法性能分析

DFS 算法是一个递归算法，需要借助一个递归工作栈，故它的**空间复杂度为 O(|V|)**

遍历图的过程实质上是对**每个顶点查找其邻接点的过程**，其耗费的时间取决于所采用的存储结构

当以**邻接矩阵**表示时，查找每个顶点的临接点所需时间为 O(|V|)，故总的**时间复杂度为 $O(|V|^2)$**

当以**邻接表**表示时，查找所有顶点的临接点所需时间为 O(|E|)，访问顶点所需时间为 O(|V|)，总的**时间复杂度为 O(|V|+|E|)**

#### 深度优先生成树和森林

在**深度优先的过程中**，我们可以**得到一棵遍历树**，称为**深度优先生成树**

对**连通图**调用 DFS 才能产生深度优先生成**树**，**非连通图**的深度优先生成**森林**

把深度优先遍历时的未访问的邻接点变成自己的子树，或者把深度优先遍历时没使用的边全删去

注意：与广度优先类似，邻接表存储的生成树不是唯一的

![image-20210921224347887](..\images\image-20210921224347887.png)

#### 深度优先进行逆拓扑排序

描述：使用 DFS 算法递归地遍历一个**无环有向图**，并在**退出递归时输出相应顶点**，这样得到的顶点序列是**逆拓扑排序**

证明：

无环有向图都是由三种情况构成：

1. A 指向 B，B 指向 C，这种明显符合描述
2. A 指向 B、C 以及 B、C 都指向 D，进行深度优先遍历会有 `A->B->D,回A->C` 那么输出是 `DBCA` 符合描述
3. A、B 指向 C，进行深度优先遍历会有 `A->C 转 B` 那么输出的是 `CAB` 符合描述

所有的有向无环图都是由这三种情况构成的，所以每个有向无环图都符合描述

把局部看成一个点的整体符合，局部也符合，所以就整幅图也符合，简单的递归思想

也可以换种思想：**深度优先先访问的结点一定是后访问结点的父亲**，根据这一特性先输出后访问结点就是逆拓扑排序

#### 深度优先判断是否是树

题目：试设计一个算法，判断一个无向图 G 是否为一棵树。若是一棵树，则算法返回 true，否则返回 false

思路：若是一棵树，则从一点开始遍历，可以遍历所有顶点，且只有 n - 1 条边（广度优先也可以实现）

```c
bool isTree(Graph& G) {
    for(i = l; i <= G.vexnum; i++)
        visited[i] = false;
    int Vnum = 0, Enum = 0;
    DFS (G, 1, Vnum, Enum, visited);
    
    if (Vnum == G.vexnum && Enum == 2 * (G.vexnum - 1))  // 符合条件
	    return true;
    else
    	return false;
}

void DFS (Graph& G, int v, int& Vnum, int& Enum, int visited[]) {
    visited[v] = true;
    Vnum++;  // 记录顶点
    int w = FirstNeighbor(G, v);
    while(w != -1) {
        Enum++;  // 记录边
        if(!visited[w])
        	DFS(G, w, Vnum, Enum, visited);
        w = NextNeighbor(G, v, w);
    }
}
```

#### 两顶点间的所有简单路径

题目：假设图用邻接表表示，设计一个算法，输出从顶点 $V_1$ 到 $V_2$ 的所有简单路径

思路：从 $V_1$ 开始把每条路径都走一下，中间不能有环，如果达到 $V_2$ 就输出走的路径

```c
void FindPath(AGraph *G, int u, int v, int path[], int d) {
    path[d] = u;
    visited[u] = 1;  // 这条路暂时被我占用了，直到我离开
    if (u == v)  // 打印路径
        for (int i = 0; i <= d; i++)
            printf("%d ", path[i]);
    else {
        ArcNode *p = G -> adjlist[u].firstarc;
        while (p != NULL) {
            w = p -> adjvex;
            if (visited[w] == 0)  // 因为不能有环，每次只能有一个人占用
                FindPath(G, w, v, path, d + 1);
            p = p -> nextarc;
        }
    }
    // 释放路径的使用权，当我从这条路离开后，别人走这里就不会形成环
    visited[u] = 0;
}
```

#### 判断图是否有环

深度优先遍历可以判断图 G 中是否存在回路，在深度优先时，只要出现回边就有环，利用[上面的思想](#两顶点间的所有简单路径)

下面代码主要说明深度优先可以实现判断图是否有回路，并不是最优解

```c
// 判断有向图是否有环，如果是无向图要多判断不是父母
bool Loop(AGraph *G, int u, int v) {
    visited[u] = 1;  // 声名路径已被使用
    ArcNode *p = G -> adjlist[u].firstarc;
    while (p != NULL) {
        w = p -> adjvex;
        if (visited[w] == 1 || Loop(G, w, v,))  // 有环
            return true;
        p = p -> nextarc;
    }
    // 释放路径的使用权，别人再用就不会形成环
    visited[u] = 0;
    return false;
}
```

### 图的遍历与图的连通性

<u>图的遍历可以用来判断图的连通性</u>

对于**无向图**来说，若是**连通**的**一次遍历**就可以遍历所有顶点；若是**非连通**的，就需要**遍历每一个连通分量**

对于**有向图**来说，若从**初始点到图中的每个顶点都有路径**，则能够访问到图中的所有顶点，否则不能访问到所有顶点

因此在 BFS 或 DFS 外套一层循环，再次选取初始点，保证每个点都会被遍历

对于**无向图**，**遍历函数的调用次数**等于该**图的连通分量数**；但对于**有向图**，<u>**非强连通分量**调用遍历函数无法访问该连通分量的所有顶点</u>，如 <a, b>，<b, c> 从 B 开始要两次，而从 A 开始却只需要一次，所以非强连通时无法知道遍历函数调用次数

## 图的应用

### 最小生成树

#### 最小生成树的定义

一个连通**图的生成树**是图的极小连通子图，它**包含图中所有顶点**，并且只**包含极可能少的边**

这意味着对于生成树来说，若**砍去它的一条边**，就会是生成树**变成非连通图**；若给它**增加一条边**，就会**形成一条回路**

对于一个带权连通无向图 G = (V, E)，**生成树不同**，**但每棵树的权**，即树中所有边上的权值之和，**也可能相同**

设 R 为 G 的所有生成树的集合，若 T 为 R 中边的**权值之和最小的那棵生成树**，则称 T 为 G 的**最小生成树**（Minimum-Spaning-Tree，MST）

不难看出，最小生成树具有如下性质：

1. **最小生成树不是唯一**的，即最小生成树的树形不唯一，R 中可能有多个最小生成树

   当图 G 中**<u>任意环</u>中各边权值互不相等**时，G 的**最小生成树是唯一的**

   若无向连通图 G 的边比顶点数少 1，即 <u>G 本身就是一棵树，G 的最小生成树就是其本身</u>

2. 最小生成树的边的权值之和总是唯一的，虽然**最小生成树不唯一**，但其对应的**边的权值之和唯一且最小**

3. 最小生成树的边数为顶点数减 1

#### Prim 算法（稠密图）

1. 随意选一个点，开始建立该点和其他点的路径长度关系，没有路径的话设置一个 $\infty$
2. 在路径的集合里面寻找最短的路径，并拿到路径的终点，将这个点加到该点集之中
3. 更新一下新的点集到其余点的路径，这里是直接用新结点的邻接路径大小更新
4. 重复操作，直到生成一棵树，这棵树就是最小生成树

![image-20210923163402417](..\images\image-20210923163402417.png)

Prim 算法的**时间复杂度是 $O(|V|^2)$**，不依赖于 |E|，适用于**边稠密的图**的最小生成树

#### Kruskal 算法（稀疏图）

1. 按照路径的长度进行从小到大的排序，排序完毕之后，设边集合为 E
2. 从 E 中选出最小的一条边，检测是否形成环，没有就添加进树，最后把边从 E 里删去
3. 重复操作，直到生成一棵树，这棵树就是最小生成树

![image-20210923165217777](..\images\image-20210923165217777.png)

在 Kruskal 里面，使用堆这种**优先队列**来取最小权重边，它的出队是 $O(\log|E|)$

还会使用一个**并查集来判断是否有环**，最坏情况时每条边都要迭代，故**时间复杂度是 $O(|E|\log|E|)$**

Kruskal 算法适合于**边稀疏而顶点较多**的图；维基百科说时间复杂度为 $O(|E|\log|V|)$

#### 破圈法

指任取一圈，去掉圈上权最大的边，反复执行这一步骤，直到没有圈为止

![image-20210924190638413](..\images\image-20210924190638413.png)

现在证明它必定会生成最小生成树：

使用反证法，设破圈法生成树 T 不是一个最小生成树，则必存在最小生成树 $T_0$

将 $T_0$ 与 T 求并集，得到一张图，此图中必定存在回路

由于 $T_0$ 是最小生成树，所以图中回路的最大权边不是来之与它的；因为选择大权边就删小权边，这样树权变大了

而 T 是使用破圈法生成的，所以图中回路的最大权边不是来之与它的

出现矛盾，所以 T 必定是最小生成树

### 最短路径

当图是带权图时，把从一个顶点 $v_0$ 到图中其余任意一个顶点 $v_i$ 的一条路径所经过边上的权值之和，定义为该路径的**带权路径长度**，把**带权路径长度最短**的那条路径称为**最短路径**

#### Dijkstra 算法

而 Dijkstra 的思想与 Prim 类似，只是它计算的是，从某点开始到其他点花费的最小代价

在构造过程中设置了两个辅助数组：

1. dist[]：记录从源点 $v_0$ 到其他各顶点当前的**最短路径长度**，可到达则为路径长度，不可到达则为 $\infty$
2. path[]：path[i] 表示从源点到顶点 i 之间的最近路径的**前驱结点**

Dijkstra 算法步骤如下：

1. 初始化，设置源点和其邻接点路径长度在 dist 数组上，并在 path 设置它的前驱是源点
2. 从 dist 弹出最小数值的顶点 $v_j$，它就是 $v_0$ 到 $v_j$ 的最短距离
3. 拿 $v_j$ 的邻接点在 dist 数组进行检测，如果小于就更新，并在 path 更新它的前驱为 j
4. 重复 2、3 步，直到所有顶点都包含进去

![73042284-9e01ea00-3e9b-11ea-89c8-d51623f3582c](..\images\73042284-9e01ea00-3e9b-11ea-89c8-d51623f3582c.gif)

由于需要遍历 dist 数组，使用邻接表还是邻接矩阵，它的**时间复杂度是 $O(|V|^2)$**

<img src="..\images\image-20220525144422103.png" alt="image-20220525144422103" style="zoom:125%;" />

注意：**Dijkstra 不适合用于带负权的图**，若要处理带负权的图可以使用 Bellman-Ford

#### Floyd 算法

Floyd 用于求**各顶点之间最短路径**的问题

Floyd 算法的基本思想是：递推产生一个 n 阶方阵序列 $A^{(-1)},\cdots,A^{(n-1)}$，其中 $A^{(k)}[i][j]$ 表示从 $v_i$ 到顶点 $v_j$ 的路径长度，k 表示绕行第 k 个顶点的运算步骤

如 $A^{(0)}[i][j]$ 是从顶点 $v_i$ 到 $v_j$，中间顶点是 $v_0$ 的最短路径的长度；$A^{(1)}$ 是中间顶点是 $v_0,v_1$ 的最短路径

Floyd 算法是一个迭代的过程，每迭代一次，在从 $v_i$ 到 $v_j$ 的最短路径上就<u>多考虑了一个顶点</u>

经过 n 次迭代后，所得到的 $A^{(n-1)}[i][j]$ 就是 $v_i$ 到 $v_j$ 的最短路径长度，即方阵 $A^{(n-1)}$ 中保存了任一对顶点之间的最短路径长度

```c
void Floyd(WItem **c, int **path, Graph G) {
    /* 初始化c[i][j] */
    for (int i = 1; i <= G->n; i++)
        for (int j = 1; j <= G->n; j++) {
            c[i][j] = G->a[i][j];
            path[i][j] = 0;
        }
    for (int i = 1; i <= G->n; i++)c[i][i] = 0;
    /* 循环计算c[i][j] 的值 */
    for (int k = 1; k <= G->n; k++)
        for (int i = 1; i <= G->n; i++)
            for (int j = 1; j <= G->n; j++) {
                // t1 + t2 表示：先到 k 再从 k 到 j，t1 + t2 < t3 表示中转比直接走小
                WItem t1 = c[i][k], t2 = c[k][j], t3 = c[i][j];
                if (t1 != G->NoEdge && t2 != G->NoEdge && (t3 == G->NoEdge || t1 + t2 < t3)) {
                    c[i][j] = t1 + t2;
                    path[i][j] = k;
                }
            }
}
```

Floyd 算法的**时间复杂度为 $O(|V|^3)$，**它**允许图中有带负权的边**，但**不允许有包含带负权值的边组成的回路**

也可以轮流使用 Dijkstra  算法来求最短路径，但就不能有负权边，时间复杂度为 $O(|V^2|)·|V|=O(|V^3|)$

### 有向无环图描述表达式

有向无环图：若一个**有向图中不存在环**，则称为**有向无环图**，简称 **DAG 图**

有向无环图是**描述含有公共子式的有效工具**，如表达式 `((a+b)*(b*(c+d))+(c+d)*e)*((c+d)*e)`

使用二叉树表示就会发现，有一些相同的子式它们重复出现；若利用有向无环图，则可实现对相同子式共享

**注意：共享后，每个相同的元素只会出现一次，表达式也好，里面的字母也好**



![image-20210923194532091](..\images\image-20210923194532091.png)

### 拓扑排序

#### AOV 网

AOV 网：如果用 **DAG 图表示一个工程**，**其顶点表示活动**，用有向边 <Vi, Vj> 表示**活动 $V_i$ 必须先于活动 $V_j$ 进行**的这样一种关系，则这种有向图称为顶点表示活动的网络记为 **AOV 网**

在 AOV 网中，活动 $V_i$ 是 $V_j$ 的直接前驱，活动 $V_j$ 是 $V_i$ 的直接后继，这种前驱和后继关系具有传递性，且任何活动 $V_i$ **不能以它自己作为自己的前驱或后继**

理解：AOV 网就是表示什么工作要先做，什么工作要后做，这么一种先后顺序的图，其中不能有环不然死循环

#### 拓扑排序

在图论中，由一个有向无环图的顶点组成的序列，当且仅当满足下列条件时，称为该图的一个拓扑排序

1. **每个顶点出现且只出现一次**
2. 若 **A 在序列中在 B 的前面**，则在图中**不存在 B 到 A 的路径**

对一个 AOV 网进行拓扑排序的算法很多，这里介绍常用的：

1. 从 DAG 图中**选择一个没有前驱的顶点并输出**
2. 从图中**删除该顶点和所有以它为起点的有向边**
3. 重复 1 和 2 直到当前的 **DAG 图为空**或当前图中**不存在无前驱的顶点（存在环）**为止

![image-20210923201402249](..\images\image-20210923201402249.png)

```c
bool TopologicalSort(MGraph G) {
    int i, w, count = 0;
    InitStack(S);  // 也可以用队列
    for (i = 0; i < G.vexnum; i++)  // 把入度为零的入栈
        if (indegree[i] == 0)
            Push(S, i);
    while (!IsEmpty(S)) {
        Pop(S, i);
        record[count++] = i;  // 输出
        // 将所有 i 指向的顶点入度减 1，然后将入度为 0 的入栈
        for (w = FirstNeighbor(G, i); w >= 0; w = NextNeighbor(G, i, w))
            if (!(--indegree[w]))
                Push(S, w);
    }
    if (count < G.vexnum)
        return false;  // 每迭代完顶点数有环排序失败
    else
        return true;
}
```

输出每个顶点同时要删除以它为起点的边，故采用邻接表的时间复杂度是 O(|V| + |E|)；邻接矩阵的时间复杂度是 $O(|V^2|)$

#### 逆拓扑排序

对一个 AOV 网，如果采用下列步骤进行排序，则称为逆拓扑排序：

1. 从 AOV 网中选择一个没有后继（出度为 0）的顶点并输出
2. 从网中删除该顶点和所有以它为终点的有向边
3. 重复 1 和 2 直到当前的 AOV 网为空

深度优先算法可以实现逆拓扑排序，具体：[深度优先进行逆拓扑排序](#深度优先进行逆拓扑排序)

#### 拓扑排序的处理 AOV 的注意

1. 入度为零的顶点，前面已经没东西做或做完了，过程可以从这个顶点所代表的活动开始或继续
2. **一个顶点有多个直接后继**，则拓扑排序的**结果通常不唯一**，但 <a, b>、<a, c>、<b, c> 这种情况结果依然唯一
3. 若各个顶点已经**排在一个线性有序的序列中**，每个顶点有**唯一的前驱后继关系**，则拓扑排序是**唯一**的
4. 若图的**邻接矩阵是三角矩阵**，则**存在拓扑排序**；但若图**可以拓扑排序**，它的邻接矩阵**不一定是三角矩阵**
5. 可以按拓扑排序的结果重新编号，生成 AOV 网的新的邻接存储矩阵，**由先到后编号是三角矩阵**
5. 若有向图的**顶点不能排在一个拓扑排序中**，则该图**一定有环**，即含有**顶点数大于 1 的强连通分量**

选择题：有向图具有**有序**的拓扑排序序列，则它的邻接矩阵必定为**三角矩阵**；因为无序编完号是有序的，矩阵是三角

选择题：即使有向无环图的**拓扑排序序列唯一**，也**不可以唯一确定该图**；如 ABC 也可以是 <a, b>、<a, c>、<b, c>

### 关键路径

#### 关键路径的定义

在带权有向图中，以**顶点表示事件**，**有向边表示活动**，边上的**权值**表示**完成活动需要的开销**，则这种图称为 **AOE 网**

**AOE 网具有以下两个性质**：

1. 只有在某顶点所代表的事件发生后，从该顶点出发的各有向边所代表的活动才可以进行
2. 只有在进入某一顶点的各有向边，所代表的活动都已经结束时，该顶点所代表的事件才可以发生

在 AOE 网中**仅有一个入度为 0 的顶点**，称为开始顶点（**源点**），它表示整个工程的开始；网中也**仅存在一个出度为 0 的顶点**，称为结束顶点（**汇点**），它表示整个工程的结束

从源点到汇点的所有路径中，**具有最大路径长度的路径**称为**关键路径**，我们将**关键路径上的活动**称为**关键活动**

工程里面的最长路径意味着完成完这个路径，工程就完成了，因此关键路径是工程的最短完成时间

#### 参量的定义

##### 事件 $v_k$ 的最早发生时间 $ve(k)$

它是指从源点 $v_1$ 到 $v_k$ 的最长路径长度，也就是 $v_k$ 的**最早开工时间**，即**源点到 $v_k$ 的关键路径**

1. 初始时，令 ve[1...n] = 0
2. 使用拓扑排序，每一个点输出时，都更新它的直接后继的最早发生时间
3. 更新方法：若 $ve[j]+Weight(v_j,v_k)>ve[k]$，则 $ve[k]=ve[j]+Weight(v_j,v_k)$

##### 事件 $v_k$ 的最迟发生时间 vl(k)

它是指在**不推迟整个工程完成**的前提下，该**事件最迟必须发生的时间**，即**工程总时间减去 $v_k$ 到汇点的关键路径**

1. 初始时，令 vl[1...n] = ve[n]
2. 使用逆拓扑排序，每一个点输出时，都更新它的直接前驱的最迟发生时间
3. 更新方法：若 $vl[j]-Weight(v_j,v_k)<vl[k]$，则 $vl[k]=vl[j]-Weight(v_j,v_k)$

##### 活动 $a_i$ 最早开始时间 e(i)

它是指该活动的起点所表示的事件最早发生时间

即该**活动最早的开始时间**，活动就是边

若边 $<v_k,v_j>$ 表示活动 $a_i$，则有 e(i) = ve(k)

##### 活动 $a_i$ 最迟开始时间 l(i)

它是指该<u>活动的终点所表示的事件最迟发生时间与该活动所需时间之差</u>

即该**活动最迟要什么时候执行，才不会推迟工程**

若边 $<v_k,v_j>$ 表示活动 $a_i$，则有 $l(i)=vl(j)-Weight(v_k,v_j)$

##### 活动 $a_i$ 的 l(i) 与 e(i) 的差 d(i)

**一个活动 $a_i$ 的最迟开始时间 l(i) 和其最早开始时间 e(i) 的差额 d(i) = l(i) − e(i)**

指该活动完成的**时间余量**，即不增加整个工程所需的总时间的情况下，活动 $a_i$ 可以拖延的时间

如果一个活动的**时间余量为 0** 时，说明该**活动必须要如期完成**，否则就会拖延完成整个工程的进度

所以称 l(i) − e(i) = 0，即 l(i) = e(i) 的活动 $a_i$ 是**关键活动**

#### 求关键路径的步骤

![image-20210924151526828](..\images\image-20210924151526828.png)

1. 从源点出发，令 ve(源点) = 0，按拓扑排序求最早发生时间 ve()
2. 从汇点出发，令 vl(汇点) = ve(汇点)，按逆拓扑排序求最迟发生时间 vl()
3. 根据各顶点的 ve() 值求所有弧的最早开始时间 e()
4. 根据各顶点的 vl() 值求所有弧的最迟开始时间 l()
5. 求 AOE 网中所有活动的差额 d()，找出所有 d() = 0 的活动构成关键路径

#### 关键路径的注意

1. **关键路径上的所有活动都是关键活动**，可以通过**加快关键活动来缩短整个工程的工期**
2. 但**不能任意缩短关键活动**，因为缩短太多，<u>关键活动可能变成非关键活动</u>
3. 对于**有几条关键路径的网**，<u>需要加快那些包括在所有关键路径上的关键活动</u>才能达到缩短工期的目的

#### 活动构造 AOE 网

下表给出了某工程各工序之间的优先关系和各工序所需的时间，其中 “一” 表示无先驱工序，请画出相应的 AOE 网

![image-20220515153330865](..\images\image-20220515153330865.png)

根据只有一个源点和一个汇点，没有先序工作的都是源点发出的，最后没有后序工作的都指向汇点

1. 找到没前边的边，创造源点，把这些边画出来
2. 遍历边，把边画出来，画的时候两条边中间没有点，就在两边中间创造点
3. 最后创造汇点，把没有指向的边都指向汇点

![image-20220515160847932](..\images\image-20220515160847932.png)

生成的图如上：

1. 创建源点 `V1` 并加入 A、B 两边
2. 添加 C 时创建 `V2`；添加 D
3. 添加 E 时创建 `V3`；添加 F
4. 添加 G 时创建 `V4` 把 C、E 连接到 `V4`
5. 添加 H 时创建 `V5`
6. 最后创建汇点 `V6` 把 H、G、F 连接到汇点

# 查找

## 查找的基本概念

* 查找：**在数据集合中寻找满足某种条件的数据元素的过程**称为查找

  查找结果分为两种：一是**查找成功**，即在数据集合中找到了满足条件的数据元素；二是**查找失败**

* 查找表：**用于查找的数据集合**称为查找表，由同一类型的数据元素组成，可以是数组、链表等数据类型

  对查找表经常进行的操作一般有 4 种：

  1. 查询某个特定的数据元素是否在查找表中
  2. 检索满足条件的某个特定的数据元素的各种属性
  3. 在查找表中插入一个数据元素
  4. 从查找表中删除某个数据元素

* 静态查找表：若一个查找表的操作只涉及上述操作 1 和 2，则**无须动态地修改查找表**，此类查找表称为**静态查找表**

  与此对应，**需要动态地插入或删除的查找表**称为**动态查找表**

  适合静态查找表的查找方法有顺序查找、折半查找、散列查找等

  适合动态查找表的查找方法有二叉排序树的查找、散列查找等

* 关键字：**数据元素中唯一标识该元素的某个数据项的值**，使用基于关键字的查找，查找结果应该是唯一的

* 平均查找长度：在查找过程中，一次查找的长度是指**需要比较的关键字次数**

  平均查找长度则是**所有查找过程中进行关键字的比较次数的平均值**，其数学定义为 $ASL=\displaystyle\sum^n_{i=1}P_iC_i$

  其中 n 是查找表的长度；$P_i$ 是查找第 i 个数据元素的概率，一般认为每个数据元素的查找概率相等，即 $P_i=1/n$；$C_i$ 是找到第 i 个数据元素所需进行的比较次数

  **平均查找长度是衡量查找算法效率的最主要的指标**

## 顺序查找和折半查找

### 顺序操作

#### 一般线性表的顺序查找

其基本思想是从线性表的一端开始，逐个检查关键字是否满足给定的条件

若查找到某个元素的关键字满足给定条件，则查找成功，返回该元素在线性表中的位置

若已经查找到表的另一端，但还没有查找到符合给定条件的元素，则返回查找失败的信息

```c
typedef struct {
    ElemType *elem;  // 从 1 开始存储
    int TableLen;  // 表的长度
} SSTable;

int Search_Seq(SSTable ST, ElemType key){
    ST.elem[0] = key;  // 哨兵，让查找不到时返回 0
    for(i = ST.TableLen; ST.elem[i] != key; --i);  // 从后向前查找
    return i;
}
```

对于有 n 个元素的表，定位第 i 个元素时，需进行 n - i + 1 次关键字的比较，即 $C_i$ = n - i + 1

查找成功时，平均长度为 $ASL_{成功}=\displaystyle\sum^n_{i=1}P_i(n-i+1)$ 当每个元素的查找概率相等，即 $P_i=\dfrac{1}{n}$ **有 $ASL_{成功}=\dfrac{n+1}{2}$**

查找不成功时，与表中各关键字的比较次数显然是 n + 1 次，从而顺序**查找不成功的平均查找长度为 $ASL_{不成功} = n + 1$**

通常查找表中记录的查找概率并不相等，**若能预先得知查找概率**，则应先对查找概率进行排序，**按查找概率由大至小排列**

顺序查找的**缺点是当 n 较大时**，平均查找长度较大，**效率低**；**优点是对数据元素的存储没有要求**，顺序存储或链式存储皆可。对表中记录的有序性也没有要求，无论记录是否按关键字有序，均可应用

注意：对线性的**链表只能进行顺序查找**

#### 有序表的顺序查找

若在查找之前就已经知道表是关键字有序的，则**查找失败时可以不用再比较到表的另一端就能返回查找失败的信息**，从而降低顺序查找失败的平均查找长度

查找思路：<u>假设表是按关键字从小到大排列，查找顺序是从前往后，现在要查找 key，当第 i 个元素大于 key 就可返回失败信息，因为第 i 即其以后的元素都大于 key，所以表中不存在 key</u>

![image-20210925135211271](..\images\image-20210925135211271.png)

树中的圆形结点表示有序顺序表中存在的元素；树中的矩形结点称为失败结点，有 n + 1 个查找失败结点

在有序表的顺序查找中，**查找成功的平均查找长度和一般线性表的顺序查找一样**

查找失败时，到达失败结点时所查找的长度等于它上面的一个圆形结点的所在层数

**查找不成功的平均查找长度**在相等查找概率的情形下为 $ASL_{不成功}=\displaystyle\sum^n_{j=1}q_j(l_j-1)=\dfrac{1+\cdots+n+n}{n+1}=\dfrac{n}{2}+\dfrac{n}{n+1}$

其中，$q_j$ 是到达第 j 个失败结点的概率，在相等查找概率的情形下，它为 1 / (n + 1)；$l_j$ 是第 j 个失败结点所在的层数

注意：有序表的顺序查找和折半查找的思想是不一样的，且有序表的顺序查找中的线性表**可以是链式存储结构**

### 折半查找

#### 折半查找的定义

折半查找又称二分查找，它**仅适用于有序的顺序表**，不适合于链式存储结构

折半查找的基本思想（对于升序顺序表）：

1. 从线性表的比较范围取中间元素与 key 比较
2. 若相等，查找成功
3. 若小于，把线性表的比较范围设置为前半部分
4. 若大于，把线性表的比较范围设置为后半部分
5. 重复，直到找到或者表范围为空为止

```c
int Binary_Search(SeqList L, ElemType key){
    int low = 0, high = L.TableLen - 1, mid;  // low，hign 定义表范围
    while (low <= high) {  // 表范围里面有元素
        mid = (low + high) / 2;  // 取中间位置
        if (L.elem[mid] == key)
            return mid;  // 查找成功则返回所在位置
        else if (L.elem[mid] > key)
            high = mid - 1;  // 从前半部分继续查找
        else
            low = mid + 1;  // 从后半部分继续查找
    }
    return -1;  // 查找失败，返回 -1
}
```

#### 折半查找的判定树

**折半查找的<u>过程</u>**可用二叉树排序树来描述，称为判定树

树中每个圆形结点表示一个记录，它的值为该记录的关键字值；树中最下面的叶结点都是方形的，它表示查找不成功的情况

折半查找取中可以是 $\lfloor (low+hign)/2\rfloor$ 或 $\lceil(low+hign)/2\rceil$ 这两种得出的**判别树是不同的**；**前者右子树结点数必须大于等于左子树结点数且最多大一**，而**后者相反**，下图的树是向下取整的树

从判定树可以看出，**查找成功**时的查找长度为**从根结点到目的结点的路径上的结点数**

**查找不成功**时的查找长度为**从根结点到对应失败结点的父结点的路径上的结点数**

若有序序列有 n 个元素，则对应的判定树有 n 个圆形的非叶结点和 n + 1 个方形的叶结点

![image-20210925135247169](..\images\image-20210925135247169.png)

判定树是一棵**平衡二叉树**，用折半查找法查找到给定值的比较次数最多不会超过树的高度

**折半查找的不存在的元素最少比较次数和最大比较次数差不会超过 1**，故它的判定树内的叶结点的**深度差不会超过 1**

等概率查找时，**查找成功的平均查找长度**为<br> $ASL=\dfrac{1}{n}\displaystyle\sum^n_{i=1}l_i=\dfrac{1}{n}(1\times1+\cdots+h\times2^{h-1})=\dfrac{n+1}{n}\log_2(n+1)-1\approx\log_2(n+1)-1$

其中 h 是树的高度且元素个数为 n 时判定**树高 $h=⌈\log_2(n+1)⌉$**；**折半查找的最大比较次数为树高，最小比较次数为树高减 1**

- 因为 $2^{h}-1$ 结点的树高为 h，且在 $2^{h-1}\sim 2^{h}-1$ 个结点时树高是 h 所以，树高为 $\lceil\log_2(n+1)\rceil$ 

所以折半查找的时间复杂度为 $O(\log_2n)$，**平均情况**下比顺序查找的效率高

折半查找法**仅适合于顺序存储结构**，**不适合于链式存储结构**，且**要求元素按关键字有序排列**

选择题：<u>求二分法的**平均查找长度**不要套公式</u>，要**画出其判定树**，然后**使用它的查找的平均查找长度的求法**

### 分块查找

**分块查找又称索引顺序查找**，它吸取了顺序查找和折半查找各自的优点，既有动态结构，又适合快速查找

分块查找的基本思想是：

1. 将查找表分为若干子块
2. 块内的元素可以无序，但**块之间是有序**的，如块一的元素小于块二等
3. 建立一个索引表，索引表中的每个元素含有各块的最大关键字和各块中的第一个元素的地址，**索引表按关键字有序排列**

分块查找的过程分为两步：

1. 在**索引表中确定待查记录所在的块**，可以顺序查找或折半查找索引表
2. 在**块内顺序查找**

**分块查找的平均查找长度为<u>索引查找</u>和<u>块内查找</u>的平均长度之和**，设索引查找和块内查找的平均查找长度分别为 $L_I$，$L_S$，则分块查找的平均查找长度为 $ASL=L_I+L_S$

![image-20210925141057262](..\images\image-20210925141057262.png)

将长度为 n 的查找表均匀地分为 b 块，每块有 s 个记录，在等概率情况下，若在块内和索引表中均采用顺序查找，则**平均查找长度为 $ASL=L_I+L_S=\dfrac{b+1}{2}+\dfrac{s+1}{2}=\dfrac{s^2+2s+n}{2s}$** 其中 $b=\dfrac{n}{s}$；若 $s=\sqrt n$，则**平均查找长度取<u>最小值</u> $\sqrt n+1$**

- 注意：计算平均查找长度使用 $ASL=\displaystyle\sum^n_{i=1}P_iC_i$ 来算，不要像上面那样拆成两个相加，上面那个是有条件的

若对**索引表采用折半查找**时，则**平均查找长度为 $ASL=L_I+L_S=\lceil\log_2(b+1)\rceil+\dfrac{s+1}{2}$**

## 树的查找

### 二叉排序树

#### 二叉排序树的定义

**二叉排序树**也称**二叉查找树**，是**一棵空树**，或者是**具有以下特性的二叉树**：

1. 若左子树非空，则左子树上所有结点的值均小于根结点的值
2. 若右子树非空，则右子树上所有结点的值均大于根结点的值
3. 左、右子树也分配为一棵二叉排序树

根据二叉树的定义有**左子树的值 < 根结点值 < 右子树的值**，所以对二叉排序树进行**中序遍历**就会得到一个**递增序列**

#### 二叉排序树的查找

二叉排序树**从根结点开始查找**，先**和根结点的值进行比较**，<u>相等则查找成功；小于就递归左子树；大于就递归右子树</u>

```c
BSTNode *BST_Search(BSTree T, int key) {
    while(T != NULL && key != T -> key) {
        if(key > T -> key) T = T -> rchild;
        else T = T -> lchild;
    }
    return T;
}
```

#### 二叉排序树的插入

二叉排序树作为一种**动态树表**，特点是树的结构不是一次生成的，而是**在查找过程中发现值不存在后的插入**

插入过程如下：

- 若原二叉树为空则直接插入结点
- 若关键字 k 小于根结点值，则插入左子树；否则插入到右子树

插入的点一定是一个**新添加的叶结点**，而且是查找失败时的**查找路径上最后访问结点的子结点**

```c
int BST_Insert(BSTree &T, int k){
    if (T == NULL) {
        T = (BSTNode*)malloc(sizeof(BSTNode));
        T -> key = k;
        T -> lchild = T -> rchild = NULL;
        return 1;  // 插入成功
    } else if (T -> key == k)
        return 0;  // 插入失败
    else if(key > T -> key)
        return BST_Insert(T -> rchild, key);  // key 比根结点的大插到右边
    else
        return BST_Insert(T -> lchild, key);  // key 比根结点的小插到左边
}
```

#### 二叉排序树的构造

二叉排序树的构造就是从一棵空树出发，依次输入元素，将它们插入二叉排序树中的合适位置

```c
void Creat_BST(BSTree &T, int str[], int n) {
    T = NULL;
    for(int i = 0; i < n; i++)
        BST_Insert(T, str[i]);
}
```

#### 二叉排序树的删除

二叉排序树的删除不是把以该结点为根的子树都删除，而是**仅删除该结点**，然后**调整二叉排序树**，使他仍是二叉排序树

删除操作的实现过程按 3 种情况来处理：

1. 若被删除结点 z 是叶结点，则直接删除，因为不会破坏二叉排序树的性质
2. 若结点 z 只有一棵子树，则让 z 的子树成为 z 的父结点的子树，代替 z 的位置
3. 若结点 z 有左右两棵子树，则令它的直接后继（或直接前驱）与 z 交换位置，这时再删除 z 情况就是第一步或第二步了

思考：二叉排序树中删除后再插入某结点，得到的二叉树取决于删除的位置，若删除的是**叶结点那么相同**，**否则不相同**

#### 二叉排序树的查找效率

二叉排序树的**查找效率**，**主要取决于树的高度**。二叉树的结点分布比较均匀像**平衡二叉树**那样，平均查找长度为 $O(\log_2n)$；但如果是一个**单支树**，则平均查找长度为 O(n)

在最坏情况下，即构造二叉排序树的**输入序列是有序的**，则会**形成一个倾斜的单支树**

在等概率情况下，**查找成功的平均查找长度**为 $(\displaystyle\sum_{i=1}^{deep}i\times num_i)/n$ 其中 deep 是总深度，$num_i$ 是第 i 层的结点数，n 是结点总数

在等概率情况下，**查找失败的平均查找长度**为 “($\displaystyle\sum$ NULL 的父亲的层数) / NULL 的个数”

- ![image-20220511165827701](..\images\image-20220511165827701.png)
- 查找成功的平均长度为：(1 + 2 × 2 + 3 × 4 + 4 × 3) / 10 = 2.9
- 查找失败的平均长度为：(3 × 5 + 4 × 6) / 11 = 39 / 11

从查找过程看，二叉排序树与二分查找相似，其平均时间性能差不多，但**二分查找的判定树唯一**，而**二叉排序树的查找不唯一**，相同的关键字其**插入顺序不同可能生成不同的二叉排序树**

维护表的有序性而言，**插入和删除**元素时，**二叉排序树平均执行时间**为 $O(\log_2n)$，而**有序顺序表**则需要 O(n)

所以，当有序表是**静态查找表**时，宜用**顺序表作为存储结构**；若有序表是**动态查找表**，则选择**二叉排序树作为逻辑结构**

### 平衡二叉树

#### 平衡二叉树的定义

避免树的高度增长过快，降低二叉排序树的性能，定义**平衡二叉树**，简称**平衡树**，它的**左右子树高度差的绝对值不超过 1**

结点**左子树与右子树的高度差**称为该结点的**平衡因子**，则平衡二叉树的平衡因子只可能是 -1、0、1

平衡二叉树可以定义为**一棵空树**，或具有以下性质的树：它的**左子树和右子树都是平衡二叉树**，且**左子树和右子树的高度差的绝对值不超过 1**

![image-20210920122745558](..\images\image-20210920122745558.png)

#### 平衡二叉树的旋转

##### 左旋转

左旋是在保持二叉排序树的规则下，令左边层数加一，右边层数减一，步骤为：

1. 设 r 是根，p 为根的右子树
2. r 的右子树变成 p 的左子树
3. p 的左子树变成 r
4. 根结点变成 p

![v2-db1cdb0da952a71f9b6d64b2608467eb_b](..\images\v2-db1cdb0da952a71f9b6d64b2608467eb_b.webp)

##### 右旋转

右旋是在保持二叉排序树的规则下，令右边层数加一，左边层数减一，步骤为：

1. 设 r 是根，p 是根的左子树
2. r 的左子树变成 p 的右子树
3. p 的右子树变成 r
4. 根结点变成 p

![v2-05246384c1c16537ca6176983bdb2627_b](..\images\v2-05246384c1c16537ca6176983bdb2627_b.webp)

#### 平衡二叉树的插入

在**插入或删除后**，检查是否导**致了平衡二叉树失衡**，若失衡就找到**距离插入点最近的失衡树**，**对它进行调整，使之平衡**

调整是递归的，从最小失衡树，即距离插入点最近的不平衡树，一直向上调整，**直到整棵树没有失衡点为止**

平衡二叉树的**插入部分和二叉查找树相同**，若插入后**不平衡需要调整**，则有**以下 4 条规律**：

1. LL 平衡旋转，当插入的点在失衡点的左子树的左子树内，以失衡点为轴进行右旋
2. RR 平衡旋转，当插入的点在失衡点的右子树的右子树内，以失衡点为轴进行左旋
3. LR 平衡旋转，当插入的点在失衡点的左子树的右子树内，以失衡点的左子树为轴进行左旋，旋转后变成情况 1
4. RL 平衡旋转，当插入的点在失衡点的右子树的左子树内，以失衡点的右子树为轴进行右旋，旋转后变成情况 2

```c
/**
 * 插入后进行调整
 * root : 根结点
 * p : 要调整的结点
 * d : 插入的数据
 */
void fixAfterInsert(btlink &root, btlink p, int d) {
    if (d < p -> element) {
        // 情况 3，在左边的右边
        if (d > p -> left -> element) rotateLeft(root, p -> left);
        // 情况 1，在左边的左边
        rotateRight(root, p);
    } else {
        // 情况 4，在右边的左边
        if (d < p -> right -> element) rotateRight(root, p -> right);
        // 情况 2，在右边的右边
        rotateLeft(root, p);
    }
}
```

插入点在哪里就意味着哪里的层数多加了一层导致失衡，所以要使用旋转把插入点的层数分一层给它兄弟，以达到平衡

LR 时左旋把左边的右边多出的一层给到左边的左边，这样就是左边的左边多层数，就是 LL 了；RL 同理

旋转只会让这个被旋转的最小失衡树平衡起来，但这个树的祖先仍然有可能会失衡，所以要递归上去检查和调整

#### 平衡二叉树的查找

平衡二叉树的查找过程与二叉排序树的相同，因此关键字比较的次数不超过树的深度

假设以 $n_h$ 表示深度为 h 的**平衡树中含有的最少结点数**，有 $n_0=0,n_1=1,n_2=2$ 并且**有** $n_h=n_{k-1}+n_{k-2}+1$

那么就有**平衡二叉树的最大深度**为 $O(\log_2n)$，因此**平衡二叉树的平均查找长度**为 $O(\log_2n)$，注意这里是有 O 的

#### 平衡二叉树的最少结点数

根据平衡二叉树的定义，它的左右子树都是平衡二叉树

自己是含有最少结点数，当且仅当<u>左右子树也是含有最小结点的情况下</u>

那么自己的结点数是左子树的结点 + 右子树的结点 + 1（根结点）

含有最小结点数，那么<u>左右子树的高度差必然为一</u>

综上就得出：

1. $n_k=n_{k-1}+n_{k-2}+1$，一个子树结点 + 另一个子树结点 + 1（根结点）
2. **非叶子结点的平衡因子的绝对值都为一**，那么这棵树是**含结点最少的平衡二叉树**（结点已经不能再少了）

### 红黑树

#### 红黑树的定义

红黑树与平衡二叉树的区别：

1. 红黑树放弃了追求完全平衡，追求大致平衡，在与平衡二叉树的时间复杂度相差不大的情况下，保证**每次插入最多只需要三次旋转就能达到平衡**，实现起来也更为简单

2. 平衡二叉树追求绝对平衡，条件比较苛刻，实现起来比较麻烦，每次插入新结点之后**需要旋转的次数不能预知**

一棵红黑树是满足如下红黑性质的**二叉排序树**：

1. 每个结点或是红色，或是黑色的
2. **根结点是黑色的**
3. **叶结点**（虚构的外部结点、**NULL 结点）都是黑色的**
4. **不存在两个相邻的红结点**（即红结点的父结点和孩子结点均是黑色的）
5. 对每个结点，从该结点到任一叶结点的简单路径上，**所含黑结点的数量相同**

与折半查找树和 B 树类似，为了便于对红黑树的实现和理解，引入了 n + 1 个**外部叶结点**，以保证红黑树中每个**内部结点的左、右孩子均非空**

![src=http___img2018.cnblogs.com_blog_1301290_201904_1301290-20190418213139526-1239863354.jpg&refer=http___img2018.cnblogs](..\images\src=http___img2018.cnblogs.com_blog_1301290_201904_1301290-20190418213139526-1239863354.jpg&refer=http___img2018.cnblogs.webp)

黑高 `bh`：从某结点出发（**不含该结点**）到达叶结点的**路径上的黑结点总数**，**根结点的黑高称为红黑树的黑高**

结论 1：**从根到叶结点的最长路径不大于最短路径的 2 倍**（任一结点左右子树的高度，相差不超过 2 倍）

- 根结点到每一个叶结点（NULL）经过黑色结点的总数是相同的，其次不会出现两个红色相邻的情况
- 因此红色结点最多和黑色结点一样多，即最小路径是全黑色，最长路径是黑红色一样多，故最多是两倍
- 如 90-60-80 与 90-120-140-126-130 就是这样的两条路径

结论 2：**有 n 个内部结点的红黑树的高度 $h≤2\log_2(n+ 1)$**

- 由结论 1 可知，从根到叶结点（不含叶结点）的任何一条简单路径上都至少有一半是黑结点
- 因此，根的黑高至少为 h/2，于是有 $n\geq 2^{h/2}-1\Rightarrow 2\log_2(n+1)\geq h$

对于一棵动态查找树，如果<u>插入和删除操作比较少，查找操作比较多，采用 AVL 树比较合适</u>，否则采用红黑树更合适

由于维护高度平衡所付出的代价比获得的效益大得多，红黑树的应用更广泛，C++ 中的 map 和 set 就是用红黑树实现的

#### 红黑树的插入

红黑树和二叉查找树的插入过程基本类似，但红黑树中插入新结点后需要进行调整以满足红黑树的性质

结论 3：**新插入红黑树中的结点初始着为红色**

- 若插入的结点初始着为黑色，则必比其他路径多出一个黑结点（必要调整），且调整起来也比较麻烦
- 若插入的结点是红色的，则仅在出现连续两个红结点时才需要调整，而且这种调整也比较简单

设结点 I 为新插入的结点，插入过程描述如下（注意：叶结点是 NULL 黑结点）：

1. 如果结点 I 是**根结点，将 I 着为黑色**，树的黑高增 1，结束

2. 用二叉查找树插入法插入，并将结点 I 着为红色。若结点 **I 的父结点是黑色的，结束**

3. 如果结点 I 不是根结点，并且 I 的父结点 `P` 是红色的，则分为下面两种情况

   根据父结点 `P` 是红色的，爷结点 `PP` 必然存在且为黑色（不妨假设 `P` 在 `PP` 的左边）

   情况 1：**叔结点是黑色**（父结点的兄弟结点），那就**把多出来的红色结点放入叔爷这两个黑色的之间**，就完成调整

   情况 2：**叔结点是红色**，这没地方放了，**向上看看有没有地方可以放这多余的结点**

   对情况 1 的处理，又分为两种可能：

   1. I 在 P 的右边，那么就以 P 为轴左旋，把插入结点设为 P 就变成可能 2
   2. I 在 P 的左边，`P` 变黑，`PP` 变红，以 `PP` 为轴右旋结束 （没有改变性质，又完成任务）

   ![2392382-fbfc4f299941cb8b](..\images\2392382-fbfc4f299941cb8b.webp?lastModify=1652777301)

   对情况 2 的处理：那么父亲和它邻居变黑，爷爷变红，指向爷爷继续迭代，直到把多余的红色解决掉为止

   ![2392382-9f2c746bf0769f49](..\images\2392382-9f2c746bf0769f49.webp?lastModify=1652781979)

若父结点 P 是爷结点 PP 的右孩子，则还有两种对称的情况；红黑树的调整方法和 AVL 的调整方法有异曲同工之秒

下面放个例子：

![2392382-f4c0891c264a2243](..\images\2392382-f4c0891c264a2243.webp?lastModify=1652782918)

#### 红黑树的删除

红黑树的删除操作容易造成**子树黑高的变化**，删除黑结点会导致根结点到叶结点间的黑结点数量减少

删除过程也是先执行二叉查找树的删除方法：有两个孩子时**用中序后继代替本结点**，然后转换为删除该后继结点

最终，删除一个结点转换为以下两种情况：

- 待删结点没有孩子，替补为 NULL
- 待删结点只有右子树或左子树，替补为子结点

思考：红黑树中**任意黑色非空结点都有非空的邻居，若邻居为红色，则它必有两个黑色的孩子**

- 根据性质 5，若黑色结点邻居是空结点（叶结点），那么根节结点到本结点下的叶结点与到隔壁的叶结点黑色数量不同

定义：双黑结点：**删除的结点是黑色的，替换的结点也是黑色的**（和下面关系不大）

可能出现的情况为（再次强调：**叶结点是黑色且为 NULL**，且删除的必定是儿子为两叶结点或单叶结点的结点）：

1. 删除的是黑色替补是红色或删除的是红色，邻居的就没关系了
2. 删除的是黑色且替补是黑色或没有，邻居是黑色，一个黑儿子（或没有黑儿子）
3. 删除的是黑色且替补是黑色或没有，邻居是黑色，两个黑儿子
4. 删除的是黑色且替补是黑色或没有，邻居是红色，且两个黑儿子

对上面的四个情况进行处理：1 和 2 会拿红色结点转黑色来填充回去，完成删除的调整工作；3 和 4 要向上迭代：

1. **删除是红色**直接删，替补补上没影响；**删除是黑色就把替补转黑色补上去**，这样就把缺少的黑子填上

2. 当隔壁的**两个儿子中有一个为红色**，那么通过变色以及旋转来用隔壁红儿子把少掉的黑子补上：

   1. 邻居左儿子为红：把左儿子染黑，邻居染红，以邻居为轴右转变成情况 2

      ![2392382-dc29605ce9889973](..\images\2392382-dc29605ce9889973.webp?lastModify=1652788532)

   2. 邻居右儿子为红：让隔壁继承父亲的颜色，让右儿子变黑，父亲变黑，以父亲为轴左旋转

      左旋时父亲的黑会加入左边把缺少的黑补上，因为隔壁变成父结点，所以隔壁右儿子变黑不让右边黑数量减少

      ![2392382-7eea721cbb855876](..\images\2392382-7eea721cbb855876.webp?lastModify=1652788548)

3. **隔壁为黑且的两儿子为黑子**：隔壁变红，那么现在到父亲的分支缺少一个黑色了，向上迭代，最多 $O(\log_2n)$

   如果迭代上去之后，**父亲是红色的话，直接变黑**，结束，这就把缺失的黑色补上了（根节点也结束）

4. **隔壁为红色**：隔壁变黑，父亲变红，以父亲为轴左旋转，这样 R 的隔壁就变成黑色了

   ![2392382-1e4c3388491b588f](..\images\2392382-1e4c3388491b588f.webp?lastModify=1652788929)

若 R 是父结点 P 的右孩子，则还有四种对称的情况，处理方式类似，不再赘述；最后放个例子：

![2392382-b037e4c29cbffc4d](..\images\2392382-b037e4c29cbffc4d.webp?lastModify=1652788995)

### 综合应用题

#### 检验是否为二叉排序树

题目：试编写一个算法，判断给定的二叉树是否为二叉排序树

思路：利用二叉排序树的中序会大于它的前驱，只要存储前驱的变量就好了

```c
int pre = 0x80000000;

int JudgeBST(BiTree bt) {
    if (bt == NULL)
        return 1;
    if (JudgeBST(bt -> lchild) == 0 || pre >= bt -> data)
        return 0;
    pre = bt -> data;
    return JudgeBST(bt -> rchild);
}
```

#### 判断二叉树是否是平衡二叉树

问题：利用二叉树遍历的思想，编写一个判断二叉树是否是平衡二叉树的算法

思路：如果一颗树是平衡二叉树，那么它满足

1. 左子树和右子树分别是一棵平衡二叉树
2. 左子树和右子树的高度差的绝对值不超过 1

使用 `void judge(Tree t, bool &balance, int &height)` 可以容易的判断

## B 树和 B+ 树

### B 树及其基本操作

#### B 树的定义

B 树又称为**多路平衡查找树**，B 树中所有**结点的孩子结点数的最大值**称为 **B 树的阶**，通常用 m 表示

一个 m 阶 B 树为空树，或者为满足如下特性的 m 叉树：

1. 树中每个结点**至多有 m 棵子树**（即**至多含有 m - 1 个关键字**）

2. 若根结点不是终端结点，则**至少含有两棵子树**

3. 除根结点之外的所有**非叶结点至少有 $\lceil m/2\rceil$ 棵子树**（即**至少含有个 $\lceil m/2\rceil-1$ 关键字**）

4. 所有非叶结点的结构如下：

   ![image-20210925192007600](..\images\image-20210925192007600.png)

   其中，$K_i$ 为结点的关键字，且满足 $K_1<\cdots<K_n$；$P_i$ 为指向子树根结点的指针，且指针 $P_{i−1}$ 所指子树中所有结点的关键字均小于 $K_i$，$P_i$ 所指子树中所有结点的关键字均大于 $K_i$；$\lceil m/2\rceil−1≤n≤m−1$ 中 n 为结点中关键字的个数

5. 所有的叶结点都出现在同一层次上，并且**不带信息**（实际上这些结点不存在，指向这些结点的指针为空）

![image-20210925193141260](..\images\image-20210925193141260.png)

#### B 树的高度

B 树的高度**不包含**最后的不带任何信息的**叶结点所处的那一层**，有些书带了这一层

若 $n\geq1$ 则对任意一棵包含 n 个关键字、高度为 h、阶数为 m 的 B 树：

1. 在一棵高度为 h 的 m 阶 B 树中关键字的个数应满足 $n\leq(m-1)(1+\cdots+m^{h-1})=m^h-1$，就有 $h\geq\log_m(n+1)$

   其中 $m-1$ 是结点中最大关键字数，$m^{h-1}$ 是当前层最多的结点数

2. 在一棵高度为 h 的 m 阶 B 树中关键字的个数应满足 $n+1\geq2(\lceil m/2\rceil)^{h-1}$，就有 $h\leq\log_{\lceil m/2\rceil}((n+1)/2)+1$

   要使 B 树最高，根据 B 树的定义：

   1. 根结点只有一个结点，即根结点只有两个子树
   2. 第三层至少有 $2\lceil m/2\rceil$ 个结点；其中 $\lceil m/2\rceil$ 是每个结点的最少子树
   3. 第 h 层至少有 $2\lceil m/2\rceil^{h-2}$ 个结点
   4. 第 h + 1 层至少有 $2\lceil m/2\rceil^{h-1}$ 个结点，对于**关键字个数为 n 的 B 树**，**叶结点**即查找不成功的结点**为 n + 1**
   5. 又 h + 1 层是叶结点，就有 $n+1\geq 2\lceil m/2\rceil^{h-1}$，即  $h\leq\log_{\lceil m/2\rceil}((n+1)/2)+1$
   6. 注意：$n+1= 2\lceil m/2\rceil^{h-1}$ 时是当前高度的最小结点情况

3. **综上得到有 n 个关键字的 B 树最小高度为 $\lceil \log_m(n+1)\rceil$ 最大高度为 $\lceil\log_{\lceil m/2\rceil}((n+1)/2)\rceil+1$**

4. 计算最小关键字数量也可以把每一层结点数加起来乘最小关键字数 $1+(\lceil m/2\rceil-1)(2+2\displaystyle\sum^h_{i=3}\lceil m/2\rceil^{i-2})$ 根结点关键字是 1

#### B 树的查找

1. 从磁盘上把结点加载进内存

2. 在结点内对关键字进行比较，使用二分查找或顺序查找

3. 如果查找成功就返回关键字对应的信息

4. 如果查找失败，就拿对应的指针信息回到第一步加载进内存

   对应的指针是指，若 $K_{i-1}$ < k < $K_i$ 那么指针就是 $P_{i-1}$，否则就是 $P_i$

5. 如果查找到叶结点（NULL）时，说明树中没有对应的关键字，查找失败

#### B 树的插入

1. 先定位，使用查找找到最下层的非叶结点
2. 把 key 插入，查看该结点的大小是否等于 $m$，若小于 m 插入结束
3. 若大于等于 m，就进行分裂操作，分裂完了由于给父结点加了个关键字，所以父结点可能也要分裂
   1. **从中间位置 $\lceil m/2\rceil$ 将该结点的关键字分为两个部分**
   2. 创建一个新结点存放右边部分的内容
   3. 中间结点插入父结点假设是 $K_i$ 位置，父结点的 $P_i$ 指向新结点
   4. ![image-20210925204111508](..\images\image-20210925204111508.png)

B 树插入的例子：

![20170627093113511](..\images\20170627093113511.png)

#### B 树的删除

1. 查找要删除的关键字所在的位置
2. 如果要删除的关键字不在最底层，那么就拿后继或前驱代替，现在就变成删除最底层
3. 如果删除关键字后结点内关键字 $\geq \lceil m/2\rceil-1$，则不需要调整，删除完成
4. 如果小于，就先看兄弟结点有没有 $\geq \lceil m/2\rceil$，有就向他借一个，删除完成
   1. 这里假设是右兄弟，左兄弟类似
   2. 从父结点拿一个结点下来，用右兄弟最小的关键字代替
   3. ![image-20210925204725392](..\images\image-20210925204725392.png)
5. 如果兄弟也没有的借，那就合并，合并会拿父结点一个关键字，导致父结点也可能需要调整（第三步开始）
   1. 就拿自己和兄弟以及一个父结点的关键字合并（合并两个子树所夹的那个结点）
   2. 这里要注意调整子树的指针位置
   3. ![image-20210925205042440](..\images\image-20210925205042440.png)

B 树删除的例子：

![src=http___img-blog.csdn.net_20150906172428271&refer=http___img-blog.csdn](..\images\src=http___img-blog.csdn.net_20150906172428271&refer=http___img-blog.csdn.webp)

### B + 树的基本概念

B + 树是**应数据库所需而出现**的一种 B 树的变形树

一棵 m 阶的 B + 树需满足下列条件：

1. 每个分支结点**最多有 m 棵子树**（孩子结点）
2. 非叶根结点至少有两棵子树，其他每个分支结点**至少有 $\lceil m/2\rceil$ 棵子树**
3. **结点的子树个数与关键字个数相等**
4. 叶结点包含**全部关键字**及**指向相应记录的指针**，叶结点中将关键字**按大小顺序排列**，相邻叶结点按大小顺序**相互链接起来**
5. 所有分支结点中仅包含它的各个**子结点中关键字的最大值**及**指向其子结点的指针**

m 阶的 B + 树与 m 阶的 B 树的主要差异如下：

1. **关键字对应的子树不一样**，B + 树**每个关键字对应一棵子树**；B 树子树的数量是关键字的数量加一

2. **根结点**和**非根内部结点**的**关键字个数不一样**，B + 树是 $\lceil m/2\rceil≤n≤m$；B 树是 $\lceil m/2\rceil-1≤n≤m-1$

3. 在 B + 树中，叶结点包含信息，所有**非叶结点仅起索引作用**，非叶结点中**不含有该关键字对应记录的存储地址**

4. 在 B + 树中，叶结点包含了全部关键字，即在非叶结点中出现的关键字也会出现在叶结点中

   而在 B 树中，叶结点（最外层内部结点）包含的关键字和其他结点包含的关键字是不重复的

通常在 B + 树中有两个头指针：一个指向**根结点**，另一个指向**关键字最小的叶结点**

可以对 B + 树进行两种查找运算：一种是从最小关键字开始的**顺序查找**，另一种是从根结点开始的**多路查找**

![image-20210925210641989](..\images\image-20210925210641989.png)

B + 树的查找、插入、删除操作和 B 树的基本类似，只是在查找时，非叶结点上的关键字值等于给定值时并不终止，而是继续向下查找，直到叶结点上的该关键字为止

## 散列表

### 散列表的基本概念

在前面介绍的线性表和树表的查找中，查找方法建立在“比较”的基础上，查找的效率取决于比较的次数

* 散列函数：一个把查找表中的**关键字映射成该关键字对应的地址的函数**，记为 `Hash(key) = Addr`，这里的地址可以是数组下标、索引或内存地址等

  散列函数可能把<u>两个或以上的不同关键字映射到同一地址</u>，称这种情况为**冲突**，这些**发生碰撞的不同关键字称为同义词**

  设计得好的散列函数应**尽量减少这样的冲突**；由于这样的冲突总是不可避免的，所以还要**设计好处理冲突的方法**

* 散列表：根据关键字而直接进行访问的数据结构，**散列表建立了关键字和存储地址之间的一种直接映射关系**

理想情况下，对散列表进行查找的时间复杂度为 O(1)，即与表中元素的个数无关

### 散列函数的构造方法

在构造散列函数时，必须注意以下几点：

1. 散列函数的**定义域**必须**包含全部需要存储的关键字**，而**值域**的范围则依赖于**散列表的大小或地址范围**
2. 散列函数计算出来的地址应该能**等概率、均匀地分布**在整个地址空间中，从而减少冲突的发生
3. **散列函数应尽量简单**，能够在较短的时间内计算出任一关键字对应的散列地址

在不同的情况下，不同的散列函数具有不同的性能，因此不能笼统地说哪种散列函数最好

在实际选择中，采用何种构造散列函数的方法取决于关键字集合的情况，但目标是为了**尽量降低产生冲突的可能性**

#### 直接定址法

直接取关键字的某个**线性函数值为散列地址**，散列函数为 H(key) = key 或 H(key) = a × key + b，其中 a 和 b 是常数

这种方法计算最简单，且不会产生冲突，它适合**关键字的分布基本连续**的情况

若关键字分布不连续，则会造成存储空间的浪费

#### 除留余数法

这是一种最简单、最常用的方法，假定散列表表长为 m，取一个**不大于 m 但最接近或等于 m 的质数 p**

利用散列函数 **H(key) = key % p**，把关键字转换成散列地址

除留余数法的**关键是选好 p**，使得通过该函数转换后等概率地映射到散列空间上的任一地址，从而尽可能减少冲突的可能性

为什么 p 是质数：因为质数因子最少，冲突较少；如 6 还有因子 2，因子的列 2, 4, 6, 8, 10, 12 冲突比较大

#### 数字分析法

设关键字是 r 进制数（如十进制数），而 r 个数码在各位上出现的频率不一定相同，可能在某些位上分布均匀一些，每种数码出现的机会均等

而在某些位上分布不均匀，只有某几种数码经常出现，此时应选取数码分布较为均匀的若干位作为散列地址

这种方法适合于**已知的关键字集合**，若更换了关键字，则需要重新构造新的散列函数

<u>数值分析法就是有一堆有规律的数字，我们可以根据这个规律思考一个散列函数</u>

#### 平方取中法

这种方法取**关键字的平方值的中间几位作为散列地址**，具体取多少位要视实际情况而定

这种方法得到的散列地址与关键字的每位都有关系，因此使得散列地址分布比较均匀

适用于**关键字的每位取值都不够均匀**或**均小于散列地址所需的位数**

如 3586 的平方 128**59**396 我们可以取中间的 59 作为散列地址

### 处理冲突的方法

用 $H_i$ 表示处理冲突中第 i 次探测得到的散列地址，假设得到的另一个散列地址 $H_1$ 仍然发生冲突，只得继续求下一个地址 $H_2$，以此类推，直到 $H_k$ 不发生冲突为止，则 $H_k$ 为关键字在表中的地址

#### 开放地址法（闭散列）

选择题：<u>解决冲突的方法选取不当是发生聚集的主要原因</u>

所谓开放地址法，是指可存放新表项的空闲地址**既向它的同义词表项开放**，**又向它的非同义词表项开放**

其数学递推公式为 $H_i=(H(key)+d_i)\%m$ 其中 m 表示散列表表长，$d_i$ 为增量序列

取定某一增量序列后，对应的处理方法就是确定的，其中增量序列有以下 4 种取法：

##### 线性探测法

当 $d_i=0,1,…,m-1$ 时，称为线性探测法

这种方法的特点是：**冲突发生时，顺序查看表中下一个单元，直到找出一个空闲单元或查遍全表**

线性探测法可能使第 i 个散列地址的同义词存入第 i + 1 个散列地址

这样本应存入第 i + 1 个散列地址的元素就争夺第 i + 2 个散列地址的元素的地址

从而造成大量元素在相邻的散列地址上“聚集”起来，大大降低了查找效率

##### 平方探测法

**当 $d_i=0^2,1^2,-1^2,…,k^2,-k^2$ 时，称为平方探测法**，其中 k ≤ m / 2，散列表长度 m 必须是一个可以表示成 `4k + 3` 的素数，又称二次探测法

平方探测法是一种**较好**的处理冲突的方法，可以避免出现“聚集”问题，它的<u>缺点是不能探测到散列表上的所有单元，但至少能探测到一半单元</u>

##### 再散列法

当 $d_i = Hash_2(key)$ 时，称为再散列法，又称双散列法

需要使用**两个散列函数**，当通过第一个散列函数 H(key) 得到的地址发生冲突时，则利用**第二个散列函数** $Hash_2(key)$ **计算该关键字的地址增量**

它的具体散列函数形式为 $H_i=(H(k)+i\times Hash_2(key)) \% m$ 初始探测位置 $H_0=H(key)\%m$，i 是冲突的次数，初始为 0

在再散列法中，最多经过 m - 1 次探测就会遍历表中所有位置，回到 $H_0$ 位置

##### 伪随机序列法

当 $d_i$ = **伪随机数序列**时，称为伪随机序列法

------

<u>要删除一个元素时，可给它做一个删除标记，进行逻辑删除</u>，因为删除后可能会影响相同散列地址的查找

但这样做的副作用是：执行多次删除后，表面上看起来散列表很满，实际上有许多位置未利用，因此需要定期维护散列表，要把删除标记的元素物理删除

#### 拉链法（开散列）

![image-20210926192903777](..\images\image-20210926192903777.png)

对于不同的关键字可能会通过散列函数映射到同一地址，为了**避免非同义词发生冲突**，可以**把所有的同义词存储在一个线性链表中**，这个线性链表由其散列地址唯一标识

假设散列地址为 i 的同义词链表的头指针存放在散列表的第 i 个单元中，因而查找、插入和删除操作主要在同义词链中进行

**拉链法适用于经常进行插入和删除的情况**

### 散列查找及性能分析

#### 散列查找过程

散列表的查找过程与构造散列表的过程基本一致

对于一个给定的关键字 key，查找的操作如下：

1. 根据散列函数可以计算出其散列地址 `Addr = Hash(key)`
2. 检测查找表中地址为 `Addr` 的位置上是否有记录，若**无记录，返回查找失败**
3. 若有记录，比较它与 key 的值，**若相等，则返回查找成功标志**，否则执行步骤 4
4. 用给定的**处理冲突方法计算“下一个散列地址”**，并把 `Addr` 置为此地址，转入步骤 2

注意：要保证在插入时的散列函数运行结果与查找时散列函数的运行结果一致

#### 性能分析

**查找成功的平均查找长度**：每个关键字的比较次数的和 ÷ 关键字总数

**查找失败的平均查找长度**：根据散列函数，计算每个查找失败的比较次数的和 ÷ 失败的次数

对同一组关键字，设定**相同的散列函数**，则**不同的处理冲突的方法得到的散列表不同**，它们的平均查找长度也不同

从散列表的查找过程可见：

1. 虽然散列表在关键字与记录的存储位置之间建立了直接映像，但由于“冲突”的产生，使得散列表的查找过程仍然是一个给定值和关键字进行比较的过程。因此，仍需要以平均查找长度作为衡量散列表的查找效率的度量

2. 散列表的查找效率取决于三个因素：**散列函数、处理冲突的方法、装填因子**

   散列表的装填因子一般记为 α，定义为一个表的装满程度，即 $\alpha=\dfrac{表中记录数\space n}{散列表长度\space m}$

散列表的**平均查找长度依赖于散列表的装填因子 α**，而**不直接依赖于 n 或 m**

直观地看，**α 越大**，表示装填的记录越“满”，**发生冲突的可能性越大**，反之发生冲突的可能性越小

注意：**根据装填因子 α 计算表长时，计算出来的值要向上取整**；拉链法只是冲突处理方法，不会影响表长的计算

#### 散列表例题

将关键字序列 (7, 8, 30, 11, 18, 9, 14) 散列存储到散列表中。散列表的存储空间是一个下标从 0 开始的一维数组，散列函数为 $H (key)=(key×3 )\space MOD\space7$，处理冲突采用线性探测再散列法，要求装填（载）因子为 0.7

1. 由装填因子 0.7 和数据总数 7，得一维数组大小为 7 / 0.7 = 10，数组下标为 0 ~ 9

2. 根据散列函数和线性探测再散列法，构造出散列表：

   ![image-20210926195814684](..\images\image-20210926195814684.png)

3. 查找 18 时，对 18 进行散列函数得 54 % 7 = 5，而和 5 比较不是，根据线性探测与 6 比较不是，最后与 7 比较查找成功，中间共比较了 3 次

4. 查找成功的平均长度是**每个关键字查找时的比较次数和**除以**关键字数**，即 (1 + 2 + 1 + 1 + 1 + 3 + 3) / 7 = 12 / 7

5. 查找失败的比较次数是，假如从 0 开始查找到 2 查找失败共比较了 3 次；从 2 开始查找到查找失败比较了 1 次

6. 查找失败的平均长度是**散列函数值域的查找失败的比较次数和**除以**散列函数值域数**，即 (3 + 2 + 1 + 2 + 1 + 5 + 4) / 7 = 18 / 7

**注意：查找失败要计算的仅仅只是散列函数的值域位置**，如上面值域是 0 ~ 6

采用链地址解决冲突的话，平均查找长度也差不多，都是**比较次数的和**除以**关键字数**

注意：有时**空指针也算比较次数**，有时空指针不算比较次数（这道考研题就算了），因题而异

## 归纳总结

**本章的核心考查点是求平均查找长度（ASL)，以度量各种查找算法的性能**

查找算法本身依托于查找结构，查找结构又是由相同数据类型的记录或结点构成的，故最终落脚于数据结构类型的区别

不管是何种查找算法，其平均查找长度的计算公式都是一样的

**查找成功的平均查找长度 $ASL_{成功}=\displaystyle\sum^n_{i=1}p_ic_i$**
**查找失败的平均查找长度 $ASL_{失败}=\displaystyle\sum^n_{i=1}q_ic_i$**

若**综合考虑**，即 $\displaystyle\sum^n_{i=1}p_i+\displaystyle\sum^n_{i=1}q_i=1$，若所有元素查找概率相等，则有 $p_i=q_i=\dfrac{1}{2n+1}$；若**分开考虑**，即 $\displaystyle\sum^n_{i=1}p_i=1$，$\displaystyle\sum^n_{i=1}q_i=1$，若所有元素查找概率相等，则有 $p_i=\dfrac{1}{n}$，$q_i=\dfrac{1}{n+1}$

虽然综合考虑更为理想，但在实际应用中多数是分开考虑的，因为对于查找不成功的情况，很多场合下没有明确给出，往往会被忽略掉。不过读者仍要注意的是，这两种考虑的计算结果是不同的，考试中一定要仔细阅读题目的要求，以免失误

# 排序

## 排序的基本概念

排序，就是重新排列表中的元素，**使表中的元素满足按关键字有序的过程**

排序的确切定义如下：

* 输入：n 个记录 $R_1,R_2,\cdots, R_n$，对应的关键字为 $k_1, k_2,\cdots, k_n$

* 输出：输入序列的一个重排 $R_1^\prime,R_2^\prime,\cdots,R_n^\prime$，使得 $k_1^\prime≤k_2^\prime≤\cdots≤k_n^\prime$（其中“<”可以换成其他的比较大小的符号）

* 算法的稳定性：若排序后**两个关键字相等的元素的相对位置不变**，则称排序算法是**稳定的**，否则称排序算法是**不稳定的**

  算法是否具有稳定性并不能衡量一个算法的优劣，它主要是**对算法的性质进行描述**

  如果待排序表中的关键字不允许重复，那么选择排序算法时的稳定与否就无关紧要

  注意：对于不稳定的排序算法，只需举出一组关键字的实例，说明它的不稳定性即可

在排序过程中，根据数据元素是否完全在内存中，可将排序算法分为两类：

1. 内部排序，是指在排序期间**元素全部存放在内存中**的排序
2. 外部排序，是指在排序期间**元素无法全部同时存放在内存中**，必须在排序的过程中根据要求**不断地在内、外存之间移动**的排序

一般情况下，内部排序算法在执行过程中都要进行两种操作：

1. 比较：通过比较两个关键字的大小，确定对应元素的前后关系
2. 移动：确定好前后关系后通过移动元素以达到有序

并非所有的内部排序算法都要基于比较操作，基数排序就不基于比较

每种排序算法都有各自的优缺点，适合在不同的环境下使用

通常可以将排序算法分为**插入排序、交换排序、选择排序、归并排序、基数排序**五大类

内部排序算法的**性能**取决于算法的**时间复杂度**和**空间复杂度**，而时间复杂度一般是**由比较和移动的次数决定的**

选择题：对任意 n 个关键字进行基于比较排序，至少需要进行 $\lceil\log_2(n!)\rceil$ 次关键字之间的**两两比较**

## 插入排序

### 直接插入排序

假设待排序表在某次过程中属于这种情况，待排序表 L[1...n] 在某次排序过程中某一个时刻状态如下：

![image-20210927155558459](..\images\image-20210927155558459.png)

要为了实现将元素 L(i) 插入到已有序的子序列 L[1…i−1] 中，需要执行以下操作（L[] 表示一个表，L() 表示一个元素）：

1. 查找出 L(i) 在 L[i+1…n] 中的插入位置 k
2. 将 L[k…i−1] 中所有元素全部后移一个位置
3. 将 L(i) 赋值到 L(k)

```c
void InsertSort(int A[],int n) {
    int i, j;
    for (i = 2; i <= n; i++) {  // 把 2 ~ n 的元素插到前面
        if (A[i] < A[i - 1]) {  // 如果小于它前驱就开始插入操作
            A[0] = A[i];
            for (j = i - 1; A[0] < A[j]; j--)  // 一边查找一边向后移动
                A[j + 1] = A[j];
            A[j + 1] = A[0];
        }
    }
}
```

直接插入排序算法的性能分析如下:

空间效率：仅使用了常数个辅助单元，因而**空间复杂度为 O(1)**

时间效率：

1. 在最好情况下，表中元素已经有序，此时每插入一个元素，都只需比较一次而不用移动元素，因而**时间复杂度为 O(n)**
2. 在最坏情况下，当初始序列为逆序时，总的**比较次数达到最大，为 $\displaystyle\sum^n_{i=2}i$**；总的**移动次数也达到最大，为 $\displaystyle\sum^n_{i=2}(i+1)$**
3. 平均情况下，考虑待排序表中元素是随机的，此时可以取上述最好与最坏情况的平均值作为平均情况下的时间复杂度，总的比较次数与总的移动次数均约为 $n^2/4$，直接插入排序算法的**时间复杂度为 $O(n^2)$**

稳定性：直接插入排序是**稳定的**。插入元素时总是从后向前先比较再移动，不会出现相同元素相对位置发生变化的情况

适用性：直接插入排序算法适用于**顺序存储**和**链式存储**的线性表

注意：大部分排序算法都仅适用于顺序存储的线性表

选择题：将 n 各不同的元素进行直接插入排序，最多需要进行的比较次数是 $\dfrac{n(n-1)}{2}$，最少比较次数是 $n-1$

### 折半插入排序

从直接插入排序算法中，不难看出每趟插入的过程中都进行了两项工作：

1. 从前面的有序子表中查找出待插入元素应该被插入的位置

2. 给插入位置腾出空间，将待插入元素复制到表中的插入位置

下面将比较和移动操作分离开，即**先折半查找出元素的待插入位置**，然后**再统一的移动待插入位置之后的元素**

当**排序表为顺序表**时，**查找**有序子表时可以**用折半查找来实现**，<u>确定待插入位置后，就可统一地向后移动元素</u>

算法代码如下:

```c
void InsertSort(int A[], int n) {
    int i, j, low, high, mid;
    for(i = 2; i <= n; i++) {
        A[0] = A[i];
        low = 1, high = i - 1;
        while(low <= high) {  // 折半查找出插入位置
            mid = (low + high) / 2;
            if (A[mid] > A[0])
                high = mid - 1;
            else
                low = mid + 1;
        }
        for (j = i - 1; j >= high + 1; j--)  // 整体元素后移
            A[j + 1] = A[j];
        A[high + 1] = A[0];  // 插入
    }
}
```

折半插入排序**仅减少了比较元素的次数**，约为 $O(n\log_2n)$，该比较次数与待排序表的初始状态无关，仅取决于表中的元素个数 n；而元素的移动次数并未改变，它依赖于待排序表的初始状态

因此，折半插入排序的**时间复杂度仍为 $O(n^2)$**，但对于**数据量不很大**的排序表，折半插入排序往往能**表现出很好的性能**

折半插入排序是一种**稳定的排序方法**

### 希尔排序

当插入排序排序**基本有序的排序表**和**数据量不大的排序表**时较快，希尔排序是基于这两点分析改进而来的

希尔排序的基本思想是：

* 把相隔某个增量的记录组成一个子表，对各个子表分别进行直接插入排序，当整个表中的元素已呈基本有序时，再对全体记录进行一次直接插入排序
* 如 5, 6, 2, 9, 8, 3, 4, 1 取 3 为增量可以有子表 5, 9,  4 和 6, 8, 1 和 2, 3，对它们进行排序后，就会更加的有序

希尔排序的过程如下：

1. 先取一个小于 n 的步长 $d_1$，把表中的全部记录分成 $d_1$ 组，所有距离为 $d_1$ 的倍数的记录放在同一组
2. 在各组内进行直接插入排序，然后取第二个步长 $d_2<d_1$，重复上述过程，直到所取到的 $d_t= 1$
3. 所有记录已放在同一组中，再进行直接插入排序，由于此时已经具有较好的局部有序性，故可以很快得到最终结果

目前为止尚未求得一个最好的增量序列，常用的方法是 $d_1=n/2$，$d_{i+1} =\lfloor d_i/2\rfloor$，并且最后一个增量等于1

![image-20210927165330697](..\images\image-20210927165330697.png)

```c
void ShellSort(int A[],int n) {
    for (int dk = n / 2; dk >= 1; dk = dk / 2)  // 步长变化
        for (int i = dk + 1; i <= n; i++)  // 对子列进行插入排序
            if (A[i] < A[i - dk]) {
                A[0] = A[i];
                for(int j = i - dk; j > 0 && A[0] < A[j]; j = j - dk)
                    A[j + dk] = A[j];
                A[j + dk] = A[0];
            }
}
```

希尔排序算法的性能分析如下：

空间效率：仅使用了常数个辅助单元，因而**空间复杂度为 O(1)**

时间效率：当 n 在某个特定范围时，希尔排序的**时间复杂度约为 $O(n^{1.3})$**；在**最坏情况**下希尔排序的**时间复杂度为 $O(n^2)$**

稳定性：希尔排序是一种**不稳定**的排序方法。当相同关键字的记录被划分到不同的子表时，可能会改变它们之间的相对次序

适用性：希尔排序算法仅适用于线性表为**顺序存储**的情况

## 交换排序

### 冒泡排序

冒泡排序的算法思想是：

* 从后往前（或从前往后）两两比较，逆序就交换，直到序列比较完
* 我们称之为一趟冒泡，结果将最小或最大的元素交换到待排序的第一个位置
* 在下一趟冒泡的时候，上一趟确定的元素不需要比较，待排序列减少一个元素
* 每一趟都会把序列中最小（或最大）元素放到序列的最终位置

```c
void BubbleSort(int A[], int n) {
    for (int i = 0; i < n - 1; i++) {
        flag = false;  // 本趟是否有交换，如没有交换表示以及有序
        for (int j = n - 1; j > i; j--)  // 进行一趟冒泡排序
            if (A[j - 1] > A[j]) {  // 如果你逆序就交换
                swap(A[j - 1], A[j]);
                flag = true;
            }
        if(flag == false)
            break;
    }
}
```

冒泡排序的性能分析如下：

空间效率：仅使用了常数个辅助单元，因而**空间复杂度为 O(1)**

时间效率：

- 当初始序列有序时，显然第一趟冒泡后 flag 依然为 false，从而直接跳出循环，比较次数为 n - 1，移动次数为 0，从而**最好情况下的时间复杂度为 O(n)**

- 当初始序列为逆序时，需要进行 n - 1 趟排序，第 i 趟排序要进行 n - i 次关键字的比较，而且每次比较后都必须移动元素 3 次来交换元素位置

  这种情况下，比较次数 $\displaystyle\sum^{n-1}_{i=1}(n-i)=\dfrac{n(n-1)}2$，移动次数 $\displaystyle\sum^{n-1}_{i=1}{3(n-i)}=\dfrac{3n(n-1)}{2}$ 从而，最坏情况下的时间复杂度为 $O(n^2)$，其**平均时间复杂度也为 $O(n^2)$**

稳定性：冒泡排序是一种**稳定的**排序方法。由于 i > j 且 A[i] = A[j] 时，不会发生交换

<u>注意：冒泡排序每趟排序都会将一个元素放置到其最终的位置上</u>

### 快速排序

快速排序是对冒泡排序的一种改进，其基本思想是基于分治法的：

1. 在待排序表 L[1…n] 中任取一个元素 pivot 作为基准
2. 将待排序表划分为独立的两部分 L[1…k − 1] 和 L[k + 1…n] 使得 **L[1…k − 1] 中所有元素小于 pivot**，**L[k + 1…n] 中所有元素均大于或等于 pivot**，则 **pivot 放在了其最终位置 L(k) 上**，这叫**一趟快速排序**
3. 分别递归的对两个子表重复上述过程，直至每部分内只有一个元素或者为空为止，即所有元素放在了其最终位置之上

先对表进行划分，而后对两个表调用同样的排序操作，因此可以递归的调用快速排序算法进行排序，具体的程序结构如下：

```c
int Partition(ElemType A[], int low, int high) {  // 划分算法
    ElemType pivot = A[low];  // 将第一个值设置为基准
    while(low < high) {  // 分割完元素跳出循环
        while(low < high && A[high] >= pivot) high--;
        A[low] = A[high];  // 将比基准小的移动到左端
        while(low < high && A[low] <= pivot) low++;
        A[high] = A[low];  // 将比基准大的移动到右端
    }
    A[low] = pivot;  // 基准元素放在最终位置
    return low;  // 返回基准的位置
}

void QuickSort(int A[], int low, int high) {
    if (low < high) {  // 递归终止条件，表空
        int pivot = Partition(A, low, high);  // 划分
        QuickSort(A, low, pivot - 1);  // 依次对两个子表进行递归排序
        QuickSort(A, pivot + 1, high);
    }
}
```

快速排序算法的性能分析如下：

空间效率：

* 快速排序是递归的，需要借助栈来保存每层递归调用的信息，其容量应与**递归调用的最大深度一致**
* 最好情况下，每次都从从中间分开，栈深度为 $O(\log_2n)$
* 最坏情况下，因为要进行 n - 1 次递归调用，所以栈的深度为 O(n)
* 平均情况下，**栈的深度为 $O(\log_2n)$**

时间效率：

* 快速排序的**最坏情况**发生在**初始排序表基本有序或基本逆序**时，就得到**最坏情况下的时间复杂度为 $O(n^2)$**
* 当 Partition() 做到平衡的划分，得到的两个子问题的大小都不可能大于 n / 2，最好情况的**时间复杂度为 $O(n\log_2n)$**
* 快速排序**平均情况**下的运行时间**与其最佳情况**下的运行时间**很接近**，平均情况的时间复杂度为 $O(n\log_2n)$
* **快速排序是所有内部排序算法中平均性能最优的排序算法**

有很多方法可以提高算法的效率：

* 尽量**选取一个可以将数据中分的枢轴元素**，如从序列的头中尾选取三个元素，再取这三个元素的中间值作为的枢轴元素
* **随机地从当前表中选取枢轴元素**，这样做可使得最坏情况在实际排序中几乎不会发生

稳定性：快速排序是一种**不稳定的**排序方法。在划分算法中，若右端区间有两个关键字相同，且均小于基准值的记录，则在交换到左端区间后，它们的相对位置会发生变化

注意：在快速排序算法中，并不产生有序子序列，但每趟排序后会将**枢轴（基准）元素放到其最终的位置上**

快排判别法：将序列排好序，与题目中的序列比较。一趟的话会有一个在正确位置，二趟的话如果在任一端点匹配成功就需要两个在正确位置，否则就需要三个在正确位置

### 综合应用题

#### 快排 Partition 的其他写法

```c
// 左右反复交换
int Partition(ElemType A[], int low, int high) {  // 划分算法
    ElemType pivot = A[low];  // 将第一个值设置为基准
    while(low < high) {  // 分割完元素跳出循环
        while(low < high && A[high] >= pivot) high--;
        A[low] = A[high];  // 将比基准小的移动到左端
        while(low < high && A[low] <= pivot) low++;
        A[high] = A[low];  // 将比基准大的移动到右端
    }
    A[low] = pivot;  // 基准元素放在最终位置
    return low;  // 返回基准的位置
}

// 左右同时交换
int Partition(Item a[], int l, int r) {
    int i = l - 1, j = r;
    Item v = a[r];  // 以最后一个为分界线
    while (i < j) {
        while (i < j && a[++i] < v);  // 左边找大于 v 的元素
        while (i < j && v < a[--j]);  // 右边找小于 v 的元素
        if(i < j) {
            Swap(a[i], a[j])
        }
    }
    Swap(a[i], a[r]);
    return i;
}

// 将小的全放在前面
int Partition(ElemType A[], int low, int high){
    ElemType pivot = A[low];
    int i = low;
    for(int j = low + 1; j <= high; j++)
        if(A[j] < pivot){
            swap(A[++i], A[j]);
        }
    swap(A[i], A[low]);
    return i;
}
```

#### 奇偶分开

题目：已知线性表按顺序存储，且每个元素都是不相同的整数型元素，设计把所有奇数移动到所有偶数前面的算法（要求时间最少，辅助空间最少）

思路：从前面向后查找，找到偶数 L(i)；再从后面向前查找，找到奇数 L(j)，将 L(i) 和 L(j) 交换，反复直到 i > j

#### 第 k 位置元素

题目：试编写一个算法，使之能够在数组 L[1...n] 中找出第 k 小的元素（即从小到大排序后处于第 k 个位置的元素）

思路：利用快排的会将枢轴（基准）元素放到其最终的位置上这一特性

1. 选择子表第 1 位元素，进行划分算法操作，这时它在的 j 位置就是第 j 小的元素
2. 比对 j 和 k，若等于它就是第 k 小的元素
3. 小于，把子表取左半部分，跳转步骤 1
4. 大于，把子表取右半部分，跳转步骤 1

#### 荷兰国旗

题目：设有一个仅由红、白、蓝三种颜色的条块组成的条块序列，请编写一个时间复杂度为 O(n) 的算法，使得这些条块按红、白、蓝的顺序排好，即排成荷兰国旗图案

思路：扫描线性表，将红色丢到前面；将蓝色丢到后面

```c
typedef enum {RED, WHITE, BLUE} color;

void Flag_Arrange(color a[], int n) {
    // i 是红色指针前面全是红色；k 是蓝色指针后面全是蓝色；j 是工作指针
    int i = 0, j = 0, k = n - 1;
    while (j <= k) {
        switch (a[j]) {
            // 红色与 i 交换，当 i, j 不同时 a[i] 只会是白色
            case RED: swap(a[i], a[j]); i++; j++; break;
            case WHITE: j++; break;
            // 蓝色与 k 交换，因为不知道 a[k] 的颜色所有先不动 j
            case BLUE: swap(a[j], a[k]); k--; break;
        }
    }
}
```

## 选择排序

### 简单选择排序

简单选择排序算法的思想：假设排序表 L[1…n]，第 i 趟排序即从 L[i…n] 中选择关键字最小的元素与 L(i) 交换，每一趟排序可以确定一个元素的最终位置，这样经过 n − 1 趟排序就可以使整个排序表有序

```c
void SelectSort(int A[], int n) {
    for (int i = 0; i < n - 1; i++) {  // n - 1 趟
        int Min = i;
        for (int j = i + 1; j < n; j++)  // 拿 L[i...n] 的最小值
            if (A[j] < A[Min])
                Min = j;
        if (Min != i){  // 把最小值与 L(i) 交换
            swap(A[i], A[Min]);  // 交换会移动三次元素
        }
    }
}
```

简单选择排序算法的性能分析如下：

空间效率：仅使用常数个辅助单元，故**空间效率为 O(1)**

时间效率：在简单选择排序过程中，元素移动的操作次数很少，不会超过 3(n - 1)次，**最好的情况是移动 0 次**，此时对应的表已经有序；但**元素间比较的次数与序列的初始状态无关**，始终是 n(n - 1)/2次，因此**时间复杂度始终是 $O(n^2)$**

稳定性：选择排序是一种**不稳定的**排序算法。如 L = {2, **2**, 1} 排序后为 L = {1, **2**, 2}

### 堆排序

#### 堆

##### 定义

堆排序是一种**树形选择排序方法**，它的特点是：在排序过程中，将 L[1…n] 看做一棵完全二叉树的顺序存储结构，利用完全二叉树双亲结点和孩子结点之间的内在关系，在当前无序区中选择关键字最大

堆的定义如下，n 个关键字序列 L[1…n] 称为堆，当且仅当该序列满足以下任一条件：

- `L(i) ≤ L(2i)` 且 `L(i) ≤ L(2i + 1)`
- `L(i) ≥ L(2i)` 且 `L(i) ≥ L(2i + 1)`

满足 1 的称为**小根堆（小顶堆）**，满足 2 的堆称为**大根堆（大顶堆）**

在大根堆中，**最大元素存放在根结点**中，且对其任一非根结点，它的值小于或者等于其双亲结点值；小根堆的定义刚好相反，根结点是最小元素

![image-20210928134645312](..\images\image-20210928134645312.png)

##### 构建

n 个结点的完全二叉树，最后一个结点是第 $\lfloor n/2\rfloor$ 个结点的孩子

大根堆的构建（小根堆类似）：

1. 对 $(\lfloor n/2\rfloor\sim1)$ 进行遍历进行以下操作（从最后非终端结点向上遍历）：
2. 拿左右子树的最大值和本结点进行比较
3. 如果没有子树或子树小于本结点进行下一轮循环
4. 如果子树大于本结点则与较大值的子树交换
5. 交换完后的子树可能比本结点大，所以转 2 继续比较交换

```c
void HeapAdjust(ElemType A[], int k, int len) {
    A[0] = A[k];
    for (i = 2 * k; i <= len; i *= 2) {
        if (i < len && A[i] < A[i + 1])  // 第二步，拿到较大值的子树
            i++;
        if (A[0] >= A[i]) break;  // 第三步，位置正确
        else {
            A[k] = a[i];  // 第四步，与较大值的子树交换
            k = i;  // 第五步，转回第二步继续比较交换
        }
    }
    A[k] = A[0];  // 把筛选点放入最终位置
 }

void BuildMaxHeap(ElemType A[], int len) {
    for(int i = len / 2; i > 0; i--)  // 第一步遍历
        HeapAdjust(A, i, len);
}
```

![image-20210928140628236](..\images\image-20210928140628236.png)

调整的时间与树高有关，为 O(h) 在建含 n 个元素的堆时，关键字的比较总次数不超过 `4n`，**时间复杂度为 O(n)**，这说明可以在线性时间内将一个无序数组建成一个堆

##### 插入

将结点放入末端，再对这个新结点向上执行调整操作

![image-20210928143459330](..\images\image-20210928143459330.png)

##### 删除

删除堆头元素后，拿数组最后的元素代替，再进行调整操作，代码就是 `HeapAdjust()`

![image-20210928143626099](..\images\image-20210928143626099.png)

注意：删除时，向下调整第一次是**两个儿子（如果有）之间的比较**，第二次才是和**较大儿子的比较**

#### 堆排序

堆排序的思路：依次删除堆头，把删除的堆头构成序列就是排好序的序列

堆排序的过程：

1. 将存放在 L[1...n] 中的 n 个元素构成堆
2. 根据堆的特性，堆头就是最大值
3. 把堆头的元素和最后一位的元素交换，那么最后位就变成最大值
4. 调整堆，再拿堆头和倒数第二位的元素交换，依次类推就排序好了

```c
void HeapSort(int A[], int len) {
    BuildMaxHeap(A, len);  // 构建堆
    for(int i = len; i > 1; i--) {
        swap(A[i], A[1]);  // 拿最后元素和堆头交换
        AdjustDown(A, 1, i - 1);  // 调整把 i - 1 个元素整理成堆
    }
}
```

堆排序算法的性能分析如下：

空间效率：仅使用了常数个辅助单元，所以**空间复杂度为 O(1)**

时间效率：建堆时间为 O(n)，之后有 n - 1 次向下调整操作，每次调整的时间复杂度为 O(h)，故在最好、最坏和平均情况下，堆排序的**时间复杂度为 $O(n\log_2n)$**

稳定性：堆排序是一种**不稳定的**排序算法。表 L={1, **2**, 2}，构造堆后 L={**2**, 1, 2}，排序后 L= {1, 2, **2**}

------

**堆排序适合关键字较多的情况**。例如，如何在 1 亿个数中选出前 100 个最大值？

- 首先使用一个大小为 100 的数组，读入前 100 个数，建立小顶堆
- 依次读入余下的数，若小于堆顶则舍弃，否则用该数取代堆顶并重新调整堆，待数据读取完毕，堆中100个数即为所求

应用题：若只想得到一个序列中第 k（k ≥ 5）个最小元素之前的部分排序序列，则可以采用**冒泡排序、堆排序、简单选择排序**，当 $k\geq5$ 时，选择堆排序最优

- 对于堆排序：建堆 + 获取 k 个最小元素时间是 $4n+k\log_2 n$；对于冒泡和选择时间是 `kn`，故 k ≥ 5 用堆排较好

## 归并排序和基数排序

### 归并排序

归并的含义是**将两个或者两个以上的有序表组合为一个新的有序表**

假定待排序表中含有 n 个记录，则可以看为是 n 个有序的子表，每个子表长度为 1，然后两两归并，得到 $\lceil n/2\rceil$ 个长度为 2 或者 1 的有序表；再两两归并，直到合并为一个长度为 n 的有序表为止，这种排序方法称为 2 - 路归并排序

![image-20210928182430183](..\images\image-20210928182430183.png)

下面的 Merge() 的功能是将两个相邻的有序表归并为一个有序表：

1. 新建数组 B 复制要合并的数据
2. 每次从对应 B 中的两段去取一个记录进行关键字的比较，将较小者放入 A 中
3. 当数组 B 中有一段的下标超过其对应的表长时，将另一段中的剩余部分直接复制到 A 中

递归形式的 2 路归并排序算法是基于分治的，其过程如下：

1. 将待排序的元素分成两个子表
2. 对左表排好序，对右表也排好序
3. 把排好序的左右表合并

```c
void Merge(int a[], int low, int mid, int high) {
    for (int i = low; i <= high; i++)  // 将 a 的要归并的元素复制到 b 中
        b[i] = a[i];
    // 归并，直到其中一个线性表为空
    for (i = low, j = mid + 1, k = i; i <= mid && j <= high; k++)
        if (b[i] <= b[j])
            a[k] = b[i++];
        else
            a[k] = b[j++];
    // 把另外的线性表放入
    while(i <= mid) a[k++] = b[i++];
    while(j <= high) a[k++] = b[j++];
}
 
void MergeSort(int a[], int low, int high) {
    if (low < high) {
        int mid = (low + high) / 2;  // 分成两个表
        MergeSort(a, low, mid);  // 对左边进行排序
        MergeSort(a, mid + 1, high);  // 对右边进行排序
        Merge(a, low, mid, high);  // 左右边都有序就可以进行合并了
    }
}
```

2 路归并排序算法的性能分析如下：

空间效率：Merge() 操作中，辅助空间刚好为 n 个单元，所以算法的**空间复杂度为 O(n)**

时间效率：每趟归并的时间复杂度为 O(n)，**共需进行 $\lceil \log_2n\rceil$ 趟归并**，所以算法的**时间复杂度为 $O(n\log_2n)$**

稳定性：2 路归并排序算法是一种**稳定的**排序方法。因为 Merge() 操作不会改变相同关键字记录的相对次序

注意：一般而言，对于 N 个元素进行 k 路归并排序时，**排序的趟数 m 满足 $k^m=N$**，从而 $m =\log_kN$，又考虑到 m 为整数，**所以 $m=\lceil \log_kN\rceil$**，其中 k 路归并就是每次拿 k 个表进行合并

### 基数排序

基数排序是一种很特别的排序方法，它**基于关键字各位的大小进行排序**

基数排序是一种借助多关键字排序的思想对单逻辑关键字进行排序的方法

假设长度为 n 的线性表中每个结点 $a_j$ 的关键字由 d 元组 $(k^{d-1}_j,\cdots,k^0_j)$ 组成，满足 $0\leq k^i_j\leq r-1$，其中 $k^{d-1}_j$ 为**最主位关键字**，$k^0_j$ 为**最次位关键字**

为实现多关键字排序，通常有两种方法：

* 最高位优先（`MSD`）法，先按最高位的值对记录进行降序排序，再按次高位进行排序
* 最低位优先（`LSD`）法，先按最低位的值对记录进行升序排序，再按次低位进行排序

基数排序需要 r 个队列，排序过程有两个操作（**通常采用链表**基数排序）：

* 分配：根据当前关键字，把**元素放入相应的队列里面**
* 收集：把**队列里面的元素依次首尾相接**，得到新的线性表

基数排序的一趟操作就是进行一次分配和收集操作，操作实例如下动图（图是基于数组的）：

![849589-20171015232453668-1397662527](..\images\849589-20171015232453668-1397662527.gif)

基数排序算法的性能分析如下（链表）：

空间效率：一趟排序需要的辅助存储空间为 r 个队列，但以后的排序中会重复使用这些队列，所以基数排序的**空间复杂度为 O(r)**，对链表进行基数排序时，队列结点就是链表的结点，所以一个队列仅需要有队头和队尾指针

时间效率：基数排序需要进行 d 趟分配和收集，一趟分配需要 O(n)，一趟收集需要 O(r)，所以基数排序的**时间复杂度为 O(d(n +r))**，它**与序列的初始状态无关**

稳定性：基数排序是一种**稳定的**排序算法。对于基数排序算法而言，很重要一点就是按位排序时必须是稳定的

如果是数组实现（一般不用）的话：空间复杂度为 $O(r \cdot n)$ 桶个数乘桶长；时间复杂度为 O(d(n + n)) 收集操作也需要 O(n) 了

注意：基数排序不能对 float 和 double 类型的实数进行排序

## 各种内部排序算法的比较及应用

### 内部排序算法的比较

从时间复杂度看：

- **简单选择排序、直接插入排序和冒泡排序**<u>平均情况</u>下的**时间复杂度都为 $O(n^2)$**，且实现过程也较简单
- **直接插入排序和冒泡排序**<u>最好情况</u>下的**时间复杂度可以达到 O(n)**，而**简单选择排序**则**与序列的初始状态无关**
- 希尔排序作为插入排序的拓展，对**较大规模的排序**都可以**达到很高的效率**，但目前**未得出其精确的渐近时间**
- 堆排序利用了一种称为堆的数据结构，可**在线性时间内完成建堆**，且**在 $O(n\log_2n)$ 内完成排序**过程
- 快速排序基于分治的思想，虽然**最坏情况**下快速排序**时间会达到 $O(n^2)$**，但快速排序**平均性能可以达到 $O(n\log_2n)$**，在实际应用中常常**优于其他排序算法**
- 归并排序基于分治的思想，由于其分割子序列与初始序列的排列无关，它的**最好、最坏和平均时间复杂度均为 $O(n\log_2n)$**

从空间复杂度看：

- **简单选择排序、插入排序、冒泡排序、希尔排序和堆排序**都仅需要借助**常数个辅助空间**
- **快速排序**在空间上只使用辅助栈，用于实现递归，**平均情况**下大小**为 $O(\log_2n)$**，当然在**最坏情况**下可能会增长到 **O(n)**
- **2 路归并排序**在合并操作中需要借助的辅助空间用于元素复制**大小为 O(n)**，虽然有方法能克服这个缺点，但其代价是算法会很复杂而且时间复杂度会增加

从稳定性看：

- **插入排序、冒泡排序、归并排序和基数排序**是**稳定的**排序方法
- **简单选择排序、快速排序、希尔排序和堆排序**都是**不稳定的**排序方法

从过程特征看：

采用不同的排序算法，在一次循环或几次循环后的排序结果可能是不同的

<u>考研题中经常出现给出一个待排序的初始序列和已经部分排序的序列，问其采用何种排序算法</u>

这就要对各类排序算法的过程特征十分熟悉，如冒泡排序和堆排序在每趟处理后都能产生当前的最大值或最小值，而快速排序一趟处理就能确定一个元素的最终位置等

<img src="..\images\image-20210928200229017.png" alt="image-20210928200229017" style="zoom: 150%;" />

### 内部排序算法的应用

选取排序方法需要考虑的因素：

1. 待排序的元素**数目 n**
2. 元素本身**信息量的大小**
3. **关键字的结构**及其**分布情况**
4. **稳定性的要求**
5. 语言工具的条件，**存储结构**及**辅助空间的大小**等

排序算法小结：

1. **若 n 较小，可采用直接插入排序或简单选择排序**；因简单选择排序的移动次数较少，当<u>记录本身信息量较大时，用简单选择排序较好</u>

2. 若文件的初始状态已按**关键字基本有序**，则选用**直接插入**或**冒泡排序**为宜

3. **若 n 较大**，则应采用**时间复杂度为 $O(n\log_2n)$ 的排序方法**：**快速排序、堆排序或归并排序**

   **快速排序**被认为是目前基于比较的**内部排序方法中最好的方法**

   **堆排序**所需的**辅助空间少于快速排序**，并且**不会出现快速排序可能出现的最坏情况**

   若**要求排序稳定则可选用归并排序**，可以先利用直接插入排序求得较长的有序子文件，然后两两归并（仍然稳定）

4. 在基于比较的排序方法中，每次比较两个关键字的大小之后，仅出现两种可能的转移，因此可以用一棵二叉树来描述比较判定过程，由此可以证明：当文件的 n 个关键字随机分布时，任何**借助于比较的排序算法**，**至少需要 $O(n\log_2n)$ 的时间**

5. 若 n 很大，记录的**关键字位数较少且可以分解**时，采用**基数排序**较好

6. 当**记录本身信息量较大**时，为避免耗费大量时间移动记录，可用**链表作为存储结构**

## 外部排序

### 外部排序的基本概念

在许多应用中，经常需要对大文件进行排序，因为文件中的记录很多、信息量庞大，无法将整个文件复制进内存中进行排序

因此，需要将**待排序的记录存储在外存**上，排序时再把数据一部分一部分地调入内存进行排序

在排序过程中需要多次进行**内存和外存之间的交换**，这种排序方法就称为**外部排序**

### 外部排序的方法

#### 排序的思路

**文件通常是按块存储在磁盘上的**，操作系统也是**按块**对磁盘上的信息进行读写的

因为磁盘读/写的操作相对于内存运算来说较慢，因此在外部排序过程中的<u>时间代价主要考虑访问磁盘的次数</u>，即 I/O 次数

**外部排序通常采用归并排序法**，它包括两个相对独立的阶段：

1. 把大文件分成多个子文件，把子文件加载进内存排序好再写回磁盘，称这些有序子文件为**归并段**或**顺串**
2. **对这些归并段进行逐趟归并**，使归并段逐渐由小到大，直至得到整个有序文件为止

例如一个含有 2000 个记录的文件，每个磁盘块可容纳 125 个记录，首先通过 8 次内部排序得到 8 个初始归并段 `R1~R8`，每个段都含有 250 个记录，然后对这些归并段继续归并，直到归并成一个文件，归并过程如下图

- 进行内部排序是指，输入缓冲区有两块，故从磁盘读入两块入内存，进行内部排序，变成一大块有序，写回磁盘

![image-20210929185321046](..\images\image-20210929185321046.png)

#### 2 路平衡归并的排序过程

1. 把内存工作区等分为 3 个缓冲区，其中的两个为输入缓冲区，一个为输出缓冲区
2. 从两个输入归并段 `R1` 和 `R2` 中分别读入一个块，放在输入缓冲区 1 和输入缓冲区 2 中
3. 在内存中进行 2 路归并，归并后的对象顺序存放在输出缓冲区中
4. 若**输出缓冲区中对象存满**，则将其顺序**写到输出归并段 `R1'` 中**，再清空输出缓冲区，继续存放归并后的对象
5. 若某个**输入缓冲区中的对象取空**，则**从对应的输入归并段中再读取下一块**，继续参加归并
6. 如此继续，直到两个输入归并段中的对象全部读入内存并都归并完成为止

选择题：m 路平衡归并排序的过程中，需要设置 m 个输入缓冲区和 1 个输出缓冲区

注意：**生成初始段的时候，整个内存工作区都可以用于生成初始归并段**，但**进行归并的时候要分成输入和输出缓冲**

- 生成初始时，内部排序后，直接放入磁盘就好了，整个内存空间都可以用，不需要分输入输出；但归并时却不能这样

#### 性能优化的思路

在外部排序中实现两两归并时，需要不停地将数据读出、写入磁盘，而这会耗费大量的时间

一般情况下：外部排序的总时间 = 内部排序所需的时间 + 外部存储读写的时间 + 内部归并所需的时间

**内部排序**是指，**生成归并段**；**内部归并**是指，**把输入缓存区的数据归并到输出缓冲区**；**外部存储读写**是指，**把文件读入输入缓存区**，**把输出缓冲区写入文件**

- 显然，外存信息读写的时间远大于内部排序和内部归并的时间，因此应着力减少 I/O 次数
- 每一趟归并需对文件读和写一遍，3 趟归并加上内部排序时所需进行的读/写，使得总共需进行 4 遍读写
- 若改用 4 路归并排序，则只需 2 趟归并，外部排序时的总读/写次数便减至 3 遍读写，依次可以通过增大归并数来减少 I/O

![image-20210929192042925](..\images\image-20210929192042925.png)

k 路平衡归并：**最多将 k 个段归段归并为 1 个**，每趟归并**将 m 个归并段归并成 $\lceil m/k\rceil$ 个归并段**

一般地，对 r 个初始归并段，做 k 路平衡归并，第一趟可将 r 个初始归并段归并为 $\lceil r/k\rceil$ 个归并段，以后每趟归并将 m 个归并段归并成 $\lceil m/k\rceil$ 个归并段，直至最后形成一个大的归并段为止

树的高度 - 1 = $\lceil\log_kr\rceil$ = 归并趟数 S，可见，只要**增大归并路数 k 或减少初始归并段个数 r 都能减少归并趟数 S**，进而减少读写磁盘的次数，**达到提高外部排序速度的目的**（可以通过增大内存工作区来增大归并段长度从而减少归并段的数量）

- k 叉树最底层有 $k^{h-1}$ 个结点，则  $r\leq k^{h-1}$ 故 h 最小时 $h-1=\lceil\log_kr\rceil$

思考：缓冲区大小是根据磁盘块决定的，并不是说内存只能放这么点东西，根据机组的知识，磁盘是按块进行数据传输的，所以缓冲区大小设置为磁盘块大小刚刚好，增多缓冲区数只是要使用更多内存而已；根据 CPU 比磁盘 I/O 速度快得多，所以只要不是太离谱，增多缓冲区所需要更多比较次数所需要的时间也不会有太大的影响

### 多路平衡归并与败者树

增加归并路数 k 时，内部归并的时间将增加，做内部归并时，在 k 个元素中选择关键字最小的记录需要比较 k - 1 次

每趟归并 n 个元素需要做 (n - 1)(k - 1) 次比较，S 趟归并总共需要的比较次数为 $S(n-1)(k-1)$=$\lceil\log_kr\rceil(n-1)(k-1)$=$\lceil\log_2r\rceil(n-1)(k-1)/\lceil\log_2k\rceil$ 其中，$(k-1)/\lceil\log_2k\rceil$ 随 k 增长而增长，因此内部归并时间亦随 k 的增长而增长

这将抵消由于增大 k 而减少外存访问次数所得到的效益。因此，不能使用普通的内部归并排序算法

**为了使内部归并不受 k 的增大的影响**，引入了败者树（构建需要 k - 1 次比较）：

* 败者树是树形选择排序的一种变体，**可视为一棵完全二叉树**
* k 个**叶结点**分别存放 k 个归并段在归并过程中**当前参加比较的记录**
* **内部结点用来记忆左右子树中的失败者**，而让胜者往上继续进行比较，一直到根结点
* 若比较两个数，**大的为失败者、小的为胜利者**，则**根结点指向的数为最小数**

因为 k 路归并的败者树深度（不算叶子结点）为 $\lceil\log_2k\rceil$，因此 k 个记录中选择最小关键字，最多需要 $\lceil\log_2k\rceil$ 次比较

所以**总的比较次数为** $S(n-1)\lceil\log_2k\rceil=\lceil\log_kr\rceil(n-1)\lceil\log_2k\rceil=(n-1)\lceil\log_2r\rceil$

使用败者树后，内部归并的比较次数与 k 无关了，**只要内存空间允许，增大归并路数 k 将有效地减少归并树的高度**，从而减少 I/O 次数，提高外部排序的速度

- 实际代码中叶子结点是放在输入缓冲区里面的，只需要开辟数组存放非叶结点，非叶结点存放失败者所在缓冲区的索引，如下图，ls[0...4] 是数组的位置，里面的值是缓冲区的索引

![image-20210929195228897](..\images\image-20210929195228897.png)

归并路数 k 增大时，相应地需要增加输入缓冲区的个数，若可供使用的内存空间不变，势必要减少每个输入缓冲区的容量，使得内存、外存交换数据的次数增大。当 k 值过大时，虽然归并趟数会减少，但读写外存的次数仍会增加

- 当内存不够时，盲目的增大归并数会令输入缓冲区小于磁盘块的大小，从而增大读写外存的次数增大

### 置换—选择排序

**置换-选择算法**用来**产生更长的初始归并段**，从而减少初始归并段个数，来减少归并的时间

设初始待排文件为 `FI`，初始归并段输出文件为 `FO`，内存工作区为 `WA`，`FO` 和 `WA` 的初始状态为空，`WA` 可容纳 w 个记录

置换-选择算法的步骤如下：

1. 从 `FI` 输入 w 个记录到工作区 WA
2. 从 `WA` 中选出其中关键字取最小值的记录，记为 `MINIMAX` 记录
3. 将 `MINIMAX` 记录输出到 `FO` 中去
4. 若 `FI` 不空，则从 `FI` 输入下一个记录到 `WA` 中
5. 从 `WA` 中所有关键字比 `MINIMAX` 记录的关键字大的记录中选出最小关键字记录，作为新的 `MINIMAX` 记录
6. 重复 3～5，直至在 `WA` 中选不出新的 `MINIMAX` 记录为止，由此得到一个初始归并段，输出一个归并段的结束标志到 `FO` 中去
7. 重复 2～6，直至WA为空，由此得到全部初始归并段

![image-20210929200821150](..\images\image-20210929200821150.png)

思考：每输出一块记录，就读入一块记录会很耗费 I/O 所以实际上可能是工作区比磁盘块大很多，先读文件把工作区填满，然后取 k 个最小的记录（假设一个磁盘块放 k 个记录）输出到文件，再读入 k 个记录来进行置换选择排序

思考：或者额外多用两块磁盘块大小的块，作为输入和输出缓冲，先用输入文件填满工作区和输入缓冲，每次选一个最小的放到输出缓冲，然后从输入缓冲读一个到工作区，输出满了就送到输出文件，输入空了就从输入文件拿一块

### 最佳归并树

文件经过置换-选择排序后，得到的是长度不等的初始归并段，组织长度不等的初始归并段的归并顺序，令 I/O 次数最少

这就需要把哈夫曼树扩展到 k 叉树了，**使用哈夫曼树可以简单的得到最佳归并树**

注意：**归并过程中的磁盘 I/O 次数 = 归并树的 WPL × 2**，乘 2 是因为读和写各需要一次

![image-20210929201624628](..\images\image-20210929201624628.png)

但当初始归并段的长度不可以构成一个 k 叉的哈夫曼树怎么办？

正确的做法是：若初始归并段不足以构成一棵严格 k 叉树时，就给它**添加足够的零，让它可以构成哈夫曼树**

![image-20210929202213082](..\images\image-20210929202213082.png)

如何判定添加虚段（0）的数目？

* 设度为 0 的结点有 $n_0$（= n）个，度为 k 的结点有 $n_k$ 个

* 对于严格的 k 叉树有 $n_0=(k-1)n_k+1$ 个，可得 $n_k=(n_0-1)/(k-1)$

* 若 $(n_0-1)\%(k-1)=0$ 则说明 $n_0$ 个叶结点**正好可以构造 k 叉归并树**

* 若 $(n_0-1)\%(k-1)=u\not=0$，则说明 $n_0$ 个叶结点，其中有 u 个是多余的

  增加一个内结点代替原本叶结点位置，就可以多出 k - 1 个叶结点使用

  那么扣去 u 个叶结点就是要添加的空归并段，即**添加 $k-u-1$ 个空归并段**，$u=(n_0-1)\%(k-1)$

也可以**使用 `n + e = k + d(k - 1)`**，e 是添加的零的个数，d 是最小整数令 $k+d(k-1)\geq n$，k 是归并的路数

## 归纳总结

1. 直接**插入排序、冒泡排序、简单选择**排序它们主要用于**元素个数 n 不是很大**（n < 10000）的情形

   它们的平均时间复杂度均为 $O(n^2)$，实现也都非常简单

   直接插入排序对于**规模很小的元素序列**（n ≤ 25）非常有效

   冒泡排序和直接插入在最好情况下，只需要一趟排序过程就可以完成，只需要 n - 1 次比较操作且不需要交换操作

   简单选择排序的关键字比较次数**总是** $O(n^2)$；最好情况下数据不需要移动，最坏情况下元素移动次数不超过 3(n - 1)

   从空间复杂度来看，这三种基本的排序方法仅需要一个辅助元素

   从稳定性来看，直接插入排序和冒泡排序都是稳定的；简单选择排序不是

2. 对于**中等规模的元素序列**（n ≤ 1000 )，**希尔排序**是一种很好的选择

   理论上和实验上已证明，希尔排序的**比较次数和移动次数比直接插入排序时少得多**，特别是当 n 越大时效果越明显

   希尔排序代码简单，基本上不需要什么额外内存，但希尔排序是一种不稳定的排序算法

3. 对于**元素个数 n 很大的情况**，可以**采用快排、堆排序、归并排序、基数排序**

   其中快排和堆排序都是不稳定的，而归并排序和基数排序是稳定的排序算法

   * 快速排序是**最通用的高效内部排序算法**，特别是它的<u>划分思想经常在很多算法设计题中出现</u>
   * 平均情况下它的时间复杂度为 $O(n\log_2n)$，额外空间也是 $O(\log_2n)$
   * 最坏情况时间复杂度会增加到 $O(n^2)$，空间复杂度也会增加到 $O(n)$，但可以通过“三者取中”法来避免最坏情况的发生

   堆排序也是一种高效的内部排序算法，它的时间复杂度是 $O(n\log_2n)$，而且没有最坏情况导致运行明显变慢，并且**堆排序基本上不需要额外的空间**。但<u>堆排序不大可能提供比快速排序更好的平均性能</u>

   归并排序也是一个重要的高效排序算法，它的一个重要特性是性能与输入元素序列无关，时间复杂度总是 $O(n\log_2n)$。归并排序的**主要缺点是需要 O(n) 的额外存储空间**

   * 基数排序是一种相对特殊的排序算法，它们对关键字的不同位部分进行处理和比较、
   * 在常规编程环境中，**基数排序的线性时间开销并不比快速排序的时间开销小很多**，且其<u>适应性远不如普通的进行比较和交换操作的排序方法</u>
   * 在实际工作中，常规的高效排序算法如快速排序的应用要比基数排序广泛得多
   * 基数排序需要的额外存储空间包括待排序元素大小的空间及与基数数目相等的一系列桶

4. 混合使用

   我们可以混合使用不同的排序算法，如可以将直接插入排序集成到归并排序的算法中

   这种**混合算法能够充分发挥不同算法各自的优势**，从而在整体上得到更好的性能

